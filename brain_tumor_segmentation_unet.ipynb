{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 5px solid green; padding: 10px; background-color:rgb(224, 247, 206);\">\n",
    "    <b>⚡️ Information:</b>\n",
    "    Yihan's customized unet experiment\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0 - Set & Check available memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limited GPU memory usage to 18GB\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "MEMORY_SIZE = 18\n",
    "memory_limit = MEMORY_SIZE * 1024\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memory_limit)]  # Set limit to 15GB\n",
    "        )\n",
    "        print(f\"Limited GPU memory usage to {MEMORY_SIZE}GB\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: GPU:0\n",
      "Current Memory Usage: 0 bytes\n",
      "Peak Memory Usage: 0 bytes\n",
      "Memory growth for PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'): None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        device_name = f\"GPU:{i}\"  # Properly format the device name\n",
    "        details = tf.config.experimental.get_memory_info(device_name)\n",
    "        print(f\"GPU: {device_name}\")\n",
    "        print(f\"Current Memory Usage: {details['current']} bytes\")\n",
    "        print(f\"Peak Memory Usage: {details['peak']} bytes\")\n",
    "else:\n",
    "    print(\"No GPU devices found.\")\n",
    "\n",
    "for gpu in gpus:\n",
    "    print(f\"Memory growth for {gpu}: {tf.config.experimental.get_memory_growth(gpu)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from skimage.transform import rotate\n",
    "from skimage.util import montage\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import cv2\n",
    "import tensorflow\n",
    "import random\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "import numpy as np\n",
    "from keras.callbacks import CSVLogger\n",
    "import keras.backend as K\n",
    "import zipfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### paths, VOLUME_*, IMG_SIZE, N_CHANNELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a sample path (here we will take the first patient of the Training dataset)\n",
    "brats_index = 'BraTS-GLI-00077-000'\n",
    "brats_sample_path = f'../brain_tumor_seg/data/raw_data/GLI_train/{brats_index}/{brats_index}-'\n",
    "\n",
    "# Specify the root data path of training data\n",
    "data_path_GLI_train_dir = f'../brain_tumor_seg/data/raw_data/GLI_train'\n",
    "\n",
    "\n",
    "# Define selected slices range\n",
    "VOLUME_START_AT = 40 \n",
    "VOLUME_SLICES_PLUS = 76 \n",
    "TUMOR_RATIO_LOWER_BOUND = 0.1\n",
    "TUMOR_RATIO_UPPER_BOUND = 0.15\n",
    "\n",
    "# For DataGenerator\n",
    "IMG_SIZE = 256\n",
    "N_CHANNELS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not a Step - Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 4 MRI modalities and the segmentation located in the patient's path using the nibabel library\n",
    "t1_img_sample=nib.load(brats_sample_path + 't1n.nii.gz')\n",
    "t1ce_img_sample=nib.load(brats_sample_path + 't1c.nii.gz')\n",
    "t2_img_sample=nib.load(brats_sample_path + 't2w.nii.gz')\n",
    "flair_img_sample=nib.load(brats_sample_path + 't2f.nii.gz')\n",
    "seg_img_sample=nib.load(brats_sample_path + 'seg.nii.gz')\n",
    "\n",
    "# Get the image data\n",
    "t1_data_sample = t1_img_sample.get_fdata()\n",
    "t1ce_data_sample = t1ce_img_sample.get_fdata()\n",
    "t2_data_sample = t2_img_sample.get_fdata()\n",
    "flair_data_sample = flair_img_sample.get_fdata()\n",
    "seg_data_sample = seg_img_sample.get_fdata()\n",
    "\n",
    "# Plot the 100th slice of the 4 RMI modalities and the segmentation\n",
    "slice_nb = 100\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(20,20))\n",
    "axs[0].imshow(t1_data_sample[:,:,slice_nb], cmap=\"gray\")\n",
    "axs[0].set_title('T1')\n",
    "axs[1].imshow(t1ce_data_sample[:,:,slice_nb], cmap=\"gray\")\n",
    "axs[1].set_title('T1CE')\n",
    "axs[2].imshow(t2_data_sample[:,:,slice_nb], cmap=\"gray\")\n",
    "axs[2].set_title('T2')\n",
    "axs[3].imshow(flair_data_sample[:,:,slice_nb], cmap=\"gray\")\n",
    "axs[3].set_title('FLAIR')\n",
    "axs[4].imshow(seg_data_sample[:,:,slice_nb], cmap=\"gray\")\n",
    "axs[4].set_title('Segmentation')\n",
    "plt.savefig(f'./plt/seg_classes_{brats_index}.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a RMI modality through all planes\n",
    "slice_nb = 100\n",
    "\n",
    "fig, axs2 = plt.subplots(1, 3, figsize=(10,10))\n",
    "\n",
    "# Apply a 90° rotation with an automatic resizing, otherwise the display is less obvious to analyze\n",
    "axs2[0].imshow(rotate(t1_data_sample[slice_nb,:,:], 90, resize=True), cmap=\"gray\")\n",
    "axs2[0].set_title('T1 - Sagittal View')\n",
    "\n",
    "axs2[1].imshow(rotate(t1_data_sample[:,slice_nb,:], 90, resize=True), cmap=\"gray\")\n",
    "axs2[1].set_title('T1 - Coronal View')\n",
    "\n",
    "axs2[2].imshow(t1_data_sample[:,:,slice_nb], cmap=\"gray\")\n",
    "axs2[2].set_title('T1 - Axial View')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize = (15,15))\n",
    "ax1.imshow(rotate(montage(t1_data_sample[:,:,:]), 90, resize=True), cmap ='gray')\n",
    "\n",
    "# montage allows us to concatenate multiple images of the same size horizontally and vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all slices of a segmentation\n",
    "fig, ax1 = plt.subplots(1, 1, figsize = (15,15))\n",
    "ax1.imshow(rotate(montage(seg_data_sample[:,:,:]), 90, resize=True), cmap ='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize = (15,15))\n",
    "ax1.imshow(rotate(montage(t1_data_sample[60:135,:,:]), 90, resize=True), cmap ='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a segmantation\n",
    "some_seg_img = nib.load(f'{brats_sample_path}seg.nii.gz').get_fdata()\n",
    "\n",
    "cmap = mpl.colors.ListedColormap(['#440054', '#3b528b', '#18b880', '#e6d74f'])\n",
    "norm = mpl.colors.BoundaryNorm([-0.5, 0.5, 1.5, 2.5, 3.5], cmap.N)\n",
    "\n",
    "plt.imshow(some_seg_img[100,:,:], cmap=cmap, norm=norm)\n",
    "plt.title(brats_index)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_samples = [os.path.join(data_path_GLI_train_dir, sample, f\"{sample}-seg.nii.gz\") for sample in os.listdir(data_path_GLI_train_dir) if not sample.endswith('.csv')]\n",
    "\n",
    "saved_values = []\n",
    "max_nb_values = 0\n",
    "for sample in seg_samples:\n",
    "    seg_img_sample = nib.load(sample).get_fdata()\n",
    "    unique_values = np.unique(seg_img_sample)\n",
    "    nb_unique_values = len(np.unique(seg_img_sample))\n",
    "    \n",
    "    if nb_unique_values > max_nb_values:\n",
    "        max_nb_values = nb_unique_values\n",
    "        saved_values = unique_values\n",
    "\n",
    "print(f\"Maximum number of values in all segmentation images: {max_nb_values}\")\n",
    "print(f\"Values: {saved_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletion of class 0\n",
    "seg_0 = some_seg_img.astype(float).copy()\n",
    "seg_0[seg_0 != 0] = np.nan\n",
    "\n",
    "# Isolation of class 1\n",
    "seg_1 = some_seg_img.astype(float).copy()\n",
    "seg_1[seg_1 != 1] = np.nan\n",
    "\n",
    "# Isolation of class 2\n",
    "seg_2 = some_seg_img.astype(float).copy()\n",
    "seg_2[seg_2 != 2] = np.nan\n",
    "\n",
    "# Isolation of class 4\n",
    "seg_3 = some_seg_img.astype(float).copy()\n",
    "seg_3[seg_3 != 4] = np.nan\n",
    "\n",
    "# Define legend\n",
    "class_names = ['class 0', 'class 1', 'class 2', 'class 3']\n",
    "legend = [plt.Rectangle((0, 0), 1, 1, color=cmap(i), label=class_names[i]) for i in range(len(class_names))]\n",
    "\n",
    "fig, axs3 = plt.subplots(1, 5, figsize=(15, 15))\n",
    "\n",
    "axs3[0].imshow(some_seg_img[100,:,:], cmap=cmap, norm=norm)\n",
    "axs3[0].set_title('Original Segmentation')\n",
    "axs3[0].legend(handles=legend, loc='upper right')\n",
    "\n",
    "axs3[1].imshow(seg_0[100,:,:], cmap=cmap, norm=norm)\n",
    "axs3[1].set_title('[Not Tumor] class 0')\n",
    "\n",
    "axs3[2].imshow(seg_1[100,:,:], cmap=cmap, norm=norm)\n",
    "axs3[2].set_title('[NCR] class 1')\n",
    "\n",
    "axs3[3].imshow(seg_2[100,:,:], cmap=cmap, norm=norm)\n",
    "axs3[3].set_title('[ED] class 2')\n",
    "\n",
    "axs3[4].imshow(seg_3[100,:,:], cmap=cmap, norm=norm)\n",
    "axs3[4].set_title('[ET] class 3')\n",
    "\n",
    "# Save the figure to a file\n",
    "plt.savefig('segmentation_classes.png', dpi=300)  # Saves the image as 'segmentation_classes.png'\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, counts = np.unique(some_seg_img, return_counts=True)\n",
    "print(f'distribution of 4 classes: {counts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modality shape\n",
    "print(f'modality shape: {t1_data_sample.shape}')\n",
    "\n",
    "# Segmentation shape\n",
    "print(f'segmentation shape: {seg_data_sample.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Load images and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 1251\n"
     ]
    }
   ],
   "source": [
    "# Retrieve all samples from path with listdir(). This method lists of all files + directories in the specified directory.\n",
    "all_datas = os.listdir(data_path_GLI_train_dir)\n",
    "print(\"Number of samples:\", len(all_datas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train length: 850\n",
      "Validation length: 251\n",
      "Test length: 150\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into train and validation sets\n",
    "datas_train, datas_val = train_test_split(all_datas, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the train set into the real train set and in a test set \n",
    "datas_train, datas_test = train_test_split(datas_train, test_size=0.15, random_state=42)\n",
    "\n",
    "# Print data distribution (Train: 68%, Test: 12%, Val: 20%)\n",
    "print(f\"Train length: {len(datas_train)}\")\n",
    "print(f\"Validation length: {len(datas_val)}\")\n",
    "print(f\"Test length: {len(datas_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: keras\n",
      "Version: 2.7.0\n",
      "Summary: Deep learning for humans.\n",
      "Home-page: https://keras.io/\n",
      "Author: Keras team\n",
      "Author-email: keras-users@googlegroups.com\n",
      "License: Apache 2.0\n",
      "Location: /home/cbel/Desktop/YIHAN/venv/lib/python3.8/site-packages\n",
      "Requires: \n",
      "Required-by: tensorflow\n",
      "---\n",
      "Name: tensorflow\n",
      "Version: 2.7.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /home/cbel/Desktop/YIHAN/venv/lib/python3.8/site-packages\n",
      "Requires: h5py, wheel, typing-extensions, google-pasta, gast, flatbuffers, tensorboard, protobuf, grpcio, opt-einsum, libclang, absl-py, tensorflow-io-gcs-filesystem, tensorflow-estimator, six, termcolor, keras-preprocessing, numpy, wrapt, astunparse, keras\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show keras tensorflow # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "tensorflow version: 2.7.0\n",
      "is built with CUDA: True\n",
      "GPU details: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU is available.\n",
      "===============================\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"===============================\")\n",
    "print(f'tensorflow version: {tf.__version__}')  # Should print 2.7.0\n",
    "print(f'is built with CUDA: {tf.test.is_built_with_cuda()}')  # Should return True\n",
    "print(f'GPU details: {tf.config.list_physical_devices(\"GPU\")}')  # Should show GPU details\n",
    "\n",
    "# Check if TensorFlow can detect a GPU\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available.\")\n",
    "else:\n",
    "    print(\"GPU is not available.\")\n",
    "\n",
    "print(\"===============================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip if no need - combine existing pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import csv\n",
    "\n",
    "DATA_1_DIR = 'processed_data_0.05_0.1'\n",
    "DATA_2_DIR = 'processed_data_0.1_0.25'\n",
    "COMBINED_DATA_DIR = 'processed_data_0.05_0.25'\n",
    "SET = 'test'\n",
    "\n",
    "\n",
    "with open(f'./data/{DATA_1_DIR}/processed_{SET}_data.pkl', 'rb') as f:\n",
    "    data1 = pickle.load(f)\n",
    "with open(f'./data/{DATA_2_DIR}/processed_{SET}_data.pkl', 'rb') as f:\n",
    "    data2 = pickle.load(f)\n",
    "combined_data = data1.copy()\n",
    "combined_data.update(data2)\n",
    "with open(f'./data/{COMBINED_DATA_DIR}/processed_{SET}_data.pkl', 'wb') as f:\n",
    "    pickle.dump(combined_data, f)\n",
    "\n",
    "\n",
    "with open(f'./data/{DATA_1_DIR}/{SET}_data_info.csv', 'r') as csv1, open(f'./data/{DATA_2_DIR}/{SET}_data_info.csv', 'r') as csv2:\n",
    "    reader1 = csv.reader(csv1)\n",
    "    reader2 = csv.reader(csv2)\n",
    "\n",
    "    with open(f'./data/{COMBINED_DATA_DIR}/{SET}_data_info.csv', 'w', newline='') as csv_out:\n",
    "        writer = csv.writer(csv_out)\n",
    "        for row in reader1:\n",
    "            writer.writerow(row)\n",
    "        next(reader2)\n",
    "        for row in reader2:\n",
    "            writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step * Crop Nii files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step * - 1: Set up params & crop method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import nibabel as nib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "total_slices_dict = {\n",
    "    \"train\": 0,\n",
    "    \"val\": 0,\n",
    "    \"test\": 0\n",
    "}\n",
    "\n",
    "def preprocess_and_save(data_list, save_path, log_path, tumor_ratio_lower_bound, tumor_ratio_upper_bound):\n",
    "    processed_data = {'X': [], 'y': []}\n",
    "    slice_info = {}  # Dictionary to store slice information for each NIfTI\n",
    "\n",
    "    with open(log_path, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(['NIfTI ID', 'Slice Index', 'Tumor Ratio', 'Brain Area'])\n",
    "\n",
    "        total_slices = 0\n",
    "\n",
    "        for i in data_list:\n",
    "            data_path = os.path.join(data_path_GLI_train_dir, i, i)\n",
    "            t1ce_path = data_path + '-t1c.nii.gz'\n",
    "            flair_path = data_path + '-t2f.nii.gz'\n",
    "            seg_path = data_path + '-seg.nii.gz'\n",
    "            \n",
    "            t1ce = nib.load(t1ce_path).get_fdata()\n",
    "            flair = nib.load(flair_path).get_fdata()\n",
    "            seg = nib.load(seg_path).get_fdata()\n",
    "\n",
    "            slice_info[i] = []  # Initialize list for each NIfTI\n",
    "\n",
    "            for j in range(VOLUME_SLICES_PLUS):\n",
    "                slice_seg = seg[:, :, j + VOLUME_START_AT]\n",
    "                slice_flair = flair[:, :, j + VOLUME_START_AT]\n",
    "                tumor_area = np.sum(slice_seg > 0)\n",
    "                brain_area = np.sum(slice_flair > 0)  # Use non-zero pixels in FLAIR as brain area\n",
    "\n",
    "                # Avoid division by zero\n",
    "                if brain_area == 0:\n",
    "                    continue\n",
    "\n",
    "                tumor_percentage = tumor_area / brain_area\n",
    "\n",
    "                if tumor_ratio_lower_bound < tumor_percentage <= tumor_ratio_upper_bound:\n",
    "                    X_slice = np.zeros((IMG_SIZE, IMG_SIZE, N_CHANNELS))\n",
    "                    X_slice[:, :, 0] = cv2.resize(slice_flair, (IMG_SIZE, IMG_SIZE))\n",
    "                    X_slice[:, :, 1] = cv2.resize(t1ce[:, :, j + VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n",
    "                    processed_data['X'].append(X_slice)\n",
    "                    processed_data['y'].append(slice_seg)\n",
    "                    slice_info[i].append(j + VOLUME_START_AT)  # Record the slice index\n",
    "\n",
    "                    # Write slice information to CSV file\n",
    "                    csv_writer.writerow([i, j + VOLUME_START_AT, round(tumor_percentage, 4), brain_area])\n",
    "                    total_slices += 1\n",
    "\n",
    "        total_slices_dict[log_path.split('/')[-1].split('_')[0]] = total_slices\n",
    "\n",
    "    # Save the processed data\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(processed_data, f)\n",
    "\n",
    "def count_rows_in_csv(file_path):\n",
    "    with open(file_path, mode='r', newline='', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader, None)\n",
    "        row_count = sum(1 for row in reader)\n",
    "    return row_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "def append_to_csv(file_path, data, header=None):\n",
    "    file_exists = os.path.isfile(file_path)\n",
    "\n",
    "    with open(file_path, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if header and not file_exists:\n",
    "            writer.writerow(header)\n",
    "        writer.writerows(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step * - 2: Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tumor ratio: 0.1 ~ 0.15\n",
      "dir processed_data created.\n",
      "train: 9830 slices\n",
      "val: 2862 slices\n",
      "test: 2118 slices\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import gc\n",
    "\n",
    "processed_data_dir_root = f'./data/processed_data_{TUMOR_RATIO_LOWER_BOUND}_{TUMOR_RATIO_UPPER_BOUND}'\n",
    "processed_data_lists_csv = f'./data/processed_data_lists.csv'\n",
    "processed_data_lists_header = ['tumor_ratio_lower_bound', 'tumor_ratio_upper_bound', 'train_slices', 'val_slices', 'test_slices', 'generated_timestamp']\n",
    "\n",
    "print(f'tumor ratio: {TUMOR_RATIO_LOWER_BOUND} ~ {TUMOR_RATIO_UPPER_BOUND}')\n",
    "\n",
    "if not os.path.exists(processed_data_dir_root):\n",
    "    os.makedirs(processed_data_dir_root)\n",
    "    print(\"dir processed_data created.\")\n",
    "\n",
    "    preprocess_and_save(datas_train, f'{processed_data_dir_root}/processed_train_data.pkl', f'{processed_data_dir_root}/train_data_info.csv', TUMOR_RATIO_LOWER_BOUND, TUMOR_RATIO_UPPER_BOUND)\n",
    "    gc.collect()\n",
    "    preprocess_and_save(datas_val, f'{processed_data_dir_root}/processed_val_data.pkl', f'{processed_data_dir_root}/val_data_info.csv', TUMOR_RATIO_LOWER_BOUND, TUMOR_RATIO_UPPER_BOUND)\n",
    "    gc.collect()\n",
    "    preprocess_and_save(datas_test, f'{processed_data_dir_root}/processed_test_data.pkl', f'{processed_data_dir_root}/test_data_info.csv', TUMOR_RATIO_LOWER_BOUND, TUMOR_RATIO_UPPER_BOUND)\n",
    "    gc.collect()\n",
    "\n",
    "    processed_data_lists_data = [\n",
    "        [TUMOR_RATIO_LOWER_BOUND, TUMOR_RATIO_UPPER_BOUND, total_slices_dict[\"train\"], total_slices_dict[\"val\"], total_slices_dict[\"test\"], datetime.now().strftime(\"%b-%d_%H-%M-%S\")]\n",
    "    ]\n",
    "    append_to_csv(processed_data_lists_csv, processed_data_lists_data, processed_data_lists_header)\n",
    "\n",
    "else:\n",
    "    print(f'dir processed_data existed at {processed_data_dir_root}.')\n",
    "\n",
    "# set the data info to params\n",
    "TRAIN_PKL = f'{processed_data_dir_root}/processed_train_data.pkl'\n",
    "VAL_PKL = f'{processed_data_dir_root}/processed_val_data.pkl'\n",
    "TEST_PKL = f'{processed_data_dir_root}/processed_test_data.pkl'\n",
    "TRAIN_PKL_CSV = f'{processed_data_dir_root}/train_data_info.csv'\n",
    "VAL_PKL_CSV = f'{processed_data_dir_root}/val_data_info.csv'\n",
    "TEST_PKL_CSV = f'{processed_data_dir_root}/test_data_info.csv'\n",
    "total_slices_dict.update({\n",
    "    \"train\": count_rows_in_csv(TRAIN_PKL_CSV),\n",
    "    \"val\": count_rows_in_csv(VAL_PKL_CSV),\n",
    "    \"test\": count_rows_in_csv(TEST_PKL_CSV)\n",
    "})\n",
    "\n",
    "print(f'train: {total_slices_dict[\"train\"]} slices')\n",
    "print(f'val: {total_slices_dict[\"val\"]} slices')\n",
    "print(f'test: {total_slices_dict[\"test\"]} slices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Set up training compoenents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When generating `DataGenerator`**:\n",
    "- We use a data generator to be able to process and send our data to our neural network (since all our images cannot be stored in memory at once).\n",
    "- For each epoch (single pass of the entire training dataset through a neural network), the model will receive 250 samples (those contained in our training dataset).\n",
    "- For each sample, the model will have to analyze 150 slices (since there are two modalities, and 75(VOLUME_SLICES) selected slices for both of them), received in a (128, 128) shape, as an X array of a (128, 128, 75, 2) shape. This array will be provided with the ground truth segmentation of the patient, which will be One-Hot encoded and will then have a (75, 128, 128, 4) shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 1: DataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-1-1 DataGenerator_UnetV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# DataGenerator from Rastislav's notebook, https://www.kaggle.com/code/rastislav/3d-mri-brain-tumor-segmentation-u-net\n",
    "\n",
    "class DataGenerator_UnetV1(keras.utils.all_utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = N_CHANNELS, shuffle=True):\n",
    "        print('------ usging Data Generator V1 ------')\n",
    "        'Initialization'\n",
    "        self.dim = dim # Resized image dimensions (128 x 128)\n",
    "        self.batch_size = batch_size #  Number of images to load each time\n",
    "        self.list_IDs = list_IDs # Patients IDs\n",
    "        self.n_channels = n_channels # Number of channels (T1CE + FLAIR)\n",
    "        self.shuffle = shuffle # Indicates if data is shuffled for each epoch\n",
    "        self.on_epoch_end() # Updates indexes after each epoch\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Load & Generate data\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        'Generates data containing batch_size samples'\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size*VOLUME_SLICES_PLUS, *self.dim, self.n_channels))\n",
    "        y = np.zeros((self.batch_size*VOLUME_SLICES_PLUS, 240, 240))\n",
    "\n",
    "        # Generate data\n",
    "        for c, i in enumerate(Batch_ids):\n",
    "            \n",
    "            # Get path of each RMI modality and the segmentation\n",
    "            data_path = os.path.join(data_path_GLI_train_dir, i, i)\n",
    "            t1ce_path = data_path + '-t1c.nii.gz'\n",
    "            flair_path = data_path + '-t2f.nii.gz'\n",
    "            seg_path = data_path + '-seg.nii.gz'\n",
    "            #t1_path = sample_path + '_t1.nii.gz'\n",
    "            #t2_path = sample_path + '_t2.nii.gz'\n",
    "            \n",
    "            # Extract the data from these paths\n",
    "            t1ce = nib.load(t1ce_path).get_fdata()\n",
    "            flair = nib.load(flair_path).get_fdata()\n",
    "            seg = nib.load(seg_path).get_fdata()\n",
    "            #t1 = nib.load(t1_paths).get_fdata()\n",
    "            #t2 = nib.load(t2_path).get_fdata()\n",
    "        \n",
    "            for j in range(VOLUME_SLICES_PLUS):\n",
    "                 X[j +VOLUME_SLICES_PLUS*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n",
    "                 X[j +VOLUME_SLICES_PLUS*c,:,:,1] = cv2.resize(t1ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "                 y[j +VOLUME_SLICES_PLUS*c] = seg[:,:,j+VOLUME_START_AT]\n",
    "                    \n",
    "        # Masks / Segmentations\n",
    "        y[y==4] = 3\n",
    "        mask = tensorflow.one_hot(y, 4)\n",
    "        Y = tensorflow.image.resize(mask, (IMG_SIZE, IMG_SIZE))\n",
    "        \n",
    "        # Scale data between 0 and 1 (since the minimum value in the data is 0)\n",
    "        return X/np.max(X), Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-1-2 DataGenerator_UnetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# DataGenerator from Rastislav's notebook, https://www.kaggle.com/code/rastislav/3d-mri-brain-tumor-segmentation-u-net\n",
    "\n",
    "class DataGenerator_UnetV2(keras.utils.all_utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = N_CHANNELS, shuffle=True):\n",
    "        print('------ usging Data Generator V2 ------')\n",
    "        'Initialization'\n",
    "        self.dim = dim # Resized image dimensions (128 x 128)\n",
    "        self.batch_size = batch_size #  Number of images to load each time\n",
    "        self.list_IDs = list_IDs # Patients IDs\n",
    "        self.n_channels = n_channels # Number of channels (T1CE + FLAIR)\n",
    "        self.shuffle = shuffle # Indicates if data is shuffled for each epoch\n",
    "        self.on_epoch_end() # Updates indexes after each epoch\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Load & Generate data\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        'Generates data containing batch_size samples'\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size*VOLUME_SLICES_PLUS, *self.dim, self.n_channels))\n",
    "        y = np.zeros((self.batch_size*VOLUME_SLICES_PLUS, 240, 240))\n",
    "\n",
    "        # Generate data\n",
    "        for c, i in enumerate(Batch_ids):\n",
    "            \n",
    "            # Get path of each RMI modality and the segmentation\n",
    "            data_path = os.path.join(data_path_GLI_train_dir, i, i)\n",
    "            t1ce_path = data_path + '-t1c.nii.gz'\n",
    "            flair_path = data_path + '-t2f.nii.gz'\n",
    "            seg_path = data_path + '-seg.nii.gz'\n",
    "            #t1_path = sample_path + '_t1.nii.gz'\n",
    "            #t2_path = sample_path + '_t2.nii.gz'\n",
    "            \n",
    "            # Extract the data from these paths\n",
    "            t1ce = nib.load(t1ce_path).get_fdata()\n",
    "            flair = nib.load(flair_path).get_fdata()\n",
    "            seg = nib.load(seg_path).get_fdata()\n",
    "            #t1 = nib.load(t1_paths).get_fdata()\n",
    "            #t2 = nib.load(t2_path).get_fdata()\n",
    "        \n",
    "            for j in range(VOLUME_SLICES_PLUS):\n",
    "                 X[j +VOLUME_SLICES_PLUS*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "                 y[j +VOLUME_SLICES_PLUS*c] = seg[:,:,j+VOLUME_START_AT]\n",
    "                    \n",
    "        # Masks / Segmentations\n",
    "        y[y==4] = 3\n",
    "        mask = tensorflow.one_hot(y, 4)\n",
    "        Y = tensorflow.image.resize(mask, (IMG_SIZE, IMG_SIZE))\n",
    "        \n",
    "        # Scale data between 0 and 1 (since the minimum value in the data is 0)\n",
    "        return X/np.max(X), Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-1-3 DataGenerator_UnetV3_count_image_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "class DataGenerator_UnetV3_count_image_ratio(keras.utils.all_utils.Sequence):\n",
    "    def __init__(self, data_path, batch_size=1, shuffle=True):\n",
    "        print('------ usging Data Generator V3: use crop NIIs ------')\n",
    "        with open(data_path, 'rb') as f:\n",
    "            self.data = pickle.load(f)\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(self.data['X']))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.data['X']) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        X_batch = [self.data['X'][k] for k in indexes]\n",
    "        y_batch = [self.data['y'][k] for k in indexes]\n",
    "\n",
    "        y_batch = np.array(y_batch)\n",
    "        y_batch[y_batch == 4] = 3\n",
    "        mask = tensorflow.one_hot(y_batch, 4)\n",
    "        Y = tensorflow.image.resize(mask, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        return np.array(X_batch) / np.max(X_batch), Y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 -2: U-Net model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-2-1 U-Net v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net implementation for BraTS 2019 by Naomi Fridman, https://naomi-fridman.medium.com/multi-class-image-segmentation-a5cc671e647a\n",
    "def unet_v1(inputs, ker_init, dropout):\n",
    "    print('****** using U-Net V1 ******')\n",
    "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(inputs)\n",
    "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv1)\n",
    "    \n",
    "    pool = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool)\n",
    "    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv2)\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv3)\n",
    "    \n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool4)\n",
    "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv5)\n",
    "    drop5 = Dropout(dropout)(conv5)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = 2)(drop5))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = 2)(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = 2)(conv8))\n",
    "    merge9 = concatenate([conv,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n",
    "    \n",
    "    up = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = 2)(conv9))\n",
    "    merge = concatenate([conv1,up], axis = 3)\n",
    "    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge)\n",
    "    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n",
    "    \n",
    "    conv10 = Conv2D(4, 1, activation = 'softmax')(conv)\n",
    "    \n",
    "    return Model(inputs = inputs, outputs = conv10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-2-2: U-Net V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_v2(inputs, ker_init, dropout=0.5):\n",
    "    print('****** using U-Net V2 ******')\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv1)\n",
    "\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv2)\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv3)\n",
    "    \n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv4)\n",
    "    drop4 = Dropout(dropout)(conv4)\n",
    "    \n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv5)\n",
    "    drop5 = Dropout(dropout)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n",
    "\n",
    "    conv10 = Conv2D(4, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    return Model(inputs = inputs, outputs = conv10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 3: Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metric between the predicted segmentation and the ground truth\n",
    "def dice_coef(y_true, y_pred, smooth=1.0):\n",
    "    class_num = 4\n",
    "    for i in range(class_num):\n",
    "        y_true_f = K.flatten(y_true[:,:,:,i])\n",
    "        y_pred_f = K.flatten(y_pred[:,:,:,i])\n",
    "        intersection = K.sum(y_true_f * y_pred_f)\n",
    "        loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n",
    "        if i == 0:\n",
    "            total_loss = loss\n",
    "        else:\n",
    "            total_loss = total_loss + loss\n",
    "    total_loss = total_loss / class_num\n",
    "    return total_loss\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())\n",
    "\n",
    "########################### my customized metrics ###########################\n",
    "\n",
    "def sensibility(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    false_positives = K.sum(K.round(K.clip(y_pred - y_true, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    # Calculate the sensibility\n",
    "    sensibility = 1 - (false_positives / (true_positives + possible_positives + K.epsilon()))\n",
    "    # Check for NaN or Inf values and return NaN if True\n",
    "    sensibility = tf.where(tf.math.is_nan(sensibility) | tf.math.is_inf(sensibility),\n",
    "                           tf.constant(float('NaN')),\n",
    "                           sensibility)\n",
    "    return sensibility\n",
    "\n",
    "\n",
    "def jaccard(y_true, y_pred):\n",
    "    # True positives, false positives, false negatives\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    false_positives = K.sum(K.round(K.clip(y_pred - y_true, 0, 1)))\n",
    "    false_negatives = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)))\n",
    "    # Calculate Jaccard index\n",
    "    denominator = true_positives + false_positives + false_negatives + K.epsilon()  # Add epsilon to avoid division by zero\n",
    "    result = true_positives / denominator\n",
    "    # Handle NaN or Inf cases\n",
    "    result = K.switch(K.is_inf(result) | K.is_nan(result), K.constant(float('NaN')), result)\n",
    "    return result\n",
    "\n",
    "\n",
    "# Hausdorff distance (approximation for use in Keras)\n",
    "def hausdorff(y_true, y_pred):\n",
    "    # Flatten the coordinates of the true and predicted segmentation masks\n",
    "    y_true_flat = K.flatten(y_true)\n",
    "    y_pred_flat = K.flatten(y_pred)\n",
    "    # Compute the Euclidean distance between every pair of points\n",
    "    dist_matrix = K.square(y_true_flat - y_pred_flat)\n",
    "    # Get the maximum distance in both directions (directed Hausdorff)\n",
    "    directed_hausdorff_1 = K.max(dist_matrix, axis=1)  # From y_true to y_pred\n",
    "    directed_hausdorff_2 = K.max(dist_matrix, axis=0)  # From y_pred to y_true\n",
    "    # Take the maximum of both directed Hausdorff distances\n",
    "    hausdorff_dist = K.maximum(directed_hausdorff_1, directed_hausdorff_2)\n",
    "    # Handle NaN or Inf values by replacing them with NaN (if needed)\n",
    "    hausdorff_dist = K.switch(K.is_inf(hausdorff_dist) | K.is_nan(hausdorff_dist), K.constant(float('NaN')), hausdorff_dist)\n",
    "    return hausdorff_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 4: Define training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input\n",
    "\n",
    "MODEL_VERSION = 1\n",
    "DATA_GENERATOR_VERSION = 3\n",
    "\n",
    "EPOCHS = 200\n",
    "STEPS_PER_EPOCH = len(datas_train)\n",
    "\n",
    "INPUT_LAYER = Input((IMG_SIZE, IMG_SIZE, N_CHANNELS))\n",
    "KER_INIT = 'he_normal'\n",
    "DROPOUT = 0.2\n",
    "LEARNING_RATE = 1e-4\n",
    "LOSS_FUNCTION = \"categorical_crossentropy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 5: Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** using U-Net V1 ******\n"
     ]
    }
   ],
   "source": [
    "# Build and compile the model\n",
    "model_builders = {\n",
    "    1: unet_v1,\n",
    "    2: unet_v2\n",
    "}\n",
    "model = model_builders.get(MODEL_VERSION, unet_v1)(inputs=INPUT_LAYER, ker_init=KER_INIT, dropout=DROPOUT)\n",
    "\n",
    "model.compile(loss=LOSS_FUNCTION, optimizer=tensorflow.keras.optimizers.Adam(learning_rate=LEARNING_RATE), metrics = ['accuracy',tensorflow.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 6: Set up DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ usging Data Generator V3: use crop NIIs ------\n",
      "------ usging Data Generator V3: use crop NIIs ------\n"
     ]
    }
   ],
   "source": [
    "data_generators = {\n",
    "    1: DataGenerator_UnetV1,\n",
    "    2: DataGenerator_UnetV2,\n",
    "    3: DataGenerator_UnetV3_count_image_ratio\n",
    "}\n",
    "\n",
    "training_generator = data_generators.get(DATA_GENERATOR_VERSION, DataGenerator_UnetV1)(TRAIN_PKL if DATA_GENERATOR_VERSION == 3 else datas_train)\n",
    "valid_generator = data_generators.get(DATA_GENERATOR_VERSION, DataGenerator_UnetV1)(VAL_PKL if DATA_GENERATOR_VERSION == 3 else datas_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 7: Do the GC and check the GPU and memory status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: GPU:0\n",
      "Current Memory Usage: 31040804 bytes\n",
      "Peak Memory Usage: 37721124 bytes\n",
      "Memory growth for PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'): None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        device_name = f\"GPU:{i}\"  # Properly format the device name\n",
    "        details = tf.config.experimental.get_memory_info(device_name)\n",
    "        print(f\"GPU: {device_name}\")\n",
    "        print(f\"Current Memory Usage: {details['current']} bytes\")\n",
    "        print(f\"Peak Memory Usage: {details['peak']} bytes\")\n",
    "else:\n",
    "    print(\"No GPU devices found.\")\n",
    "\n",
    "for gpu in gpus:\n",
    "    print(f\"Memory growth for {gpu}: {tf.config.experimental.get_memory_growth(gpu)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed Precision Training\n",
    "# from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "# policy = mixed_precision.Policy('mixed_float16')\n",
    "# mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 8: Set up callbacks\n",
    "\n",
    "Callbacks are functions that can be executed during the training process. \n",
    "\n",
    "We will use three callbacks:\n",
    "\n",
    "- **ReduceLROnPlateau**: This callback reduces the learning rate when a metric has stopped improving (validation loss here). The learning rate is reduced by a factor of 0.2, the patience is set to 2 epochs, and the minimum learning rate is set to 0.000001.\n",
    "\n",
    "- **ModelCheckpoint**: Saves the best model weights (model that has obtained the lowest validation loss during the different epochs). Saving a model allows us to reuse it later or to share it, without having to retrain it from scratch. This will save us time and resources!\n",
    "\n",
    "- **CSVLogger**: Add metrics to a CSV file, which is named *training.log* (parameter `append` is set to `False` so the file is overwritten if it already exists). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dir ./model/model_v1_Mar-22_15-37-10 created.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Generate timestamp for filenames\n",
    "start_train_timestamp = datetime.now().strftime(\"%b-%d_%H-%M-%S\")\n",
    "\n",
    "model_dir = f'./model/model_v{MODEL_VERSION}_{start_train_timestamp}'\n",
    "\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    print(f\"Model dir {model_dir} created.\")\n",
    "else:\n",
    "    print(f\"Model dir {model_dir} existed.\")\n",
    "\n",
    "# Define file paths with timestamps\n",
    "training_log_filename = f\"{model_dir}/training-{start_train_timestamp}.log\"\n",
    "model_checkpoint_path = f\"{model_dir}/model_epoch{{epoch:02d}}-val_loss{{val_loss:.6f}}_{start_train_timestamp}.m5\"\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.000001, verbose=1),\n",
    "    \n",
    "    keras.callbacks.ModelCheckpoint(filepath=model_checkpoint_path, verbose=1, save_best_only=True, save_weights_only=True),\n",
    "\n",
    "    CSVLogger(training_log_filename, separator=',', append=False)  # Save logs with timestamp\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Train & Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - 1: log all cell outputs during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "model name: unet_v1\n",
      "epochs: 200\n",
      "steps_per_epoch: 850\n",
      "dimension: 256\n",
      "n_channels: 2\n",
      "input layer: KerasTensor(type_spec=TensorSpec(shape=(None, 256, 256, 2), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
      "kernel init: he_normal\n",
      "dropout: 0.2\n",
      "learning rate: 0.0001\n",
      "loss function: categorical_crossentropy\n",
      "train cases: 850\n",
      "train slices: 9830\n",
      "validation cases: 251\n",
      "val slices: 2862\n",
      "slice index: 40 ~ 116\n",
      "tumor ratio: 0.1 ~ 0.15\n",
      "test cases: 150\n",
      "start training at: Mar-22_15-37-10\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(f'----------')\n",
    "print(f'model name: {model_builders[MODEL_VERSION].__name__}')\n",
    "print(f'epochs: {EPOCHS}')\n",
    "print(f'steps_per_epoch: {STEPS_PER_EPOCH}')\n",
    "print(f'dimension: {IMG_SIZE}')\n",
    "print(f'n_channels: {N_CHANNELS}')\n",
    "print(f'input layer: {INPUT_LAYER}')\n",
    "print(f'kernel init: {KER_INIT}')\n",
    "print(f'dropout: {DROPOUT}')\n",
    "print(f'learning rate: {LEARNING_RATE}')\n",
    "print(f'loss function: {LOSS_FUNCTION}')\n",
    "    \n",
    "print(f\"train cases: {len(datas_train)}\")\n",
    "print(f'train slices: {total_slices_dict[\"train\"]}')\n",
    "print(f\"validation cases: {len(datas_val)}\")\n",
    "print(f'val slices: {total_slices_dict[\"val\"]}')\n",
    "print(f'slice index: {VOLUME_START_AT} ~ {VOLUME_START_AT + VOLUME_SLICES_PLUS}')\n",
    "print(f'tumor ratio: {TUMOR_RATIO_LOWER_BOUND} ~ {TUMOR_RATIO_UPPER_BOUND}')\n",
    "print(f\"test cases: {len(datas_test)}\")\n",
    "\n",
    "print(f'start training at: {start_train_timestamp}')\n",
    "print(f'----------')\n",
    "\n",
    "original_stdout = sys.stdout\n",
    "with open(f'{model_dir}/info.log', 'w') as predict_log_file:\n",
    "    sys.stdout = predict_log_file\n",
    "    print(f'----------')\n",
    "    print(f'model name: {model_builders[MODEL_VERSION].__name__}')\n",
    "    print(f'epochs: {EPOCHS}')\n",
    "    print(f'steps_per_epoch: {STEPS_PER_EPOCH}')\n",
    "    print(f'dimension: {IMG_SIZE}')\n",
    "    print(f'n_channels: {N_CHANNELS}')\n",
    "    print(f'input layer: {INPUT_LAYER}')\n",
    "    print(f'kernel init: {KER_INIT}')\n",
    "    print(f'dropout: {DROPOUT}')\n",
    "    print(f'learning rate: {LEARNING_RATE}')\n",
    "    print(f'loss function: {LOSS_FUNCTION}')\n",
    "\n",
    "    print(f\"train cases: {len(datas_train)}\")\n",
    "    print(f'train slices: {total_slices_dict[\"train\"]}')\n",
    "    print(f\"validation cases: {len(datas_val)}\")\n",
    "    print(f'val slices: {total_slices_dict[\"val\"]}')\n",
    "    print(f'slice index: {VOLUME_START_AT} ~ {VOLUME_START_AT + VOLUME_SLICES_PLUS}')\n",
    "    print(f'tumor ratio: {TUMOR_RATIO_LOWER_BOUND} ~ {TUMOR_RATIO_UPPER_BOUND}')\n",
    "    print(f\"test cases: {len(datas_test)}\")\n",
    "\n",
    "    print(f'start training at: {start_train_timestamp}')\n",
    "    print(f'----------')\n",
    "\n",
    "sys.stdout = original_stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - 2: train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 15:37:12.639494: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850/850 [==============================] - ETA: 0s - loss: 0.1222 - accuracy: 0.9645 - mean_io_u: 0.6447 - dice_coef: 0.3456 - precision: 0.9696 - sensitivity: 0.9502 - specificity: 0.9929\n",
      "Epoch 00001: val_loss improved from inf to 0.07296, saving model to ./model/model_v1_Mar-22_15-37-10/model_epoch01-val_loss0.072959_Mar-22_15-37-10.m5\n",
      "850/850 [==============================] - 29s 29ms/step - loss: 0.1222 - accuracy: 0.9645 - mean_io_u: 0.6447 - dice_coef: 0.3456 - precision: 0.9696 - sensitivity: 0.9502 - specificity: 0.9929 - val_loss: 0.0730 - val_accuracy: 0.9770 - val_mean_io_u: 0.7659 - val_dice_coef: 0.3943 - val_precision: 0.9851 - val_sensitivity: 0.9669 - val_specificity: 0.9948 - lr: 1.0000e-04\n",
      "Epoch 2/200\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.0648 - accuracy: 0.9788 - mean_io_u: 0.7212 - dice_coef: 0.4327 - precision: 0.9854 - sensitivity: 0.9702 - specificity: 0.9949"
     ]
    }
   ],
   "source": [
    "model.fit(training_generator,\n",
    "          epochs=EPOCHS,\n",
    "          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=valid_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - 3: Plot the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "training_log_filename = glob.glob(os.path.join(model_dir, 'training-*.log'))[0]\n",
    "plt_filename = os.path.splitext(os.path.basename(training_log_filename))[0]\n",
    "print(f'plt image will be saved in: {training_log_filename}\\nwith name: {plt_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSVlogger file that contains all our metrics (accuracy, loss, dice_coef, ...) of our training\n",
    "history = pd.read_csv(training_log_filename, sep=',', engine='python')\n",
    "\n",
    "# Plot training and validation metrics\n",
    "fig, axs = plt.subplots(1, 3, figsize=(16, 8))\n",
    "# fig, axs = plt.subplots(1, 4, figsize=(16, 8))\n",
    "\n",
    "axs[0].plot(history['epoch'], history['accuracy'], 'b', label='Training Accuracy')\n",
    "axs[0].plot(history['epoch'], history['val_accuracy'], 'r', label='Validation Accuracy')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Accuracy')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(history['epoch'], history['loss'], 'b', label='Training Loss')\n",
    "axs[1].plot(history['epoch'], history['val_loss'], 'r', label='Validation Loss')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[1].legend()\n",
    "\n",
    "axs[2].plot(history['epoch'], history['dice_coef'], 'b', label='Training dice coef')\n",
    "axs[2].plot(history['epoch'], history['val_dice_coef'], 'r', label='Validation dice coef')\n",
    "axs[2].set_xlabel('Epoch')\n",
    "axs[2].set_ylabel('Dice Coefficient')\n",
    "axs[2].legend()\n",
    "\n",
    "# axs[3].plot(history['epoch'], history['mean_io_u'], 'b', label='Training mean IOU')\n",
    "# axs[3].plot(history['epoch'], history['val_mean_io_u'], 'r', label='Validation mean IOU')\n",
    "# axs[3].set_xlabel('Epoch')\n",
    "# axs[3].set_ylabel('Mean IOU')\n",
    "# axs[3].legend()\n",
    "\n",
    "# Add space between subplots\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "plt.savefig(f'./plt/train/{plt_filename}.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "def find_latest_file(directory, pattern):\n",
    "    search_pattern = os.path.join(directory, pattern)\n",
    "    files = glob.glob(search_pattern)\n",
    "\n",
    "    if not files:\n",
    "        return None\n",
    "\n",
    "    latest_file = max(files, key=os.path.getmtime)\n",
    "\n",
    "    return latest_file\n",
    "\n",
    "PATTERN = 'model_epoch*-val_loss*_*.m5.index'\n",
    "\n",
    "latest_model_file = find_latest_file(f'{model_dir}', PATTERN)\n",
    "\n",
    "latest_trained_model = os.path.splitext(os.path.splitext(os.path.basename(latest_model_file))[0])[0]\n",
    "\n",
    "print(f'latest model file: {latest_trained_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile a model and load our saved weights\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "INPUT_LAYER = Input((IMG_SIZE, IMG_SIZE, N_CHANNELS))\n",
    "KER_INIT = KER_INIT\n",
    "DROPOUT = DROPOUT\n",
    "LEARNING_RATE = LEARNING_RATE\n",
    "\n",
    "best_saved_model = model_builders.get(MODEL_VERSION, unet_v1)(inputs=INPUT_LAYER, ker_init=KER_INIT, dropout=DROPOUT)\n",
    "\n",
    "best_saved_model.compile(loss=\"categorical_crossentropy\", optimizer=tensorflow.keras.optimizers.Adam(learning_rate=LEARNING_RATE), metrics = ['accuracy',tensorflow.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity] )\n",
    "\n",
    "\n",
    "best_saved_model.load_weights(f'{model_dir}/{latest_trained_model}.m5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_segmentation(sample_path):\n",
    "    # Load NIfTI (.nii) files of the sample (patient)\n",
    "    t1ce_path = sample_path + '-t1c.nii.gz'\n",
    "    flair_path = sample_path + '-t2f.nii.gz'\n",
    "    #t1_path = sample_path + '_t1.nii'\n",
    "    #t2_path = sample_path + '_t2.nii'\n",
    "            \n",
    "    # Extract the data from these paths\n",
    "    t1ce = nib.load(t1ce_path).get_fdata()\n",
    "    flair = nib.load(flair_path).get_fdata()\n",
    "    \n",
    "    # Create an empty array\n",
    "    X = np.empty((VOLUME_SLICES_PLUS, IMG_SIZE, IMG_SIZE, 2))\n",
    "    \n",
    "    # Perform the same operations as our DataGenerator, to keep the same input shape\n",
    "    for j in range(VOLUME_SLICES_PLUS):\n",
    "        X[j,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n",
    "        X[j,:,:,1] = cv2.resize(t1ce[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n",
    "        \n",
    "    # Send our images to the CNN model and return predicted segmentation \n",
    "    return model.predict(X/np.max(X), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predicted_segmentations(samples_list, slice_to_plot, cmap, norm):\n",
    "    # Choose a random patient\n",
    "    random_sample = random.choice(samples_list)\n",
    "    print(f'random_sample: {random_sample}')\n",
    "    \n",
    "    # Get path of this patient\n",
    "    random_sample_path = os.path.join(data_path_GLI_train_dir, random_sample, random_sample)\n",
    "    print(f'random_sample_path: {random_sample_path}')\n",
    "    \n",
    "    # Predict patient's segmentation\n",
    "    predicted_seg = predict_segmentation(random_sample_path)\n",
    "   \n",
    "    # Load patient's original segmentation (Ground truth)\n",
    "    seg_path = random_sample_path + '-seg.nii.gz'\n",
    "    seg = nib.load(seg_path).get_fdata()\n",
    "    \n",
    "    # Resize original segmentation to the same dimensions of the predictions. (Add VOLUME_START_AT because original segmentation contains 155 slices vs only 75 for our prediction)\n",
    "    seg=cv2.resize(seg[:,:,slice_to_plot+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_NEAREST)\n",
    "    \n",
    "    # Differentiate segmentations by their labels\n",
    "    all = predicted_seg[slice_to_plot,:,:,1:4] # Deletion of class 0 (Keep only Core + Edema + Enhancing classes)\n",
    "    zero = predicted_seg[slice_to_plot,:,:,0] # Isolation of class 0, Background (kind of useless, it is the opposite of the \"all\")\n",
    "    first = predicted_seg[slice_to_plot,:,:,1] # Isolation of class 1, Core\n",
    "    second = predicted_seg[slice_to_plot,:,:,2] # Isolation of class 2, Edema\n",
    "    third = predicted_seg[slice_to_plot,:,:,3] # Isolation of class 3, Enhancing\n",
    "\n",
    "    convert_all = all.astype(np.float32) if all.dtype == np.float16 else all\n",
    "    convert_zero = zero.astype(np.float32) if zero.dtype == np.float16 else zero\n",
    "    convert_first = first.astype(np.float32) if first.dtype == np.float16 else first\n",
    "    convert_second = second.astype(np.float32) if second.dtype == np.float16 else second\n",
    "    convert_third = third.astype(np.float32) if third.dtype == np.float16 else third\n",
    "\n",
    "    # Plot Original segmentation & predicted segmentation\n",
    "    print(\"Patient number: \", random_sample)\n",
    "    fig, axstest = plt.subplots(1, 6, figsize=(25, 20))\n",
    "\n",
    "    # Original segmentation\n",
    "    axstest[0].imshow(seg, cmap, norm)\n",
    "    axstest[0].set_title('Original Segmentation')\n",
    "    \n",
    "    # Layers 1, 2, 3\n",
    "    axstest[1].imshow(convert_all)\n",
    "    axstest[1].set_title('Predicted Segmentation - all layers')\n",
    "    \n",
    "    # Layer 0\n",
    "    axstest[2].imshow(convert_zero)\n",
    "    axstest[2].set_title('Predicted Segmentation - layer 0')\n",
    "    \n",
    "    # Layer 1\n",
    "    axstest[3].imshow(convert_first)\n",
    "    axstest[3].set_title('Predicted Segmentation - layer 1')\n",
    "    \n",
    "    # Layer 2\n",
    "    axstest[4].imshow(convert_second)\n",
    "    axstest[4].set_title('Predicted Segmentation - layer 2')\n",
    "    \n",
    "    # Layer 3\n",
    "    axstest[5].imshow(convert_third)\n",
    "    axstest[5].set_title('Predicted Segmentation - layer 3')\n",
    "    \n",
    "    # Add space between subplots\n",
    "    plt.subplots_adjust(wspace=0.8)\n",
    "\n",
    "    plt.savefig(f'./plt/predict/{model_dir.split('./model/')[1]}/{random_sample}.png', dpi=300)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "cmap = mpl.colors.ListedColormap(['#440054', '#3b528b', '#18b880', '#e6d74f'])\n",
    "norm = mpl.colors.BoundaryNorm([-0.5, 0.5, 1.5, 2.5, 3.5], cmap.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predicted_segmentations(datas_test, 60, cmap, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predicted_segmentations(datas_test, 50, cmap, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predicted_segmentations(datas_test, 70, cmap, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_post_processed_segmentations(sample, slice_to_plot, cmap, norm):\n",
    "    \n",
    "    # Get path of this patient\n",
    "    sample_path = os.path.join(data_path_GLI_train_dir, sample, sample)\n",
    "    \n",
    "    # Predict patient's segmentation\n",
    "    predicted_seg = predict_segmentation(sample_path)\n",
    "   \n",
    "    # Load patient's original segmentation (Ground truth)\n",
    "    seg_path = sample_path + '-seg.nii.gz'\n",
    "    seg = nib.load(seg_path).get_fdata()\n",
    "    \n",
    "    # Resize original segmentation to the same dimensions of the predictions. (Add VOLUME_START_AT because original segmentation contains 155 slices vs only 75 for our prediction)\n",
    "    seg=cv2.resize(seg[:,:,slice_to_plot+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_NEAREST)\n",
    "    \n",
    "    # Fix 4 to 3 to have the same values as in the predicted segmentation, and then same colors\n",
    "    seg[seg==4] = 3\n",
    "    \n",
    "    # Remove background layer (0) from original segmentation\n",
    "    seg[seg==0] = np.nan\n",
    "    \n",
    "    # Post-processing\n",
    "    # Get indexes for each class of the highest probability pixels. Array will then contain only [0 1 2 3] instead of probabilities\n",
    "    my_pred = np.argmax(predicted_seg, axis=3)\n",
    "    my_pred = my_pred[slice_to_plot, :, :]\n",
    "\n",
    "    # Remove background layer (0) from post-processed predicted segmentation\n",
    "    # To fix 0 to np.nan, we need to convert array as a float\n",
    "    my_pred = my_pred.astype(float)\n",
    "    my_pred[my_pred == 0] = np.nan\n",
    "\n",
    "    # Remove background layer (0) from classical predicted segmentation\n",
    "    all = predicted_seg[slice_to_plot,:,:,1:4] \n",
    "\n",
    "    convert_all = all.astype(np.float32) if all.dtype == np.float16 else all\n",
    "    \n",
    "    # Plot Original segmentation & predicted segmentation without processing & predicted segmentation\n",
    "    print(\"Patient number: \", sample)\n",
    "    fig, axstest = plt.subplots(1, 3, figsize=(15, 10))\n",
    "\n",
    "    axstest[0].imshow(seg, cmap, norm)\n",
    "    axstest[0].set_title('Original Segmentation')\n",
    "    \n",
    "    axstest[1].imshow(convert_all)\n",
    "    axstest[1].set_title('Prediction (w/o post processing (layer 1,2,3)')\n",
    "    \n",
    "    axstest[2].imshow(my_pred, cmap, norm)\n",
    "    axstest[2].set_title('Prediction (w/ post processing (layer 1,2,3)')\n",
    "    \n",
    "    # Add space between subplots\n",
    "    plt.subplots_adjust(wspace=0.8)\n",
    "    plt.savefig(f'./plt/predict/{model_dir.split('./model/')[1]}/{sample}.png', dpi=300)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_post_processed_segmentations(sample = \"BraTS-GLI-00777-000\", slice_to_plot=60, cmap=cmap, norm=norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_post_processed_segmentations(sample = \"BraTS-GLI-00675-000\", slice_to_plot=50, cmap=cmap, norm=norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 - Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Evaluate the model on the test data\n",
    "test_generator = data_generators.get(DATA_GENERATOR_VERSION, DataGenerator_UnetV1)(TEST_PKL if DATA_GENERATOR_VERSION == 3 else datas_test)\n",
    "results = model.evaluate(test_generator, batch_size=200, callbacks= callbacks)\n",
    "\n",
    "descriptions = [\"Loss\", \"Accuracy\", \"MeanIOU\", \"Dice coefficient\", \"Precision\", \"Sensitivity\", \"Specificity\"]\n",
    "\n",
    "# Combine results list and descriptions list\n",
    "results_list = zip(results, descriptions)\n",
    "\n",
    "print(\"\\nModel evaluation on the test set:\")\n",
    "\n",
    "original_stdout = sys.stdout\n",
    "with open(f'{model_dir}/predict_result.log', 'w') as predict_log_file:\n",
    "    sys.stdout = predict_log_file\n",
    "\n",
    "    # Display each metric with its description\n",
    "    print(\"==================================\")\n",
    "    for i, (metric, description) in enumerate(results_list):\n",
    "        print(f\"{description} : {round(metric, 4)}\")\n",
    "    print(\"==================================\")\n",
    "\n",
    "sys.stdout = original_stdout"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aa84e851cfc8b4ce9eea0fba0960fb7c512de47d9926a3aadb9d11b047583128"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
