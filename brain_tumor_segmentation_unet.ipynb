{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 5px solid green; padding: 10px; background-color:rgb(224, 247, 206);\">\n",
    "    <b>⚡️ Information:</b>\n",
    "    Yihan's customized unet experiment\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0 - Set & Check available memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limited GPU memory usage to 18GB\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "MEMORY_SIZE = 18\n",
    "memory_limit = MEMORY_SIZE * 1024\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memory_limit)]  # Set limit to 15GB\n",
    "        )\n",
    "        print(f\"Limited GPU memory usage to {MEMORY_SIZE}GB\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: GPU:0\n",
      "Current Memory Usage: 0 bytes\n",
      "Peak Memory Usage: 0 bytes\n",
      "Memory growth for PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'): None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        device_name = f\"GPU:{i}\"  # Properly format the device name\n",
    "        details = tf.config.experimental.get_memory_info(device_name)\n",
    "        print(f\"GPU: {device_name}\")\n",
    "        print(f\"Current Memory Usage: {details['current']} bytes\")\n",
    "        print(f\"Peak Memory Usage: {details['peak']} bytes\")\n",
    "else:\n",
    "    print(\"No GPU devices found.\")\n",
    "\n",
    "for gpu in gpus:\n",
    "    print(f\"Memory growth for {gpu}: {tf.config.experimental.get_memory_growth(gpu)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from skimage.transform import rotate\n",
    "from skimage.util import montage\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import cv2\n",
    "import tensorflow\n",
    "import random\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "import numpy as np\n",
    "from keras.callbacks import CSVLogger\n",
    "import keras.backend as K\n",
    "import zipfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### paths, VOLUME_*, IMG_SIZE, N_CHANNELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a sample path (here we will take the first patient of the Training dataset)\n",
    "brats_index = 'BraTS-GLI-00077-000'\n",
    "brats_sample_path = f'../brain_tumor_seg/data/raw_data/GLI_train/{brats_index}/{brats_index}-'\n",
    "\n",
    "# Specify the root data path of training data\n",
    "data_path_GLI_train_dir = f'../brain_tumor_seg/data/raw_data/GLI_train'\n",
    "\n",
    "\n",
    "# Define selected slices range\n",
    "VOLUME_START_AT = 40 \n",
    "VOLUME_SLICES_PLUS = 76 \n",
    "TUMOR_RATIO_LOWER_BOUND = 0.15\n",
    "TUMOR_RATIO_UPPER_BOUND = 0.2\n",
    "\n",
    "# For DataGenerator\n",
    "IMG_SIZE = 256\n",
    "N_CHANNELS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not a Step - Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 4 MRI modalities and the segmentation located in the patient's path using the nibabel library\n",
    "t1_img_sample=nib.load(brats_sample_path + 't1n.nii.gz')\n",
    "t1ce_img_sample=nib.load(brats_sample_path + 't1c.nii.gz')\n",
    "t2_img_sample=nib.load(brats_sample_path + 't2w.nii.gz')\n",
    "flair_img_sample=nib.load(brats_sample_path + 't2f.nii.gz')\n",
    "seg_img_sample=nib.load(brats_sample_path + 'seg.nii.gz')\n",
    "\n",
    "# Get the image data\n",
    "t1_data_sample = t1_img_sample.get_fdata()\n",
    "t1ce_data_sample = t1ce_img_sample.get_fdata()\n",
    "t2_data_sample = t2_img_sample.get_fdata()\n",
    "flair_data_sample = flair_img_sample.get_fdata()\n",
    "seg_data_sample = seg_img_sample.get_fdata()\n",
    "\n",
    "# Plot the 100th slice of the 4 RMI modalities and the segmentation\n",
    "slice_nb = 100\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(20,20))\n",
    "axs[0].imshow(t1_data_sample[:,:,slice_nb], cmap=\"gray\")\n",
    "axs[0].set_title('T1')\n",
    "axs[1].imshow(t1ce_data_sample[:,:,slice_nb], cmap=\"gray\")\n",
    "axs[1].set_title('T1CE')\n",
    "axs[2].imshow(t2_data_sample[:,:,slice_nb], cmap=\"gray\")\n",
    "axs[2].set_title('T2')\n",
    "axs[3].imshow(flair_data_sample[:,:,slice_nb], cmap=\"gray\")\n",
    "axs[3].set_title('FLAIR')\n",
    "axs[4].imshow(seg_data_sample[:,:,slice_nb], cmap=\"gray\")\n",
    "axs[4].set_title('Segmentation')\n",
    "plt.savefig(f'./plt/seg_classes_{brats_index}.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a RMI modality through all planes\n",
    "slice_nb = 100\n",
    "\n",
    "fig, axs2 = plt.subplots(1, 3, figsize=(10,10))\n",
    "\n",
    "# Apply a 90° rotation with an automatic resizing, otherwise the display is less obvious to analyze\n",
    "axs2[0].imshow(rotate(t1_data_sample[slice_nb,:,:], 90, resize=True), cmap=\"gray\")\n",
    "axs2[0].set_title('T1 - Sagittal View')\n",
    "\n",
    "axs2[1].imshow(rotate(t1_data_sample[:,slice_nb,:], 90, resize=True), cmap=\"gray\")\n",
    "axs2[1].set_title('T1 - Coronal View')\n",
    "\n",
    "axs2[2].imshow(t1_data_sample[:,:,slice_nb], cmap=\"gray\")\n",
    "axs2[2].set_title('T1 - Axial View')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize = (15,15))\n",
    "ax1.imshow(rotate(montage(t1_data_sample[:,:,:]), 90, resize=True), cmap ='gray')\n",
    "\n",
    "# montage allows us to concatenate multiple images of the same size horizontally and vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all slices of a segmentation\n",
    "fig, ax1 = plt.subplots(1, 1, figsize = (15,15))\n",
    "ax1.imshow(rotate(montage(seg_data_sample[:,:,:]), 90, resize=True), cmap ='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize = (15,15))\n",
    "ax1.imshow(rotate(montage(t1_data_sample[60:135,:,:]), 90, resize=True), cmap ='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a segmantation\n",
    "some_seg_img = nib.load(f'{brats_sample_path}seg.nii.gz').get_fdata()\n",
    "\n",
    "cmap = mpl.colors.ListedColormap(['#440054', '#3b528b', '#18b880', '#e6d74f'])\n",
    "norm = mpl.colors.BoundaryNorm([-0.5, 0.5, 1.5, 2.5, 3.5], cmap.N)\n",
    "\n",
    "plt.imshow(some_seg_img[100,:,:], cmap=cmap, norm=norm)\n",
    "plt.title(brats_index)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_samples = [os.path.join(data_path_GLI_train_dir, sample, f\"{sample}-seg.nii.gz\") for sample in os.listdir(data_path_GLI_train_dir) if not sample.endswith('.csv')]\n",
    "\n",
    "saved_values = []\n",
    "max_nb_values = 0\n",
    "for sample in seg_samples:\n",
    "    seg_img_sample = nib.load(sample).get_fdata()\n",
    "    unique_values = np.unique(seg_img_sample)\n",
    "    nb_unique_values = len(np.unique(seg_img_sample))\n",
    "    \n",
    "    if nb_unique_values > max_nb_values:\n",
    "        max_nb_values = nb_unique_values\n",
    "        saved_values = unique_values\n",
    "\n",
    "print(f\"Maximum number of values in all segmentation images: {max_nb_values}\")\n",
    "print(f\"Values: {saved_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletion of class 0\n",
    "seg_0 = some_seg_img.astype(float).copy()\n",
    "seg_0[seg_0 != 0] = np.nan\n",
    "\n",
    "# Isolation of class 1\n",
    "seg_1 = some_seg_img.astype(float).copy()\n",
    "seg_1[seg_1 != 1] = np.nan\n",
    "\n",
    "# Isolation of class 2\n",
    "seg_2 = some_seg_img.astype(float).copy()\n",
    "seg_2[seg_2 != 2] = np.nan\n",
    "\n",
    "# Isolation of class 4\n",
    "seg_3 = some_seg_img.astype(float).copy()\n",
    "seg_3[seg_3 != 4] = np.nan\n",
    "\n",
    "# Define legend\n",
    "class_names = ['class 0', 'class 1', 'class 2', 'class 3']\n",
    "legend = [plt.Rectangle((0, 0), 1, 1, color=cmap(i), label=class_names[i]) for i in range(len(class_names))]\n",
    "\n",
    "fig, axs3 = plt.subplots(1, 5, figsize=(15, 15))\n",
    "\n",
    "axs3[0].imshow(some_seg_img[100,:,:], cmap=cmap, norm=norm)\n",
    "axs3[0].set_title('Original Segmentation')\n",
    "axs3[0].legend(handles=legend, loc='upper right')\n",
    "\n",
    "axs3[1].imshow(seg_0[100,:,:], cmap=cmap, norm=norm)\n",
    "axs3[1].set_title('[Not Tumor] class 0')\n",
    "\n",
    "axs3[2].imshow(seg_1[100,:,:], cmap=cmap, norm=norm)\n",
    "axs3[2].set_title('[NCR] class 1')\n",
    "\n",
    "axs3[3].imshow(seg_2[100,:,:], cmap=cmap, norm=norm)\n",
    "axs3[3].set_title('[ED] class 2')\n",
    "\n",
    "axs3[4].imshow(seg_3[100,:,:], cmap=cmap, norm=norm)\n",
    "axs3[4].set_title('[ET] class 3')\n",
    "\n",
    "# Save the figure to a file\n",
    "plt.savefig('segmentation_classes.png', dpi=300)  # Saves the image as 'segmentation_classes.png'\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, counts = np.unique(some_seg_img, return_counts=True)\n",
    "print(f'distribution of 4 classes: {counts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modality shape\n",
    "print(f'modality shape: {t1_data_sample.shape}')\n",
    "\n",
    "# Segmentation shape\n",
    "print(f'segmentation shape: {seg_data_sample.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Load images and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 1251\n"
     ]
    }
   ],
   "source": [
    "# Retrieve all samples from path with listdir(). This method lists of all files + directories in the specified directory.\n",
    "all_datas = os.listdir(data_path_GLI_train_dir)\n",
    "print(\"Number of samples:\", len(all_datas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train length: 850\n",
      "Validation length: 251\n",
      "Test length: 150\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into train and validation sets\n",
    "datas_train, datas_val = train_test_split(all_datas, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the train set into the real train set and in a test set \n",
    "datas_train, datas_test = train_test_split(datas_train, test_size=0.15, random_state=42)\n",
    "\n",
    "# Print data distribution (Train: 68%, Test: 12%, Val: 20%)\n",
    "print(f\"Train length: {len(datas_train)}\")\n",
    "print(f\"Validation length: {len(datas_val)}\")\n",
    "print(f\"Test length: {len(datas_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: keras\n",
      "Version: 2.7.0\n",
      "Summary: Deep learning for humans.\n",
      "Home-page: https://keras.io/\n",
      "Author: Keras team\n",
      "Author-email: keras-users@googlegroups.com\n",
      "License: Apache 2.0\n",
      "Location: /home/cbel/Desktop/YIHAN/venv/lib/python3.8/site-packages\n",
      "Requires: \n",
      "Required-by: tensorflow\n",
      "---\n",
      "Name: tensorflow\n",
      "Version: 2.7.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /home/cbel/Desktop/YIHAN/venv/lib/python3.8/site-packages\n",
      "Requires: opt-einsum, astunparse, grpcio, typing-extensions, tensorboard, absl-py, wrapt, keras-preprocessing, tensorflow-io-gcs-filesystem, h5py, protobuf, wheel, six, tensorflow-estimator, google-pasta, numpy, libclang, keras, gast, termcolor, flatbuffers\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show keras tensorflow # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "tensorflow version: 2.7.0\n",
      "is built with CUDA: True\n",
      "GPU details: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU is available.\n",
      "===============================\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"===============================\")\n",
    "print(f'tensorflow version: {tf.__version__}')  # Should print 2.7.0\n",
    "print(f'is built with CUDA: {tf.test.is_built_with_cuda()}')  # Should return True\n",
    "print(f'GPU details: {tf.config.list_physical_devices(\"GPU\")}')  # Should show GPU details\n",
    "\n",
    "# Check if TensorFlow can detect a GPU\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available.\")\n",
    "else:\n",
    "    print(\"GPU is not available.\")\n",
    "\n",
    "print(\"===============================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip if no need - combine existing pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import csv\n",
    "\n",
    "DATA_1_DIR = 'processed_data_0.05_0.1'\n",
    "DATA_2_DIR = 'processed_data_0.1_0.25'\n",
    "COMBINED_DATA_DIR = 'processed_data_0.05_0.25'\n",
    "SET = 'test'\n",
    "\n",
    "\n",
    "with open(f'./data/{DATA_1_DIR}/processed_{SET}_data.pkl', 'rb') as f:\n",
    "    data1 = pickle.load(f)\n",
    "with open(f'./data/{DATA_2_DIR}/processed_{SET}_data.pkl', 'rb') as f:\n",
    "    data2 = pickle.load(f)\n",
    "combined_data = data1.copy()\n",
    "combined_data.update(data2)\n",
    "with open(f'./data/{COMBINED_DATA_DIR}/processed_{SET}_data.pkl', 'wb') as f:\n",
    "    pickle.dump(combined_data, f)\n",
    "\n",
    "\n",
    "with open(f'./data/{DATA_1_DIR}/{SET}_data_info.csv', 'r') as csv1, open(f'./data/{DATA_2_DIR}/{SET}_data_info.csv', 'r') as csv2:\n",
    "    reader1 = csv.reader(csv1)\n",
    "    reader2 = csv.reader(csv2)\n",
    "\n",
    "    with open(f'./data/{COMBINED_DATA_DIR}/{SET}_data_info.csv', 'w', newline='') as csv_out:\n",
    "        writer = csv.writer(csv_out)\n",
    "        for row in reader1:\n",
    "            writer.writerow(row)\n",
    "        next(reader2)\n",
    "        for row in reader2:\n",
    "            writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step * Crop Nii files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step * - 1: Set up params & crop method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import nibabel as nib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "total_slices_dict = {\n",
    "    \"train\": 0,\n",
    "    \"val\": 0,\n",
    "    \"test\": 0\n",
    "}\n",
    "\n",
    "def preprocess_and_save(data_list, save_path, log_path, tumor_ratio_lower_bound, tumor_ratio_upper_bound):\n",
    "    processed_data = {'X': [], 'y': []}\n",
    "    slice_info = {}  # Dictionary to store slice information for each NIfTI\n",
    "\n",
    "    with open(log_path, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(['NIfTI ID', 'Slice Index', 'Tumor Ratio', 'Brain Area'])\n",
    "\n",
    "        total_slices = 0\n",
    "\n",
    "        for i in data_list:\n",
    "            data_path = os.path.join(data_path_GLI_train_dir, i, i)\n",
    "            t1ce_path = data_path + '-t1c.nii.gz'\n",
    "            flair_path = data_path + '-t2f.nii.gz'\n",
    "            seg_path = data_path + '-seg.nii.gz'\n",
    "            \n",
    "            t1ce = nib.load(t1ce_path).get_fdata()\n",
    "            flair = nib.load(flair_path).get_fdata()\n",
    "            seg = nib.load(seg_path).get_fdata()\n",
    "\n",
    "            slice_info[i] = []  # Initialize list for each NIfTI\n",
    "\n",
    "            for j in range(VOLUME_SLICES_PLUS):\n",
    "                slice_seg = seg[:, :, j + VOLUME_START_AT]\n",
    "                slice_flair = flair[:, :, j + VOLUME_START_AT]\n",
    "                tumor_area = np.sum(slice_seg > 0)\n",
    "                brain_area = np.sum(slice_flair > 0)  # Use non-zero pixels in FLAIR as brain area\n",
    "\n",
    "                # Avoid division by zero\n",
    "                if brain_area == 0:\n",
    "                    continue\n",
    "\n",
    "                tumor_percentage = tumor_area / brain_area\n",
    "\n",
    "                if tumor_ratio_lower_bound < tumor_percentage <= tumor_ratio_upper_bound:\n",
    "                    X_slice = np.zeros((IMG_SIZE, IMG_SIZE, N_CHANNELS))\n",
    "                    X_slice[:, :, 0] = cv2.resize(slice_flair, (IMG_SIZE, IMG_SIZE))\n",
    "                    X_slice[:, :, 1] = cv2.resize(t1ce[:, :, j + VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n",
    "                    processed_data['X'].append(X_slice)\n",
    "                    processed_data['y'].append(slice_seg)\n",
    "                    slice_info[i].append(j + VOLUME_START_AT)  # Record the slice index\n",
    "\n",
    "                    # Write slice information to CSV file\n",
    "                    csv_writer.writerow([i, j + VOLUME_START_AT, round(tumor_percentage, 4), brain_area])\n",
    "                    total_slices += 1\n",
    "\n",
    "        total_slices_dict[log_path.split('/')[-1].split('_')[0]] = total_slices\n",
    "\n",
    "    # Save the processed data\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(processed_data, f)\n",
    "\n",
    "def count_rows_in_csv(file_path):\n",
    "    with open(file_path, mode='r', newline='', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader, None)\n",
    "        row_count = sum(1 for row in reader)\n",
    "    return row_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "def append_to_csv(file_path, data, header=None):\n",
    "    file_exists = os.path.isfile(file_path)\n",
    "\n",
    "    with open(file_path, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if header and not file_exists:\n",
    "            writer.writerow(header)\n",
    "        writer.writerows(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step * - 2: Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tumor ratio: 0.15 ~ 0.2\n",
      "dir processed_data existed at ./data/dimension_256/processed_data_0.15_0.2.\n",
      "train: 7678 slices\n",
      "val: 2139 slices\n",
      "test: 1382 slices\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import gc\n",
    "\n",
    "processed_data_dir_root = f'./data/dimension_{IMG_SIZE}/processed_data_{TUMOR_RATIO_LOWER_BOUND}_{TUMOR_RATIO_UPPER_BOUND}'\n",
    "processed_data_lists_csv = f'./data/dimension_{IMG_SIZE}/processed_data_lists.csv'\n",
    "processed_data_lists_header = ['tumor_ratio_lower_bound', 'tumor_ratio_upper_bound', 'train_slices', 'val_slices', 'test_slices', 'generated_timestamp']\n",
    "\n",
    "print(f'tumor ratio: {TUMOR_RATIO_LOWER_BOUND} ~ {TUMOR_RATIO_UPPER_BOUND}')\n",
    "\n",
    "if not os.path.exists(processed_data_dir_root):\n",
    "    os.makedirs(processed_data_dir_root)\n",
    "    print(\"dir processed_data created.\")\n",
    "\n",
    "    preprocess_and_save(datas_train, f'{processed_data_dir_root}/processed_train_data.pkl', f'{processed_data_dir_root}/train_data_info.csv', TUMOR_RATIO_LOWER_BOUND, TUMOR_RATIO_UPPER_BOUND)\n",
    "    gc.collect()\n",
    "    preprocess_and_save(datas_val, f'{processed_data_dir_root}/processed_val_data.pkl', f'{processed_data_dir_root}/val_data_info.csv', TUMOR_RATIO_LOWER_BOUND, TUMOR_RATIO_UPPER_BOUND)\n",
    "    gc.collect()\n",
    "    preprocess_and_save(datas_test, f'{processed_data_dir_root}/processed_test_data.pkl', f'{processed_data_dir_root}/test_data_info.csv', TUMOR_RATIO_LOWER_BOUND, TUMOR_RATIO_UPPER_BOUND)\n",
    "    gc.collect()\n",
    "\n",
    "    processed_data_lists_data = [\n",
    "        [TUMOR_RATIO_LOWER_BOUND, TUMOR_RATIO_UPPER_BOUND, total_slices_dict[\"train\"], total_slices_dict[\"val\"], total_slices_dict[\"test\"], datetime.now().strftime(\"%b-%d_%H-%M-%S\")]\n",
    "    ]\n",
    "    append_to_csv(processed_data_lists_csv, processed_data_lists_data, processed_data_lists_header)\n",
    "\n",
    "else:\n",
    "    print(f'dir processed_data existed at {processed_data_dir_root}.')\n",
    "\n",
    "# set the data info to params\n",
    "TRAIN_PKL = f'{processed_data_dir_root}/processed_train_data.pkl'\n",
    "VAL_PKL = f'{processed_data_dir_root}/processed_val_data.pkl'\n",
    "TEST_PKL = f'{processed_data_dir_root}/processed_test_data.pkl'\n",
    "TRAIN_PKL_CSV = f'{processed_data_dir_root}/train_data_info.csv'\n",
    "VAL_PKL_CSV = f'{processed_data_dir_root}/val_data_info.csv'\n",
    "TEST_PKL_CSV = f'{processed_data_dir_root}/test_data_info.csv'\n",
    "total_slices_dict.update({\n",
    "    \"train\": count_rows_in_csv(TRAIN_PKL_CSV),\n",
    "    \"val\": count_rows_in_csv(VAL_PKL_CSV),\n",
    "    \"test\": count_rows_in_csv(TEST_PKL_CSV)\n",
    "})\n",
    "\n",
    "print(f'train: {total_slices_dict[\"train\"]} slices')\n",
    "print(f'val: {total_slices_dict[\"val\"]} slices')\n",
    "print(f'test: {total_slices_dict[\"test\"]} slices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Set up training compoenents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When generating `DataGenerator`**:\n",
    "- We use a data generator to be able to process and send our data to our neural network (since all our images cannot be stored in memory at once).\n",
    "- For each epoch (single pass of the entire training dataset through a neural network), the model will receive 250 samples (those contained in our training dataset).\n",
    "- For each sample, the model will have to analyze 150 slices (since there are two modalities, and 75(VOLUME_SLICES) selected slices for both of them), received in a (128, 128) shape, as an X array of a (128, 128, 75, 2) shape. This array will be provided with the ground truth segmentation of the patient, which will be One-Hot encoded and will then have a (75, 128, 128, 4) shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 1: DataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-1-1 DataGenerator_UnetV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# DataGenerator from Rastislav's notebook, https://www.kaggle.com/code/rastislav/3d-mri-brain-tumor-segmentation-u-net\n",
    "\n",
    "class DataGenerator_UnetV1(keras.utils.all_utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = N_CHANNELS, shuffle=True):\n",
    "        print('------ usging Data Generator V1 ------')\n",
    "        'Initialization'\n",
    "        self.dim = dim # Resized image dimensions (128 x 128)\n",
    "        self.batch_size = batch_size #  Number of images to load each time\n",
    "        self.list_IDs = list_IDs # Patients IDs\n",
    "        self.n_channels = n_channels # Number of channels (T1CE + FLAIR)\n",
    "        self.shuffle = shuffle # Indicates if data is shuffled for each epoch\n",
    "        self.on_epoch_end() # Updates indexes after each epoch\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Load & Generate data\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        'Generates data containing batch_size samples'\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size*VOLUME_SLICES_PLUS, *self.dim, self.n_channels))\n",
    "        y = np.zeros((self.batch_size*VOLUME_SLICES_PLUS, 240, 240))\n",
    "\n",
    "        # Generate data\n",
    "        for c, i in enumerate(Batch_ids):\n",
    "            \n",
    "            # Get path of each RMI modality and the segmentation\n",
    "            data_path = os.path.join(data_path_GLI_train_dir, i, i)\n",
    "            t1ce_path = data_path + '-t1c.nii.gz'\n",
    "            flair_path = data_path + '-t2f.nii.gz'\n",
    "            seg_path = data_path + '-seg.nii.gz'\n",
    "            #t1_path = sample_path + '_t1.nii.gz'\n",
    "            #t2_path = sample_path + '_t2.nii.gz'\n",
    "            \n",
    "            # Extract the data from these paths\n",
    "            t1ce = nib.load(t1ce_path).get_fdata()\n",
    "            flair = nib.load(flair_path).get_fdata()\n",
    "            seg = nib.load(seg_path).get_fdata()\n",
    "            #t1 = nib.load(t1_paths).get_fdata()\n",
    "            #t2 = nib.load(t2_path).get_fdata()\n",
    "        \n",
    "            for j in range(VOLUME_SLICES_PLUS):\n",
    "                 X[j +VOLUME_SLICES_PLUS*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n",
    "                 X[j +VOLUME_SLICES_PLUS*c,:,:,1] = cv2.resize(t1ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "                 y[j +VOLUME_SLICES_PLUS*c] = seg[:,:,j+VOLUME_START_AT]\n",
    "                    \n",
    "        # Masks / Segmentations\n",
    "        y[y==4] = 3\n",
    "        mask = tensorflow.one_hot(y, 4)\n",
    "        Y = tensorflow.image.resize(mask, (IMG_SIZE, IMG_SIZE))\n",
    "        \n",
    "        # Scale data between 0 and 1 (since the minimum value in the data is 0)\n",
    "        return X/np.max(X), Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-1-2 DataGenerator_UnetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# DataGenerator from Rastislav's notebook, https://www.kaggle.com/code/rastislav/3d-mri-brain-tumor-segmentation-u-net\n",
    "\n",
    "class DataGenerator_UnetV2(keras.utils.all_utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = N_CHANNELS, shuffle=True):\n",
    "        print('------ usging Data Generator V2 ------')\n",
    "        'Initialization'\n",
    "        self.dim = dim # Resized image dimensions (128 x 128)\n",
    "        self.batch_size = batch_size #  Number of images to load each time\n",
    "        self.list_IDs = list_IDs # Patients IDs\n",
    "        self.n_channels = n_channels # Number of channels (T1CE + FLAIR)\n",
    "        self.shuffle = shuffle # Indicates if data is shuffled for each epoch\n",
    "        self.on_epoch_end() # Updates indexes after each epoch\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Load & Generate data\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        'Generates data containing batch_size samples'\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size*VOLUME_SLICES_PLUS, *self.dim, self.n_channels))\n",
    "        y = np.zeros((self.batch_size*VOLUME_SLICES_PLUS, 240, 240))\n",
    "\n",
    "        # Generate data\n",
    "        for c, i in enumerate(Batch_ids):\n",
    "            \n",
    "            # Get path of each RMI modality and the segmentation\n",
    "            data_path = os.path.join(data_path_GLI_train_dir, i, i)\n",
    "            t1ce_path = data_path + '-t1c.nii.gz'\n",
    "            flair_path = data_path + '-t2f.nii.gz'\n",
    "            seg_path = data_path + '-seg.nii.gz'\n",
    "            #t1_path = sample_path + '_t1.nii.gz'\n",
    "            #t2_path = sample_path + '_t2.nii.gz'\n",
    "            \n",
    "            # Extract the data from these paths\n",
    "            t1ce = nib.load(t1ce_path).get_fdata()\n",
    "            flair = nib.load(flair_path).get_fdata()\n",
    "            seg = nib.load(seg_path).get_fdata()\n",
    "            #t1 = nib.load(t1_paths).get_fdata()\n",
    "            #t2 = nib.load(t2_path).get_fdata()\n",
    "        \n",
    "            for j in range(VOLUME_SLICES_PLUS):\n",
    "                 X[j +VOLUME_SLICES_PLUS*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "                 y[j +VOLUME_SLICES_PLUS*c] = seg[:,:,j+VOLUME_START_AT]\n",
    "                    \n",
    "        # Masks / Segmentations\n",
    "        y[y==4] = 3\n",
    "        mask = tensorflow.one_hot(y, 4)\n",
    "        Y = tensorflow.image.resize(mask, (IMG_SIZE, IMG_SIZE))\n",
    "        \n",
    "        # Scale data between 0 and 1 (since the minimum value in the data is 0)\n",
    "        return X/np.max(X), Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-1-3 DataGenerator_UnetV3_count_image_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "class DataGenerator_UnetV3_count_image_ratio(keras.utils.all_utils.Sequence):\n",
    "    def __init__(self, data_path, batch_size=1, shuffle=True):\n",
    "        print('------ usging Data Generator V3: use crop NIIs ------')\n",
    "        with open(data_path, 'rb') as f:\n",
    "            self.data = pickle.load(f)\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(self.data['X']))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.data['X']) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        X_batch = [self.data['X'][k] for k in indexes]\n",
    "        y_batch = [self.data['y'][k] for k in indexes]\n",
    "\n",
    "        y_batch = np.array(y_batch)\n",
    "        y_batch[y_batch == 4] = 3\n",
    "        mask = tensorflow.one_hot(y_batch, 4)\n",
    "        Y = tensorflow.image.resize(mask, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        return np.array(X_batch) / np.max(X_batch), Y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 -2: U-Net model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-2-1 U-Net v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net implementation for BraTS 2019 by Naomi Fridman, https://naomi-fridman.medium.com/multi-class-image-segmentation-a5cc671e647a\n",
    "def unet_v1(inputs, ker_init, dropout):\n",
    "    print('****** using U-Net V1 ******')\n",
    "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(inputs)\n",
    "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv1)\n",
    "    \n",
    "    pool = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool)\n",
    "    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv2)\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv3)\n",
    "    \n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool4)\n",
    "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv5)\n",
    "    drop5 = Dropout(dropout)(conv5)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = 2)(drop5))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = 2)(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = 2)(conv8))\n",
    "    merge9 = concatenate([conv,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n",
    "    \n",
    "    up = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = 2)(conv9))\n",
    "    merge = concatenate([conv1,up], axis = 3)\n",
    "    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge)\n",
    "    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n",
    "    \n",
    "    conv10 = Conv2D(4, 1, activation = 'softmax')(conv)\n",
    "    \n",
    "    return Model(inputs = inputs, outputs = conv10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-2-2: U-Net V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_v2(inputs, ker_init, dropout=0.5):\n",
    "    print('****** using U-Net V2 ******')\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv1)\n",
    "\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv2)\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv3)\n",
    "    \n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv4)\n",
    "    drop4 = Dropout(dropout)(conv4)\n",
    "    \n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv5)\n",
    "    drop5 = Dropout(dropout)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n",
    "\n",
    "    conv10 = Conv2D(4, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    return Model(inputs = inputs, outputs = conv10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 3: Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_dice_loss(y_true, y_pred, smooth=1e-6):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[0,1,2])\n",
    "    union = K.sum(y_true, axis=[0,1,2]) + K.sum(y_pred, axis=[0,1,2])\n",
    "    dice_loss = 1 - K.mean((2. * intersection + smooth) / (union + smooth))\n",
    "    return dice_loss\n",
    "\n",
    "def focal_loss(alpha=0.25, gamma=2.0):\n",
    "    def loss(y_true, y_pred):\n",
    "        ce = tf.keras.losses.CategoricalCrossentropy()(y_true, y_pred)\n",
    "        pt = tf.exp(-ce)  # 計算 p_t\n",
    "        focal_loss = alpha * (1 - pt) ** gamma * ce\n",
    "        return focal_loss\n",
    "    return loss\n",
    "\n",
    "def focal_dice_loss(y_true, y_pred):\n",
    "    return focal_loss()(y_true, y_pred) + categorical_dice_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 4: Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metric between the predicted segmentation and the ground truth\n",
    "def dice_coef(y_true, y_pred, smooth=1.0):\n",
    "    class_num = 4\n",
    "    for i in range(class_num):\n",
    "        y_true_f = K.flatten(y_true[:,:,:,i])\n",
    "        y_pred_f = K.flatten(y_pred[:,:,:,i])\n",
    "        intersection = K.sum(y_true_f * y_pred_f)\n",
    "        loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n",
    "        if i == 0:\n",
    "            total_loss = loss\n",
    "        else:\n",
    "            total_loss = total_loss + loss\n",
    "    total_loss = total_loss / class_num\n",
    "    return total_loss\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())\n",
    "\n",
    "########################### my customized metrics ###########################\n",
    "\n",
    "def sensibility(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    false_positives = K.sum(K.round(K.clip(y_pred - y_true, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    # Calculate the sensibility\n",
    "    sensibility = 1 - (false_positives / (true_positives + possible_positives + K.epsilon()))\n",
    "    # Check for NaN or Inf values and return NaN if True\n",
    "    sensibility = tf.where(tf.math.is_nan(sensibility) | tf.math.is_inf(sensibility),\n",
    "                           tf.constant(float('NaN')),\n",
    "                           sensibility)\n",
    "    return sensibility\n",
    "\n",
    "\n",
    "def jaccard(y_true, y_pred):\n",
    "    # True positives, false positives, false negatives\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    false_positives = K.sum(K.round(K.clip(y_pred - y_true, 0, 1)))\n",
    "    false_negatives = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)))\n",
    "    # Calculate Jaccard index\n",
    "    denominator = true_positives + false_positives + false_negatives + K.epsilon()  # Add epsilon to avoid division by zero\n",
    "    result = true_positives / denominator\n",
    "    # Handle NaN or Inf cases\n",
    "    result = K.switch(K.is_inf(result) | K.is_nan(result), K.constant(float('NaN')), result)\n",
    "    return result\n",
    "\n",
    "\n",
    "# Hausdorff distance (approximation for use in Keras)\n",
    "def hausdorff(y_true, y_pred):\n",
    "    # Flatten the coordinates of the true and predicted segmentation masks\n",
    "    y_true_flat = K.flatten(y_true)\n",
    "    y_pred_flat = K.flatten(y_pred)\n",
    "    # Compute the Euclidean distance between every pair of points\n",
    "    dist_matrix = K.square(y_true_flat - y_pred_flat)\n",
    "    # Get the maximum distance in both directions (directed Hausdorff)\n",
    "    directed_hausdorff_1 = K.max(dist_matrix, axis=1)  # From y_true to y_pred\n",
    "    directed_hausdorff_2 = K.max(dist_matrix, axis=0)  # From y_pred to y_true\n",
    "    # Take the maximum of both directed Hausdorff distances\n",
    "    hausdorff_dist = K.maximum(directed_hausdorff_1, directed_hausdorff_2)\n",
    "    # Handle NaN or Inf values by replacing them with NaN (if needed)\n",
    "    hausdorff_dist = K.switch(K.is_inf(hausdorff_dist) | K.is_nan(hausdorff_dist), K.constant(float('NaN')), hausdorff_dist)\n",
    "    return hausdorff_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 5: Define training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input\n",
    "\n",
    "MODEL_VERSION = 1\n",
    "DATA_GENERATOR_VERSION = 3\n",
    "\n",
    "EPOCHS = 200\n",
    "STEPS_PER_EPOCH = len(datas_train)\n",
    "\n",
    "INPUT_LAYER = Input((IMG_SIZE, IMG_SIZE, N_CHANNELS))\n",
    "KER_INIT = 'he_normal'\n",
    "DROPOUT = 0.2\n",
    "LEARNING_RATE = 1e-4\n",
    "# LOSS_FUNCTION = \"categorical_crossentropy\"\n",
    "LOSS_FUNCTION = focal_dice_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 6: Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** using U-Net V1 ******\n"
     ]
    }
   ],
   "source": [
    "# Build and compile the model\n",
    "model_builders = {\n",
    "    1: unet_v1,\n",
    "    2: unet_v2\n",
    "}\n",
    "model = model_builders.get(MODEL_VERSION, unet_v1)(inputs=INPUT_LAYER, ker_init=KER_INIT, dropout=DROPOUT)\n",
    "\n",
    "model.compile(loss=LOSS_FUNCTION, optimizer=tensorflow.keras.optimizers.Adam(learning_rate=LEARNING_RATE), metrics = ['accuracy',tensorflow.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 7: Set up DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ usging Data Generator V3: use crop NIIs ------\n",
      "------ usging Data Generator V3: use crop NIIs ------\n"
     ]
    }
   ],
   "source": [
    "data_generators = {\n",
    "    1: DataGenerator_UnetV1,\n",
    "    2: DataGenerator_UnetV2,\n",
    "    3: DataGenerator_UnetV3_count_image_ratio\n",
    "}\n",
    "\n",
    "training_generator = data_generators.get(DATA_GENERATOR_VERSION, DataGenerator_UnetV1)(TRAIN_PKL if DATA_GENERATOR_VERSION == 3 else datas_train)\n",
    "valid_generator = data_generators.get(DATA_GENERATOR_VERSION, DataGenerator_UnetV1)(VAL_PKL if DATA_GENERATOR_VERSION == 3 else datas_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 8: Do the GC and check the GPU and memory status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: GPU:0\n",
      "Current Memory Usage: 31040804 bytes\n",
      "Peak Memory Usage: 37721124 bytes\n",
      "Memory growth for PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'): None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        device_name = f\"GPU:{i}\"  # Properly format the device name\n",
    "        details = tf.config.experimental.get_memory_info(device_name)\n",
    "        print(f\"GPU: {device_name}\")\n",
    "        print(f\"Current Memory Usage: {details['current']} bytes\")\n",
    "        print(f\"Peak Memory Usage: {details['peak']} bytes\")\n",
    "else:\n",
    "    print(\"No GPU devices found.\")\n",
    "\n",
    "for gpu in gpus:\n",
    "    print(f\"Memory growth for {gpu}: {tf.config.experimental.get_memory_growth(gpu)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed Precision Training\n",
    "# from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "# policy = mixed_precision.Policy('mixed_float16')\n",
    "# mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 9: Set up callbacks\n",
    "\n",
    "Callbacks are functions that can be executed during the training process. \n",
    "\n",
    "We will use three callbacks:\n",
    "\n",
    "- **ReduceLROnPlateau**: This callback reduces the learning rate when a metric has stopped improving (validation loss here). The learning rate is reduced by a factor of 0.2, the patience is set to 2 epochs, and the minimum learning rate is set to 0.000001.\n",
    "\n",
    "- **ModelCheckpoint**: Saves the best model weights (model that has obtained the lowest validation loss during the different epochs). Saving a model allows us to reuse it later or to share it, without having to retrain it from scratch. This will save us time and resources!\n",
    "\n",
    "- **CSVLogger**: Add metrics to a CSV file, which is named *training.log* (parameter `append` is set to `False` so the file is overwritten if it already exists). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dir ./model/model_v1_Mar-23_22-21-34 created.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Generate timestamp for filenames\n",
    "start_train_timestamp = datetime.now().strftime(\"%b-%d_%H-%M-%S\")\n",
    "\n",
    "model_dir = f'./model/model_v{MODEL_VERSION}_{start_train_timestamp}'\n",
    "\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    print(f\"Model dir {model_dir} created.\")\n",
    "else:\n",
    "    print(f\"Model dir {model_dir} existed.\")\n",
    "\n",
    "# Define file paths with timestamps\n",
    "training_log_filename = f\"{model_dir}/training-{start_train_timestamp}.log\"\n",
    "model_checkpoint_path = f\"{model_dir}/model_epoch{{epoch:02d}}-val_loss{{val_loss:.6f}}_{start_train_timestamp}.m5\"\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.000001, verbose=1),\n",
    "    \n",
    "    keras.callbacks.ModelCheckpoint(filepath=model_checkpoint_path, verbose=1, save_best_only=True, save_weights_only=True),\n",
    "\n",
    "    CSVLogger(training_log_filename, separator=',', append=False)  # Save logs with timestamp\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Train & Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - 1: log all cell outputs during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "model name: unet_v1\n",
      "epochs: 200\n",
      "steps_per_epoch: 850\n",
      "dimension: 256\n",
      "n_channels: 2\n",
      "input layer: KerasTensor(type_spec=TensorSpec(shape=(None, 256, 256, 2), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
      "kernel init: he_normal\n",
      "dropout: 0.2\n",
      "learning rate: 0.0001\n",
      "loss function: <function focal_dice_loss at 0x7f55634765e0>\n",
      "train cases: 850\n",
      "train slices: 7678\n",
      "validation cases: 251\n",
      "val slices: 2139\n",
      "slice index: 40 ~ 116\n",
      "tumor ratio: 0.15 ~ 0.2\n",
      "test cases: 150\n",
      "start training at: Mar-23_22-21-34\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(f'----------')\n",
    "print(f'model name: {model_builders[MODEL_VERSION].__name__}')\n",
    "print(f'epochs: {EPOCHS}')\n",
    "print(f'steps_per_epoch: {STEPS_PER_EPOCH}')\n",
    "print(f'dimension: {IMG_SIZE}')\n",
    "print(f'n_channels: {N_CHANNELS}')\n",
    "print(f'input layer: {INPUT_LAYER}')\n",
    "print(f'kernel init: {KER_INIT}')\n",
    "print(f'dropout: {DROPOUT}')\n",
    "print(f'learning rate: {LEARNING_RATE}')\n",
    "print(f'loss function: {LOSS_FUNCTION}')\n",
    "    \n",
    "print(f\"train cases: {len(datas_train)}\")\n",
    "print(f'train slices: {total_slices_dict[\"train\"]}')\n",
    "print(f\"validation cases: {len(datas_val)}\")\n",
    "print(f'val slices: {total_slices_dict[\"val\"]}')\n",
    "print(f'slice index: {VOLUME_START_AT} ~ {VOLUME_START_AT + VOLUME_SLICES_PLUS}')\n",
    "print(f'tumor ratio: {TUMOR_RATIO_LOWER_BOUND} ~ {TUMOR_RATIO_UPPER_BOUND}')\n",
    "print(f\"test cases: {len(datas_test)}\")\n",
    "\n",
    "print(f'start training at: {start_train_timestamp}')\n",
    "print(f'----------')\n",
    "\n",
    "original_stdout = sys.stdout\n",
    "with open(f'{model_dir}/info.log', 'w') as predict_log_file:\n",
    "    sys.stdout = predict_log_file\n",
    "    print(f'----------')\n",
    "    print(f'model name: {model_builders[MODEL_VERSION].__name__}')\n",
    "    print(f'epochs: {EPOCHS}')\n",
    "    print(f'steps_per_epoch: {STEPS_PER_EPOCH}')\n",
    "    print(f'dimension: {IMG_SIZE}')\n",
    "    print(f'n_channels: {N_CHANNELS}')\n",
    "    print(f'input layer: {INPUT_LAYER}')\n",
    "    print(f'kernel init: {KER_INIT}')\n",
    "    print(f'dropout: {DROPOUT}')\n",
    "    print(f'learning rate: {LEARNING_RATE}')\n",
    "    print(f'loss function: {LOSS_FUNCTION}')\n",
    "\n",
    "    print(f\"train cases: {len(datas_train)}\")\n",
    "    print(f'train slices: {total_slices_dict[\"train\"]}')\n",
    "    print(f\"validation cases: {len(datas_val)}\")\n",
    "    print(f'val slices: {total_slices_dict[\"val\"]}')\n",
    "    print(f'slice index: {VOLUME_START_AT} ~ {VOLUME_START_AT + VOLUME_SLICES_PLUS}')\n",
    "    print(f'tumor ratio: {TUMOR_RATIO_LOWER_BOUND} ~ {TUMOR_RATIO_UPPER_BOUND}')\n",
    "    print(f\"test cases: {len(datas_test)}\")\n",
    "\n",
    "    print(f'start training at: {start_train_timestamp}')\n",
    "    print(f'----------')\n",
    "\n",
    "sys.stdout = original_stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - 2: train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 22:21:36.092270: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "848/850 [============================>.] - ETA: 0s - loss: 0.6022 - accuracy: 0.9254 - mean_io_u: 0.7576 - dice_coef: 0.4095 - precision: 0.9400 - sensitivity: 0.9066 - specificity: 0.9806\n",
      "Epoch 00001: val_loss improved from inf to 0.43499, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch01-val_loss0.434989_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 25s 25ms/step - loss: 0.6020 - accuracy: 0.9255 - mean_io_u: 0.7577 - dice_coef: 0.4097 - precision: 0.9401 - sensitivity: 0.9068 - specificity: 0.9806 - val_loss: 0.4350 - val_accuracy: 0.9669 - val_mean_io_u: 0.7563 - val_dice_coef: 0.5714 - val_precision: 0.9677 - val_sensitivity: 0.9658 - val_specificity: 0.9892 - lr: 1.0000e-04\n",
      "Epoch 2/200\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.3902 - accuracy: 0.9651 - mean_io_u: 0.7685 - dice_coef: 0.6186 - precision: 0.9655 - sensitivity: 0.9643 - specificity: 0.9885\n",
      "Epoch 00002: val_loss improved from 0.43499 to 0.36795, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch02-val_loss0.367953_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.3902 - accuracy: 0.9651 - mean_io_u: 0.7685 - dice_coef: 0.6186 - precision: 0.9655 - sensitivity: 0.9643 - specificity: 0.9885 - val_loss: 0.3680 - val_accuracy: 0.9611 - val_mean_io_u: 0.7722 - val_dice_coef: 0.6368 - val_precision: 0.9613 - val_sensitivity: 0.9605 - val_specificity: 0.9871 - lr: 1.0000e-04\n",
      "Epoch 3/200\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.3155 - accuracy: 0.9756 - mean_io_u: 0.8084 - dice_coef: 0.6976 - precision: 0.9755 - sensitivity: 0.9750 - specificity: 0.9918\n",
      "Epoch 00003: val_loss improved from 0.36795 to 0.31887, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch03-val_loss0.318865_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.3158 - accuracy: 0.9756 - mean_io_u: 0.8086 - dice_coef: 0.6973 - precision: 0.9754 - sensitivity: 0.9750 - specificity: 0.9918 - val_loss: 0.3189 - val_accuracy: 0.9788 - val_mean_io_u: 0.8946 - val_dice_coef: 0.6997 - val_precision: 0.9786 - val_sensitivity: 0.9783 - val_specificity: 0.9929 - lr: 1.0000e-04\n",
      "Epoch 4/200\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.2970 - accuracy: 0.9783 - mean_io_u: 0.8334 - dice_coef: 0.7157 - precision: 0.9781 - sensitivity: 0.9778 - specificity: 0.9927\n",
      "Epoch 00004: val_loss improved from 0.31887 to 0.29215, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch04-val_loss0.292152_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.2976 - accuracy: 0.9782 - mean_io_u: 0.8334 - dice_coef: 0.7152 - precision: 0.9780 - sensitivity: 0.9777 - specificity: 0.9927 - val_loss: 0.2922 - val_accuracy: 0.9797 - val_mean_io_u: 0.8443 - val_dice_coef: 0.7211 - val_precision: 0.9795 - val_sensitivity: 0.9793 - val_specificity: 0.9932 - lr: 1.0000e-04\n",
      "Epoch 5/200\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.2870 - accuracy: 0.9800 - mean_io_u: 0.8443 - dice_coef: 0.7303 - precision: 0.9797 - sensitivity: 0.9795 - specificity: 0.9932\n",
      "Epoch 00005: val_loss improved from 0.29215 to 0.28540, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch05-val_loss0.285400_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.2870 - accuracy: 0.9800 - mean_io_u: 0.8443 - dice_coef: 0.7302 - precision: 0.9798 - sensitivity: 0.9795 - specificity: 0.9933 - val_loss: 0.2854 - val_accuracy: 0.9820 - val_mean_io_u: 0.8572 - val_dice_coef: 0.7273 - val_precision: 0.9818 - val_sensitivity: 0.9816 - val_specificity: 0.9939 - lr: 1.0000e-04\n",
      "Epoch 6/200\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.2768 - accuracy: 0.9808 - mean_io_u: 0.8605 - dice_coef: 0.7391 - precision: 0.9806 - sensitivity: 0.9804 - specificity: 0.9935\n",
      "Epoch 00006: val_loss improved from 0.28540 to 0.25720, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch06-val_loss0.257203_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.2767 - accuracy: 0.9808 - mean_io_u: 0.8604 - dice_coef: 0.7392 - precision: 0.9806 - sensitivity: 0.9804 - specificity: 0.9935 - val_loss: 0.2572 - val_accuracy: 0.9822 - val_mean_io_u: 0.8708 - val_dice_coef: 0.7555 - val_precision: 0.9820 - val_sensitivity: 0.9818 - val_specificity: 0.9940 - lr: 1.0000e-04\n",
      "Epoch 7/200\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.2568 - accuracy: 0.9831 - mean_io_u: 0.8622 - dice_coef: 0.7600 - precision: 0.9828 - sensitivity: 0.9826 - specificity: 0.9943\n",
      "Epoch 00007: val_loss improved from 0.25720 to 0.25565, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch07-val_loss0.255648_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.2571 - accuracy: 0.9830 - mean_io_u: 0.8622 - dice_coef: 0.7596 - precision: 0.9828 - sensitivity: 0.9826 - specificity: 0.9943 - val_loss: 0.2556 - val_accuracy: 0.9842 - val_mean_io_u: 0.9004 - val_dice_coef: 0.7591 - val_precision: 0.9839 - val_sensitivity: 0.9838 - val_specificity: 0.9946 - lr: 1.0000e-04\n",
      "Epoch 8/200\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.2518 - accuracy: 0.9837 - mean_io_u: 0.8724 - dice_coef: 0.7665 - precision: 0.9835 - sensitivity: 0.9833 - specificity: 0.9945\n",
      "Epoch 00008: val_loss improved from 0.25565 to 0.24623, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch08-val_loss0.246230_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.2516 - accuracy: 0.9837 - mean_io_u: 0.8725 - dice_coef: 0.7667 - precision: 0.9835 - sensitivity: 0.9833 - specificity: 0.9945 - val_loss: 0.2462 - val_accuracy: 0.9855 - val_mean_io_u: 0.8904 - val_dice_coef: 0.7728 - val_precision: 0.9852 - val_sensitivity: 0.9852 - val_specificity: 0.9951 - lr: 1.0000e-04\n",
      "Epoch 9/200\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.2476 - accuracy: 0.9852 - mean_io_u: 0.8742 - dice_coef: 0.7724 - precision: 0.9849 - sensitivity: 0.9848 - specificity: 0.9950\n",
      "Epoch 00009: val_loss did not improve from 0.24623\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.2476 - accuracy: 0.9852 - mean_io_u: 0.8742 - dice_coef: 0.7724 - precision: 0.9849 - sensitivity: 0.9848 - specificity: 0.9950 - val_loss: 0.2508 - val_accuracy: 0.9838 - val_mean_io_u: 0.9160 - val_dice_coef: 0.7740 - val_precision: 0.9836 - val_sensitivity: 0.9835 - val_specificity: 0.9945 - lr: 1.0000e-04\n",
      "Epoch 10/200\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.2563 - accuracy: 0.9843 - mean_io_u: 0.8837 - dice_coef: 0.7636 - precision: 0.9841 - sensitivity: 0.9840 - specificity: 0.9947\n",
      "Epoch 00010: val_loss improved from 0.24623 to 0.23992, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch10-val_loss0.239921_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.2563 - accuracy: 0.9843 - mean_io_u: 0.8837 - dice_coef: 0.7636 - precision: 0.9841 - sensitivity: 0.9840 - specificity: 0.9947 - val_loss: 0.2399 - val_accuracy: 0.9855 - val_mean_io_u: 0.8798 - val_dice_coef: 0.7791 - val_precision: 0.9852 - val_sensitivity: 0.9852 - val_specificity: 0.9951 - lr: 1.0000e-04\n",
      "Epoch 11/200\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.2469 - accuracy: 0.9847 - mean_io_u: 0.8757 - dice_coef: 0.7714 - precision: 0.9845 - sensitivity: 0.9844 - specificity: 0.9948\n",
      "Epoch 00011: val_loss did not improve from 0.23992\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.2472 - accuracy: 0.9847 - mean_io_u: 0.8758 - dice_coef: 0.7711 - precision: 0.9844 - sensitivity: 0.9843 - specificity: 0.9948 - val_loss: 0.2435 - val_accuracy: 0.9838 - val_mean_io_u: 0.8678 - val_dice_coef: 0.7725 - val_precision: 0.9836 - val_sensitivity: 0.9835 - val_specificity: 0.9945 - lr: 1.0000e-04\n",
      "Epoch 12/200\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.2615 - accuracy: 0.9822 - mean_io_u: 0.8755 - dice_coef: 0.7615 - precision: 0.9819 - sensitivity: 0.9818 - specificity: 0.9940\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.23992\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.2611 - accuracy: 0.9822 - mean_io_u: 0.8754 - dice_coef: 0.7618 - precision: 0.9819 - sensitivity: 0.9818 - specificity: 0.9940 - val_loss: 0.2581 - val_accuracy: 0.9833 - val_mean_io_u: 0.8646 - val_dice_coef: 0.7753 - val_precision: 0.9831 - val_sensitivity: 0.9830 - val_specificity: 0.9944 - lr: 1.0000e-04\n",
      "Epoch 13/200\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.2333 - accuracy: 0.9861 - mean_io_u: 0.8719 - dice_coef: 0.7846 - precision: 0.9858 - sensitivity: 0.9857 - specificity: 0.9953\n",
      "Epoch 00013: val_loss improved from 0.23992 to 0.22301, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch13-val_loss0.223007_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.2336 - accuracy: 0.9861 - mean_io_u: 0.8721 - dice_coef: 0.7844 - precision: 0.9858 - sensitivity: 0.9857 - specificity: 0.9953 - val_loss: 0.2230 - val_accuracy: 0.9866 - val_mean_io_u: 0.8921 - val_dice_coef: 0.8006 - val_precision: 0.9864 - val_sensitivity: 0.9863 - val_specificity: 0.9955 - lr: 2.0000e-05\n",
      "Epoch 14/200\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.2180 - accuracy: 0.9872 - mean_io_u: 0.8959 - dice_coef: 0.7993 - precision: 0.9869 - sensitivity: 0.9869 - specificity: 0.9956\n",
      "Epoch 00014: val_loss improved from 0.22301 to 0.21967, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch14-val_loss0.219668_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.2178 - accuracy: 0.9872 - mean_io_u: 0.8959 - dice_coef: 0.7994 - precision: 0.9870 - sensitivity: 0.9869 - specificity: 0.9957 - val_loss: 0.2197 - val_accuracy: 0.9869 - val_mean_io_u: 0.9114 - val_dice_coef: 0.8049 - val_precision: 0.9867 - val_sensitivity: 0.9866 - val_specificity: 0.9956 - lr: 2.0000e-05\n",
      "Epoch 15/200\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.2053 - accuracy: 0.9884 - mean_io_u: 0.8985 - dice_coef: 0.8146 - precision: 0.9881 - sensitivity: 0.9881 - specificity: 0.9960\n",
      "Epoch 00015: val_loss improved from 0.21967 to 0.21389, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch15-val_loss0.213894_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.2054 - accuracy: 0.9884 - mean_io_u: 0.8985 - dice_coef: 0.8146 - precision: 0.9881 - sensitivity: 0.9881 - specificity: 0.9960 - val_loss: 0.2139 - val_accuracy: 0.9870 - val_mean_io_u: 0.9049 - val_dice_coef: 0.8060 - val_precision: 0.9868 - val_sensitivity: 0.9868 - val_specificity: 0.9956 - lr: 2.0000e-05\n",
      "Epoch 16/200\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.2129 - accuracy: 0.9880 - mean_io_u: 0.9356 - dice_coef: 0.8132 - precision: 0.9877 - sensitivity: 0.9877 - specificity: 0.9959\n",
      "Epoch 00016: val_loss improved from 0.21389 to 0.20973, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch16-val_loss0.209734_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.2128 - accuracy: 0.9880 - mean_io_u: 0.9357 - dice_coef: 0.8132 - precision: 0.9877 - sensitivity: 0.9877 - specificity: 0.9959 - val_loss: 0.2097 - val_accuracy: 0.9874 - val_mean_io_u: 0.9601 - val_dice_coef: 0.8088 - val_precision: 0.9872 - val_sensitivity: 0.9872 - val_specificity: 0.9957 - lr: 2.0000e-05\n",
      "Epoch 17/200\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.1881 - accuracy: 0.9883 - mean_io_u: 0.9309 - dice_coef: 0.8289 - precision: 0.9881 - sensitivity: 0.9881 - specificity: 0.9960\n",
      "Epoch 00017: val_loss did not improve from 0.20973\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1886 - accuracy: 0.9883 - mean_io_u: 0.9308 - dice_coef: 0.8285 - precision: 0.9881 - sensitivity: 0.9881 - specificity: 0.9960 - val_loss: 0.2145 - val_accuracy: 0.9870 - val_mean_io_u: 0.9276 - val_dice_coef: 0.8136 - val_precision: 0.9867 - val_sensitivity: 0.9868 - val_specificity: 0.9956 - lr: 2.0000e-05\n",
      "Epoch 18/200\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.1805 - accuracy: 0.9891 - mean_io_u: 0.9172 - dice_coef: 0.8295 - precision: 0.9888 - sensitivity: 0.9888 - specificity: 0.9963\n",
      "Epoch 00018: val_loss improved from 0.20973 to 0.18948, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch18-val_loss0.189478_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1808 - accuracy: 0.9891 - mean_io_u: 0.9172 - dice_coef: 0.8292 - precision: 0.9888 - sensitivity: 0.9888 - specificity: 0.9963 - val_loss: 0.1895 - val_accuracy: 0.9882 - val_mean_io_u: 0.9158 - val_dice_coef: 0.8255 - val_precision: 0.9879 - val_sensitivity: 0.9879 - val_specificity: 0.9960 - lr: 2.0000e-05\n",
      "Epoch 19/200\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.1903 - accuracy: 0.9884 - mean_io_u: 0.9264 - dice_coef: 0.8264 - precision: 0.9881 - sensitivity: 0.9882 - specificity: 0.9960\n",
      "Epoch 00019: val_loss did not improve from 0.18948\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1902 - accuracy: 0.9884 - mean_io_u: 0.9264 - dice_coef: 0.8265 - precision: 0.9881 - sensitivity: 0.9881 - specificity: 0.9960 - val_loss: 0.2324 - val_accuracy: 0.9858 - val_mean_io_u: 0.9346 - val_dice_coef: 0.7934 - val_precision: 0.9855 - val_sensitivity: 0.9856 - val_specificity: 0.9952 - lr: 2.0000e-05\n",
      "Epoch 20/200\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.1847 - accuracy: 0.9884 - mean_io_u: 0.9107 - dice_coef: 0.8290 - precision: 0.9881 - sensitivity: 0.9881 - specificity: 0.9960\n",
      "Epoch 00020: val_loss improved from 0.18948 to 0.18740, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch20-val_loss0.187396_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1848 - accuracy: 0.9884 - mean_io_u: 0.9108 - dice_coef: 0.8290 - precision: 0.9881 - sensitivity: 0.9881 - specificity: 0.9960 - val_loss: 0.1874 - val_accuracy: 0.9881 - val_mean_io_u: 0.9209 - val_dice_coef: 0.8274 - val_precision: 0.9878 - val_sensitivity: 0.9878 - val_specificity: 0.9959 - lr: 2.0000e-05\n",
      "Epoch 21/200\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.1813 - accuracy: 0.9889 - mean_io_u: 0.9216 - dice_coef: 0.8292 - precision: 0.9886 - sensitivity: 0.9886 - specificity: 0.9962\n",
      "Epoch 00021: val_loss improved from 0.18740 to 0.18625, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch21-val_loss0.186254_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1813 - accuracy: 0.9889 - mean_io_u: 0.9216 - dice_coef: 0.8292 - precision: 0.9886 - sensitivity: 0.9886 - specificity: 0.9962 - val_loss: 0.1863 - val_accuracy: 0.9880 - val_mean_io_u: 0.9088 - val_dice_coef: 0.8278 - val_precision: 0.9877 - val_sensitivity: 0.9877 - val_specificity: 0.9959 - lr: 2.0000e-05\n",
      "Epoch 22/200\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.1719 - accuracy: 0.9894 - mean_io_u: 0.9239 - dice_coef: 0.8371 - precision: 0.9891 - sensitivity: 0.9891 - specificity: 0.9964\n",
      "Epoch 00022: val_loss did not improve from 0.18625\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1717 - accuracy: 0.9894 - mean_io_u: 0.9240 - dice_coef: 0.8373 - precision: 0.9891 - sensitivity: 0.9891 - specificity: 0.9964 - val_loss: 0.1871 - val_accuracy: 0.9881 - val_mean_io_u: 0.9602 - val_dice_coef: 0.8280 - val_precision: 0.9879 - val_sensitivity: 0.9879 - val_specificity: 0.9960 - lr: 2.0000e-05\n",
      "Epoch 23/200\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.1726 - accuracy: 0.9893 - mean_io_u: 0.9325 - dice_coef: 0.8389 - precision: 0.9890 - sensitivity: 0.9890 - specificity: 0.9963\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.18625\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1726 - accuracy: 0.9893 - mean_io_u: 0.9325 - dice_coef: 0.8389 - precision: 0.9890 - sensitivity: 0.9890 - specificity: 0.9963 - val_loss: 0.1887 - val_accuracy: 0.9882 - val_mean_io_u: 0.9183 - val_dice_coef: 0.8274 - val_precision: 0.9879 - val_sensitivity: 0.9879 - val_specificity: 0.9960 - lr: 2.0000e-05\n",
      "Epoch 24/200\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.1707 - accuracy: 0.9896 - mean_io_u: 0.9266 - dice_coef: 0.8408 - precision: 0.9893 - sensitivity: 0.9893 - specificity: 0.9964\n",
      "Epoch 00024: val_loss improved from 0.18625 to 0.18316, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch24-val_loss0.183160_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1705 - accuracy: 0.9896 - mean_io_u: 0.9266 - dice_coef: 0.8410 - precision: 0.9893 - sensitivity: 0.9893 - specificity: 0.9964 - val_loss: 0.1832 - val_accuracy: 0.9885 - val_mean_io_u: 0.9275 - val_dice_coef: 0.8318 - val_precision: 0.9882 - val_sensitivity: 0.9883 - val_specificity: 0.9961 - lr: 4.0000e-06\n",
      "Epoch 25/200\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.1688 - accuracy: 0.9894 - mean_io_u: 0.9154 - dice_coef: 0.8410 - precision: 0.9891 - sensitivity: 0.9891 - specificity: 0.9964\n",
      "Epoch 00025: val_loss did not improve from 0.18316\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1695 - accuracy: 0.9894 - mean_io_u: 0.9154 - dice_coef: 0.8404 - precision: 0.9891 - sensitivity: 0.9891 - specificity: 0.9964 - val_loss: 0.1832 - val_accuracy: 0.9883 - val_mean_io_u: 0.9161 - val_dice_coef: 0.8321 - val_precision: 0.9880 - val_sensitivity: 0.9881 - val_specificity: 0.9960 - lr: 4.0000e-06\n",
      "Epoch 26/200\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.1662 - accuracy: 0.9897 - mean_io_u: 0.9137 - dice_coef: 0.8425 - precision: 0.9894 - sensitivity: 0.9894 - specificity: 0.9965\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.18316\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1664 - accuracy: 0.9897 - mean_io_u: 0.9137 - dice_coef: 0.8422 - precision: 0.9894 - sensitivity: 0.9894 - specificity: 0.9965 - val_loss: 0.1840 - val_accuracy: 0.9886 - val_mean_io_u: 0.9246 - val_dice_coef: 0.8307 - val_precision: 0.9883 - val_sensitivity: 0.9883 - val_specificity: 0.9961 - lr: 4.0000e-06\n",
      "Epoch 27/200\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.1599 - accuracy: 0.9899 - mean_io_u: 0.9194 - dice_coef: 0.8482 - precision: 0.9896 - sensitivity: 0.9896 - specificity: 0.9965\n",
      "Epoch 00027: val_loss did not improve from 0.18316\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1599 - accuracy: 0.9899 - mean_io_u: 0.9194 - dice_coef: 0.8482 - precision: 0.9896 - sensitivity: 0.9896 - specificity: 0.9965 - val_loss: 0.1833 - val_accuracy: 0.9884 - val_mean_io_u: 0.9171 - val_dice_coef: 0.8311 - val_precision: 0.9882 - val_sensitivity: 0.9882 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 28/200\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.1659 - accuracy: 0.9898 - mean_io_u: 0.9173 - dice_coef: 0.8460 - precision: 0.9895 - sensitivity: 0.9895 - specificity: 0.9965\n",
      "Epoch 00028: val_loss improved from 0.18316 to 0.18240, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch28-val_loss0.182405_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1659 - accuracy: 0.9898 - mean_io_u: 0.9173 - dice_coef: 0.8459 - precision: 0.9895 - sensitivity: 0.9895 - specificity: 0.9965 - val_loss: 0.1824 - val_accuracy: 0.9886 - val_mean_io_u: 0.9233 - val_dice_coef: 0.8321 - val_precision: 0.9883 - val_sensitivity: 0.9883 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 29/200\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.1686 - accuracy: 0.9896 - mean_io_u: 0.9180 - dice_coef: 0.8407 - precision: 0.9893 - sensitivity: 0.9893 - specificity: 0.9964\n",
      "Epoch 00029: val_loss did not improve from 0.18240\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1686 - accuracy: 0.9896 - mean_io_u: 0.9180 - dice_coef: 0.8407 - precision: 0.9893 - sensitivity: 0.9893 - specificity: 0.9964 - val_loss: 0.1828 - val_accuracy: 0.9885 - val_mean_io_u: 0.9233 - val_dice_coef: 0.8315 - val_precision: 0.9883 - val_sensitivity: 0.9883 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 30/200\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.1658 - accuracy: 0.9900 - mean_io_u: 0.9207 - dice_coef: 0.8442 - precision: 0.9897 - sensitivity: 0.9897 - specificity: 0.9966\n",
      "Epoch 00030: val_loss improved from 0.18240 to 0.18222, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch30-val_loss0.182221_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1658 - accuracy: 0.9900 - mean_io_u: 0.9207 - dice_coef: 0.8442 - precision: 0.9897 - sensitivity: 0.9897 - specificity: 0.9966 - val_loss: 0.1822 - val_accuracy: 0.9885 - val_mean_io_u: 0.9224 - val_dice_coef: 0.8324 - val_precision: 0.9883 - val_sensitivity: 0.9883 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 31/200\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.1604 - accuracy: 0.9900 - mean_io_u: 0.9202 - dice_coef: 0.8481 - precision: 0.9897 - sensitivity: 0.9897 - specificity: 0.9966\n",
      "Epoch 00031: val_loss did not improve from 0.18222\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1602 - accuracy: 0.9900 - mean_io_u: 0.9202 - dice_coef: 0.8482 - precision: 0.9897 - sensitivity: 0.9897 - specificity: 0.9966 - val_loss: 0.1823 - val_accuracy: 0.9886 - val_mean_io_u: 0.9207 - val_dice_coef: 0.8320 - val_precision: 0.9883 - val_sensitivity: 0.9883 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 32/200\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.1669 - accuracy: 0.9900 - mean_io_u: 0.9125 - dice_coef: 0.8434 - precision: 0.9897 - sensitivity: 0.9897 - specificity: 0.9966\n",
      "Epoch 00032: val_loss improved from 0.18222 to 0.18221, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch32-val_loss0.182214_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1677 - accuracy: 0.9900 - mean_io_u: 0.9125 - dice_coef: 0.8427 - precision: 0.9897 - sensitivity: 0.9897 - specificity: 0.9966 - val_loss: 0.1822 - val_accuracy: 0.9885 - val_mean_io_u: 0.9127 - val_dice_coef: 0.8320 - val_precision: 0.9883 - val_sensitivity: 0.9883 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 33/200\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.1649 - accuracy: 0.9898 - mean_io_u: 0.9094 - dice_coef: 0.8440 - precision: 0.9895 - sensitivity: 0.9896 - specificity: 0.9965\n",
      "Epoch 00033: val_loss improved from 0.18221 to 0.18206, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch33-val_loss0.182062_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1650 - accuracy: 0.9899 - mean_io_u: 0.9093 - dice_coef: 0.8440 - precision: 0.9896 - sensitivity: 0.9896 - specificity: 0.9965 - val_loss: 0.1821 - val_accuracy: 0.9885 - val_mean_io_u: 0.9132 - val_dice_coef: 0.8319 - val_precision: 0.9883 - val_sensitivity: 0.9883 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 34/200\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.1614 - accuracy: 0.9901 - mean_io_u: 0.9107 - dice_coef: 0.8478 - precision: 0.9898 - sensitivity: 0.9899 - specificity: 0.9966\n",
      "Epoch 00034: val_loss did not improve from 0.18206\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1614 - accuracy: 0.9901 - mean_io_u: 0.9107 - dice_coef: 0.8478 - precision: 0.9898 - sensitivity: 0.9899 - specificity: 0.9966 - val_loss: 0.1825 - val_accuracy: 0.9886 - val_mean_io_u: 0.9147 - val_dice_coef: 0.8319 - val_precision: 0.9883 - val_sensitivity: 0.9883 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 35/200\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.1612 - accuracy: 0.9897 - mean_io_u: 0.9106 - dice_coef: 0.8467 - precision: 0.9894 - sensitivity: 0.9894 - specificity: 0.9965\n",
      "Epoch 00035: val_loss improved from 0.18206 to 0.18166, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch35-val_loss0.181655_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1611 - accuracy: 0.9897 - mean_io_u: 0.9106 - dice_coef: 0.8468 - precision: 0.9894 - sensitivity: 0.9894 - specificity: 0.9965 - val_loss: 0.1817 - val_accuracy: 0.9885 - val_mean_io_u: 0.9094 - val_dice_coef: 0.8319 - val_precision: 0.9883 - val_sensitivity: 0.9883 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 36/200\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.1572 - accuracy: 0.9901 - mean_io_u: 0.9080 - dice_coef: 0.8509 - precision: 0.9898 - sensitivity: 0.9898 - specificity: 0.9966\n",
      "Epoch 00036: val_loss did not improve from 0.18166\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1570 - accuracy: 0.9901 - mean_io_u: 0.9080 - dice_coef: 0.8511 - precision: 0.9898 - sensitivity: 0.9898 - specificity: 0.9966 - val_loss: 0.1819 - val_accuracy: 0.9886 - val_mean_io_u: 0.9096 - val_dice_coef: 0.8317 - val_precision: 0.9883 - val_sensitivity: 0.9883 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 37/200\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.1650 - accuracy: 0.9902 - mean_io_u: 0.9117 - dice_coef: 0.8439 - precision: 0.9899 - sensitivity: 0.9899 - specificity: 0.9966\n",
      "Epoch 00037: val_loss did not improve from 0.18166\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1650 - accuracy: 0.9902 - mean_io_u: 0.9116 - dice_coef: 0.8440 - precision: 0.9899 - sensitivity: 0.9899 - specificity: 0.9966 - val_loss: 0.1820 - val_accuracy: 0.9886 - val_mean_io_u: 0.9140 - val_dice_coef: 0.8318 - val_precision: 0.9883 - val_sensitivity: 0.9883 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 38/200\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.1560 - accuracy: 0.9903 - mean_io_u: 0.9128 - dice_coef: 0.8536 - precision: 0.9900 - sensitivity: 0.9900 - specificity: 0.9967\n",
      "Epoch 00038: val_loss improved from 0.18166 to 0.18160, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch38-val_loss0.181604_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1560 - accuracy: 0.9903 - mean_io_u: 0.9128 - dice_coef: 0.8536 - precision: 0.9900 - sensitivity: 0.9900 - specificity: 0.9967 - val_loss: 0.1816 - val_accuracy: 0.9886 - val_mean_io_u: 0.9184 - val_dice_coef: 0.8321 - val_precision: 0.9883 - val_sensitivity: 0.9883 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 39/200\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.1588 - accuracy: 0.9902 - mean_io_u: 0.9135 - dice_coef: 0.8502 - precision: 0.9899 - sensitivity: 0.9899 - specificity: 0.9966\n",
      "Epoch 00039: val_loss improved from 0.18160 to 0.18158, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch39-val_loss0.181576_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1589 - accuracy: 0.9902 - mean_io_u: 0.9134 - dice_coef: 0.8500 - precision: 0.9899 - sensitivity: 0.9899 - specificity: 0.9966 - val_loss: 0.1816 - val_accuracy: 0.9887 - val_mean_io_u: 0.9193 - val_dice_coef: 0.8319 - val_precision: 0.9884 - val_sensitivity: 0.9884 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 40/200\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.1586 - accuracy: 0.9904 - mean_io_u: 0.9110 - dice_coef: 0.8498 - precision: 0.9901 - sensitivity: 0.9901 - specificity: 0.9967\n",
      "Epoch 00040: val_loss did not improve from 0.18158\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1586 - accuracy: 0.9904 - mean_io_u: 0.9110 - dice_coef: 0.8498 - precision: 0.9901 - sensitivity: 0.9901 - specificity: 0.9967 - val_loss: 0.1819 - val_accuracy: 0.9886 - val_mean_io_u: 0.9129 - val_dice_coef: 0.8317 - val_precision: 0.9883 - val_sensitivity: 0.9883 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 41/200\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.1617 - accuracy: 0.9906 - mean_io_u: 0.9130 - dice_coef: 0.8468 - precision: 0.9903 - sensitivity: 0.9903 - specificity: 0.9968\n",
      "Epoch 00041: val_loss did not improve from 0.18158\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1617 - accuracy: 0.9906 - mean_io_u: 0.9131 - dice_coef: 0.8469 - precision: 0.9903 - sensitivity: 0.9903 - specificity: 0.9968 - val_loss: 0.1818 - val_accuracy: 0.9886 - val_mean_io_u: 0.9190 - val_dice_coef: 0.8328 - val_precision: 0.9883 - val_sensitivity: 0.9884 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 42/200\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.1578 - accuracy: 0.9906 - mean_io_u: 0.9161 - dice_coef: 0.8489 - precision: 0.9903 - sensitivity: 0.9903 - specificity: 0.9968\n",
      "Epoch 00042: val_loss improved from 0.18158 to 0.18151, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch42-val_loss0.181507_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1577 - accuracy: 0.9906 - mean_io_u: 0.9161 - dice_coef: 0.8490 - precision: 0.9903 - sensitivity: 0.9903 - specificity: 0.9968 - val_loss: 0.1815 - val_accuracy: 0.9886 - val_mean_io_u: 0.9194 - val_dice_coef: 0.8330 - val_precision: 0.9883 - val_sensitivity: 0.9884 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 43/200\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.1553 - accuracy: 0.9901 - mean_io_u: 0.9156 - dice_coef: 0.8523 - precision: 0.9898 - sensitivity: 0.9898 - specificity: 0.9966\n",
      "Epoch 00043: val_loss improved from 0.18151 to 0.18139, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch43-val_loss0.181393_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1556 - accuracy: 0.9901 - mean_io_u: 0.9156 - dice_coef: 0.8520 - precision: 0.9898 - sensitivity: 0.9898 - specificity: 0.9966 - val_loss: 0.1814 - val_accuracy: 0.9886 - val_mean_io_u: 0.9189 - val_dice_coef: 0.8329 - val_precision: 0.9884 - val_sensitivity: 0.9884 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 44/200\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.1628 - accuracy: 0.9902 - mean_io_u: 0.9144 - dice_coef: 0.8469 - precision: 0.9899 - sensitivity: 0.9899 - specificity: 0.9966\n",
      "Epoch 00044: val_loss improved from 0.18139 to 0.18134, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch44-val_loss0.181344_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1628 - accuracy: 0.9902 - mean_io_u: 0.9143 - dice_coef: 0.8468 - precision: 0.9899 - sensitivity: 0.9899 - specificity: 0.9966 - val_loss: 0.1813 - val_accuracy: 0.9885 - val_mean_io_u: 0.9127 - val_dice_coef: 0.8329 - val_precision: 0.9882 - val_sensitivity: 0.9882 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 45/200\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.1623 - accuracy: 0.9902 - mean_io_u: 0.9104 - dice_coef: 0.8475 - precision: 0.9899 - sensitivity: 0.9899 - specificity: 0.9966\n",
      "Epoch 00045: val_loss did not improve from 0.18134\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1622 - accuracy: 0.9902 - mean_io_u: 0.9105 - dice_coef: 0.8475 - precision: 0.9899 - sensitivity: 0.9899 - specificity: 0.9966 - val_loss: 0.1814 - val_accuracy: 0.9885 - val_mean_io_u: 0.9119 - val_dice_coef: 0.8325 - val_precision: 0.9883 - val_sensitivity: 0.9883 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 46/200\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.1567 - accuracy: 0.9904 - mean_io_u: 0.9121 - dice_coef: 0.8500 - precision: 0.9901 - sensitivity: 0.9901 - specificity: 0.9967\n",
      "Epoch 00046: val_loss improved from 0.18134 to 0.18087, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch46-val_loss0.180866_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1568 - accuracy: 0.9904 - mean_io_u: 0.9122 - dice_coef: 0.8500 - precision: 0.9901 - sensitivity: 0.9901 - specificity: 0.9967 - val_loss: 0.1809 - val_accuracy: 0.9886 - val_mean_io_u: 0.9207 - val_dice_coef: 0.8333 - val_precision: 0.9884 - val_sensitivity: 0.9884 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 47/200\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.1693 - accuracy: 0.9902 - mean_io_u: 0.9119 - dice_coef: 0.8407 - precision: 0.9899 - sensitivity: 0.9899 - specificity: 0.9966\n",
      "Epoch 00047: val_loss did not improve from 0.18087\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1690 - accuracy: 0.9902 - mean_io_u: 0.9120 - dice_coef: 0.8409 - precision: 0.9899 - sensitivity: 0.9899 - specificity: 0.9966 - val_loss: 0.1811 - val_accuracy: 0.9885 - val_mean_io_u: 0.9173 - val_dice_coef: 0.8328 - val_precision: 0.9883 - val_sensitivity: 0.9883 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 48/200\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.1571 - accuracy: 0.9903 - mean_io_u: 0.9149 - dice_coef: 0.8516 - precision: 0.9900 - sensitivity: 0.9900 - specificity: 0.9967\n",
      "Epoch 00048: val_loss did not improve from 0.18087\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1574 - accuracy: 0.9903 - mean_io_u: 0.9151 - dice_coef: 0.8514 - precision: 0.9900 - sensitivity: 0.9900 - specificity: 0.9967 - val_loss: 0.1812 - val_accuracy: 0.9886 - val_mean_io_u: 0.9160 - val_dice_coef: 0.8327 - val_precision: 0.9883 - val_sensitivity: 0.9883 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 49/200\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.1621 - accuracy: 0.9902 - mean_io_u: 0.9104 - dice_coef: 0.8464 - precision: 0.9899 - sensitivity: 0.9899 - specificity: 0.9966\n",
      "Epoch 00049: val_loss improved from 0.18087 to 0.18072, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch49-val_loss0.180720_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1621 - accuracy: 0.9902 - mean_io_u: 0.9104 - dice_coef: 0.8464 - precision: 0.9899 - sensitivity: 0.9899 - specificity: 0.9966 - val_loss: 0.1807 - val_accuracy: 0.9887 - val_mean_io_u: 0.9204 - val_dice_coef: 0.8330 - val_precision: 0.9884 - val_sensitivity: 0.9885 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 50/200\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.1582 - accuracy: 0.9902 - mean_io_u: 0.9116 - dice_coef: 0.8470 - precision: 0.9899 - sensitivity: 0.9899 - specificity: 0.9966\n",
      "Epoch 00050: val_loss did not improve from 0.18072\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1584 - accuracy: 0.9902 - mean_io_u: 0.9116 - dice_coef: 0.8469 - precision: 0.9899 - sensitivity: 0.9899 - specificity: 0.9966 - val_loss: 0.1815 - val_accuracy: 0.9887 - val_mean_io_u: 0.9196 - val_dice_coef: 0.8327 - val_precision: 0.9884 - val_sensitivity: 0.9884 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 51/200\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.1574 - accuracy: 0.9903 - mean_io_u: 0.9158 - dice_coef: 0.8515 - precision: 0.9900 - sensitivity: 0.9900 - specificity: 0.9967\n",
      "Epoch 00051: val_loss did not improve from 0.18072\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1572 - accuracy: 0.9903 - mean_io_u: 0.9159 - dice_coef: 0.8517 - precision: 0.9900 - sensitivity: 0.9900 - specificity: 0.9967 - val_loss: 0.1822 - val_accuracy: 0.9886 - val_mean_io_u: 0.9197 - val_dice_coef: 0.8322 - val_precision: 0.9883 - val_sensitivity: 0.9884 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 52/200\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.1591 - accuracy: 0.9903 - mean_io_u: 0.9160 - dice_coef: 0.8484 - precision: 0.9899 - sensitivity: 0.9900 - specificity: 0.9967\n",
      "Epoch 00052: val_loss did not improve from 0.18072\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1590 - accuracy: 0.9903 - mean_io_u: 0.9159 - dice_coef: 0.8484 - precision: 0.9900 - sensitivity: 0.9900 - specificity: 0.9967 - val_loss: 0.1824 - val_accuracy: 0.9886 - val_mean_io_u: 0.9154 - val_dice_coef: 0.8317 - val_precision: 0.9883 - val_sensitivity: 0.9883 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 53/200\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.1560 - accuracy: 0.9905 - mean_io_u: 0.9118 - dice_coef: 0.8513 - precision: 0.9902 - sensitivity: 0.9902 - specificity: 0.9967\n",
      "Epoch 00053: val_loss did not improve from 0.18072\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1557 - accuracy: 0.9905 - mean_io_u: 0.9119 - dice_coef: 0.8516 - precision: 0.9902 - sensitivity: 0.9902 - specificity: 0.9967 - val_loss: 0.1820 - val_accuracy: 0.9885 - val_mean_io_u: 0.9181 - val_dice_coef: 0.8323 - val_precision: 0.9883 - val_sensitivity: 0.9883 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 54/200\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.1591 - accuracy: 0.9905 - mean_io_u: 0.9161 - dice_coef: 0.8500 - precision: 0.9901 - sensitivity: 0.9902 - specificity: 0.9967\n",
      "Epoch 00054: val_loss did not improve from 0.18072\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1596 - accuracy: 0.9904 - mean_io_u: 0.9163 - dice_coef: 0.8495 - precision: 0.9901 - sensitivity: 0.9902 - specificity: 0.9967 - val_loss: 0.1818 - val_accuracy: 0.9886 - val_mean_io_u: 0.9205 - val_dice_coef: 0.8321 - val_precision: 0.9884 - val_sensitivity: 0.9884 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 55/200\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.1545 - accuracy: 0.9906 - mean_io_u: 0.9205 - dice_coef: 0.8534 - precision: 0.9903 - sensitivity: 0.9903 - specificity: 0.9968\n",
      "Epoch 00055: val_loss did not improve from 0.18072\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1544 - accuracy: 0.9906 - mean_io_u: 0.9204 - dice_coef: 0.8534 - precision: 0.9903 - sensitivity: 0.9903 - specificity: 0.9968 - val_loss: 0.1807 - val_accuracy: 0.9886 - val_mean_io_u: 0.9259 - val_dice_coef: 0.8335 - val_precision: 0.9884 - val_sensitivity: 0.9884 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 56/200\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.1573 - accuracy: 0.9905 - mean_io_u: 0.9230 - dice_coef: 0.8503 - precision: 0.9902 - sensitivity: 0.9902 - specificity: 0.9967\n",
      "Epoch 00056: val_loss did not improve from 0.18072\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1571 - accuracy: 0.9905 - mean_io_u: 0.9231 - dice_coef: 0.8505 - precision: 0.9902 - sensitivity: 0.9902 - specificity: 0.9967 - val_loss: 0.1807 - val_accuracy: 0.9886 - val_mean_io_u: 0.9267 - val_dice_coef: 0.8335 - val_precision: 0.9884 - val_sensitivity: 0.9884 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 57/200\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.1566 - accuracy: 0.9902 - mean_io_u: 0.9201 - dice_coef: 0.8508 - precision: 0.9899 - sensitivity: 0.9899 - specificity: 0.9966\n",
      "Epoch 00057: val_loss improved from 0.18072 to 0.17939, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch57-val_loss0.179389_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1567 - accuracy: 0.9901 - mean_io_u: 0.9201 - dice_coef: 0.8507 - precision: 0.9898 - sensitivity: 0.9899 - specificity: 0.9966 - val_loss: 0.1794 - val_accuracy: 0.9887 - val_mean_io_u: 0.9245 - val_dice_coef: 0.8341 - val_precision: 0.9884 - val_sensitivity: 0.9884 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 58/200\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.1593 - accuracy: 0.9900 - mean_io_u: 0.9151 - dice_coef: 0.8482 - precision: 0.9897 - sensitivity: 0.9897 - specificity: 0.9966\n",
      "Epoch 00058: val_loss did not improve from 0.17939\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1593 - accuracy: 0.9900 - mean_io_u: 0.9151 - dice_coef: 0.8483 - precision: 0.9897 - sensitivity: 0.9897 - specificity: 0.9966 - val_loss: 0.1801 - val_accuracy: 0.9886 - val_mean_io_u: 0.9149 - val_dice_coef: 0.8335 - val_precision: 0.9883 - val_sensitivity: 0.9883 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 59/200\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.1605 - accuracy: 0.9903 - mean_io_u: 0.9145 - dice_coef: 0.8481 - precision: 0.9900 - sensitivity: 0.9900 - specificity: 0.9967\n",
      "Epoch 00059: val_loss did not improve from 0.17939\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1602 - accuracy: 0.9903 - mean_io_u: 0.9145 - dice_coef: 0.8483 - precision: 0.9900 - sensitivity: 0.9900 - specificity: 0.9967 - val_loss: 0.1797 - val_accuracy: 0.9886 - val_mean_io_u: 0.9207 - val_dice_coef: 0.8339 - val_precision: 0.9883 - val_sensitivity: 0.9883 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 60/200\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.1603 - accuracy: 0.9902 - mean_io_u: 0.9209 - dice_coef: 0.8484 - precision: 0.9899 - sensitivity: 0.9899 - specificity: 0.9966\n",
      "Epoch 00060: val_loss improved from 0.17939 to 0.17934, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch60-val_loss0.179338_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1598 - accuracy: 0.9902 - mean_io_u: 0.9209 - dice_coef: 0.8488 - precision: 0.9899 - sensitivity: 0.9899 - specificity: 0.9966 - val_loss: 0.1793 - val_accuracy: 0.9885 - val_mean_io_u: 0.9175 - val_dice_coef: 0.8335 - val_precision: 0.9883 - val_sensitivity: 0.9883 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 61/200\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.1539 - accuracy: 0.9903 - mean_io_u: 0.9148 - dice_coef: 0.8537 - precision: 0.9900 - sensitivity: 0.9900 - specificity: 0.9967\n",
      "Epoch 00061: val_loss did not improve from 0.17934\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1540 - accuracy: 0.9903 - mean_io_u: 0.9149 - dice_coef: 0.8536 - precision: 0.9900 - sensitivity: 0.9900 - specificity: 0.9967 - val_loss: 0.1794 - val_accuracy: 0.9886 - val_mean_io_u: 0.9172 - val_dice_coef: 0.8335 - val_precision: 0.9883 - val_sensitivity: 0.9884 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 62/200\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.1560 - accuracy: 0.9903 - mean_io_u: 0.9131 - dice_coef: 0.8533 - precision: 0.9900 - sensitivity: 0.9900 - specificity: 0.9967\n",
      "Epoch 00062: val_loss improved from 0.17934 to 0.17909, saving model to ./model/model_v1_Mar-23_22-21-34/model_epoch62-val_loss0.179089_Mar-23_22-21-34.m5\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1560 - accuracy: 0.9903 - mean_io_u: 0.9131 - dice_coef: 0.8533 - precision: 0.9900 - sensitivity: 0.9900 - specificity: 0.9967 - val_loss: 0.1791 - val_accuracy: 0.9886 - val_mean_io_u: 0.9216 - val_dice_coef: 0.8338 - val_precision: 0.9884 - val_sensitivity: 0.9884 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 63/200\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.1570 - accuracy: 0.9903 - mean_io_u: 0.9214 - dice_coef: 0.8494 - precision: 0.9900 - sensitivity: 0.9900 - specificity: 0.9967\n",
      "Epoch 00063: val_loss did not improve from 0.17909\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1570 - accuracy: 0.9903 - mean_io_u: 0.9214 - dice_coef: 0.8494 - precision: 0.9900 - sensitivity: 0.9900 - specificity: 0.9967 - val_loss: 0.1793 - val_accuracy: 0.9886 - val_mean_io_u: 0.9239 - val_dice_coef: 0.8339 - val_precision: 0.9884 - val_sensitivity: 0.9884 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 64/200\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.1554 - accuracy: 0.9907 - mean_io_u: 0.9195 - dice_coef: 0.8530 - precision: 0.9904 - sensitivity: 0.9904 - specificity: 0.9968\n",
      "Epoch 00064: val_loss did not improve from 0.17909\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1554 - accuracy: 0.9907 - mean_io_u: 0.9195 - dice_coef: 0.8530 - precision: 0.9904 - sensitivity: 0.9904 - specificity: 0.9968 - val_loss: 0.1801 - val_accuracy: 0.9887 - val_mean_io_u: 0.9206 - val_dice_coef: 0.8336 - val_precision: 0.9884 - val_sensitivity: 0.9884 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 65/200\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.1592 - accuracy: 0.9904 - mean_io_u: 0.9190 - dice_coef: 0.8495 - precision: 0.9901 - sensitivity: 0.9901 - specificity: 0.9967\n",
      "Epoch 00065: val_loss did not improve from 0.17909\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1600 - accuracy: 0.9904 - mean_io_u: 0.9191 - dice_coef: 0.8487 - precision: 0.9901 - sensitivity: 0.9901 - specificity: 0.9967 - val_loss: 0.1800 - val_accuracy: 0.9887 - val_mean_io_u: 0.9246 - val_dice_coef: 0.8333 - val_precision: 0.9884 - val_sensitivity: 0.9884 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 66/200\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.1544 - accuracy: 0.9904 - mean_io_u: 0.9183 - dice_coef: 0.8521 - precision: 0.9901 - sensitivity: 0.9901 - specificity: 0.9967\n",
      "Epoch 00066: val_loss did not improve from 0.17909\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1543 - accuracy: 0.9904 - mean_io_u: 0.9184 - dice_coef: 0.8522 - precision: 0.9901 - sensitivity: 0.9901 - specificity: 0.9967 - val_loss: 0.1805 - val_accuracy: 0.9886 - val_mean_io_u: 0.9227 - val_dice_coef: 0.8330 - val_precision: 0.9883 - val_sensitivity: 0.9884 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 67/200\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.1519 - accuracy: 0.9904 - mean_io_u: 0.9194 - dice_coef: 0.8555 - precision: 0.9901 - sensitivity: 0.9901 - specificity: 0.9967\n",
      "Epoch 00067: val_loss did not improve from 0.17909\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1519 - accuracy: 0.9904 - mean_io_u: 0.9194 - dice_coef: 0.8555 - precision: 0.9901 - sensitivity: 0.9901 - specificity: 0.9967 - val_loss: 0.1800 - val_accuracy: 0.9887 - val_mean_io_u: 0.9222 - val_dice_coef: 0.8334 - val_precision: 0.9884 - val_sensitivity: 0.9884 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 68/200\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.1518 - accuracy: 0.9904 - mean_io_u: 0.9188 - dice_coef: 0.8545 - precision: 0.9901 - sensitivity: 0.9901 - specificity: 0.9967\n",
      "Epoch 00068: val_loss did not improve from 0.17909\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1516 - accuracy: 0.9904 - mean_io_u: 0.9188 - dice_coef: 0.8547 - precision: 0.9901 - sensitivity: 0.9901 - specificity: 0.9967 - val_loss: 0.1794 - val_accuracy: 0.9886 - val_mean_io_u: 0.9182 - val_dice_coef: 0.8340 - val_precision: 0.9884 - val_sensitivity: 0.9884 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 69/200\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.1474 - accuracy: 0.9906 - mean_io_u: 0.9160 - dice_coef: 0.8608 - precision: 0.9903 - sensitivity: 0.9903 - specificity: 0.9968\n",
      "Epoch 00069: val_loss did not improve from 0.17909\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1473 - accuracy: 0.9906 - mean_io_u: 0.9160 - dice_coef: 0.8609 - precision: 0.9903 - sensitivity: 0.9903 - specificity: 0.9968 - val_loss: 0.1807 - val_accuracy: 0.9886 - val_mean_io_u: 0.9187 - val_dice_coef: 0.8335 - val_precision: 0.9884 - val_sensitivity: 0.9884 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 70/200\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.1571 - accuracy: 0.9904 - mean_io_u: 0.9191 - dice_coef: 0.8496 - precision: 0.9900 - sensitivity: 0.9901 - specificity: 0.9967\n",
      "Epoch 00070: val_loss did not improve from 0.17909\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1571 - accuracy: 0.9904 - mean_io_u: 0.9191 - dice_coef: 0.8496 - precision: 0.9900 - sensitivity: 0.9901 - specificity: 0.9967 - val_loss: 0.1810 - val_accuracy: 0.9886 - val_mean_io_u: 0.9211 - val_dice_coef: 0.8324 - val_precision: 0.9884 - val_sensitivity: 0.9884 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 71/200\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.1513 - accuracy: 0.9906 - mean_io_u: 0.9177 - dice_coef: 0.8559 - precision: 0.9903 - sensitivity: 0.9903 - specificity: 0.9968\n",
      "Epoch 00071: val_loss did not improve from 0.17909\n",
      "850/850 [==============================] - 21s 25ms/step - loss: 0.1515 - accuracy: 0.9906 - mean_io_u: 0.9177 - dice_coef: 0.8557 - precision: 0.9903 - sensitivity: 0.9903 - specificity: 0.9968 - val_loss: 0.1807 - val_accuracy: 0.9887 - val_mean_io_u: 0.9247 - val_dice_coef: 0.8326 - val_precision: 0.9884 - val_sensitivity: 0.9884 - val_specificity: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 72/200\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.1536 - accuracy: 0.9908 - mean_io_u: 0.9236 - dice_coef: 0.8533 - precision: 0.9904 - sensitivity: 0.9905 - specificity: 0.9968"
     ]
    }
   ],
   "source": [
    "model.fit(training_generator,\n",
    "          epochs=EPOCHS,\n",
    "          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=valid_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - 3: Plot the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "training_log_filename = glob.glob(os.path.join(model_dir, 'training-*.log'))[0]\n",
    "plt_filename = os.path.splitext(os.path.basename(training_log_filename))[0]\n",
    "print(f'plt image will be saved in: {training_log_filename}\\nwith name: {plt_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSVlogger file that contains all our metrics (accuracy, loss, dice_coef, ...) of our training\n",
    "history = pd.read_csv(training_log_filename, sep=',', engine='python')\n",
    "\n",
    "# Plot training and validation metrics\n",
    "fig, axs = plt.subplots(1, 3, figsize=(16, 8))\n",
    "# fig, axs = plt.subplots(1, 4, figsize=(16, 8))\n",
    "\n",
    "axs[0].plot(history['epoch'], history['accuracy'], 'b', label='Training Accuracy')\n",
    "axs[0].plot(history['epoch'], history['val_accuracy'], 'r', label='Validation Accuracy')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Accuracy')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(history['epoch'], history['loss'], 'b', label='Training Loss')\n",
    "axs[1].plot(history['epoch'], history['val_loss'], 'r', label='Validation Loss')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[1].legend()\n",
    "\n",
    "axs[2].plot(history['epoch'], history['dice_coef'], 'b', label='Training dice coef')\n",
    "axs[2].plot(history['epoch'], history['val_dice_coef'], 'r', label='Validation dice coef')\n",
    "axs[2].set_xlabel('Epoch')\n",
    "axs[2].set_ylabel('Dice Coefficient')\n",
    "axs[2].legend()\n",
    "\n",
    "# axs[3].plot(history['epoch'], history['mean_io_u'], 'b', label='Training mean IOU')\n",
    "# axs[3].plot(history['epoch'], history['val_mean_io_u'], 'r', label='Validation mean IOU')\n",
    "# axs[3].set_xlabel('Epoch')\n",
    "# axs[3].set_ylabel('Mean IOU')\n",
    "# axs[3].legend()\n",
    "\n",
    "# Add space between subplots\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "plt.savefig(f'./plt/train/{plt_filename}.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICT_PLT_DIR = f'./plt/predict/{model_dir.split(\"./model/\")[1]}'\n",
    "if not os.path.exists(PREDICT_PLT_DIR):\n",
    "    os.makedirs(PREDICT_PLT_DIR)\n",
    "    print(f\"Dir {PREDICT_PLT_DIR} created.\")\n",
    "else:\n",
    "    print(f\"Dir {PREDICT_PLT_DIR} existed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "def find_latest_file(directory, pattern):\n",
    "    search_pattern = os.path.join(directory, pattern)\n",
    "    files = glob.glob(search_pattern)\n",
    "\n",
    "    if not files:\n",
    "        return None\n",
    "\n",
    "    latest_file = max(files, key=os.path.getmtime)\n",
    "\n",
    "    return latest_file\n",
    "\n",
    "PATTERN = 'model_epoch*-val_loss*_*.m5.index'\n",
    "\n",
    "latest_model_file = find_latest_file(f'{model_dir}', PATTERN)\n",
    "\n",
    "latest_trained_model = os.path.splitext(os.path.splitext(os.path.basename(latest_model_file))[0])[0]\n",
    "\n",
    "print(f'latest model file: {latest_trained_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile a model and load our saved weights\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "INPUT_LAYER = Input((IMG_SIZE, IMG_SIZE, N_CHANNELS))\n",
    "KER_INIT = KER_INIT\n",
    "DROPOUT = DROPOUT\n",
    "LEARNING_RATE = LEARNING_RATE\n",
    "\n",
    "best_saved_model = model_builders.get(MODEL_VERSION, unet_v1)(inputs=INPUT_LAYER, ker_init=KER_INIT, dropout=DROPOUT)\n",
    "\n",
    "best_saved_model.compile(loss=\"categorical_crossentropy\", optimizer=tensorflow.keras.optimizers.Adam(learning_rate=LEARNING_RATE), metrics = ['accuracy',tensorflow.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity] )\n",
    "\n",
    "\n",
    "best_saved_model.load_weights(f'{model_dir}/{latest_trained_model}.m5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_segmentation(sample_path):\n",
    "    # Load NIfTI (.nii) files of the sample (patient)\n",
    "    t1ce_path = sample_path + '-t1c.nii.gz'\n",
    "    flair_path = sample_path + '-t2f.nii.gz'\n",
    "    #t1_path = sample_path + '_t1.nii'\n",
    "    #t2_path = sample_path + '_t2.nii'\n",
    "            \n",
    "    # Extract the data from these paths\n",
    "    t1ce = nib.load(t1ce_path).get_fdata()\n",
    "    flair = nib.load(flair_path).get_fdata()\n",
    "    \n",
    "    # Create an empty array\n",
    "    X = np.empty((VOLUME_SLICES_PLUS, IMG_SIZE, IMG_SIZE, 2))\n",
    "    \n",
    "    # Perform the same operations as our DataGenerator, to keep the same input shape\n",
    "    for j in range(VOLUME_SLICES_PLUS):\n",
    "        X[j,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n",
    "        X[j,:,:,1] = cv2.resize(t1ce[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n",
    "        \n",
    "    # Send our images to the CNN model and return predicted segmentation \n",
    "    return model.predict(X/np.max(X), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predicted_segmentations(samples_list, slice_to_plot, cmap, norm):\n",
    "    # Choose a random patient\n",
    "    random_sample = random.choice(samples_list)\n",
    "    print(f'random_sample: {random_sample}')\n",
    "    \n",
    "    # Get path of this patient\n",
    "    random_sample_path = os.path.join(data_path_GLI_train_dir, random_sample, random_sample)\n",
    "    print(f'random_sample_path: {random_sample_path}')\n",
    "    \n",
    "    # Predict patient's segmentation\n",
    "    predicted_seg = predict_segmentation(random_sample_path)\n",
    "   \n",
    "    # Load patient's original segmentation (Ground truth)\n",
    "    seg_path = random_sample_path + '-seg.nii.gz'\n",
    "    seg = nib.load(seg_path).get_fdata()\n",
    "    \n",
    "    # Resize original segmentation to the same dimensions of the predictions. (Add VOLUME_START_AT because original segmentation contains 155 slices vs only 75 for our prediction)\n",
    "    seg=cv2.resize(seg[:,:,slice_to_plot+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_NEAREST)\n",
    "    \n",
    "    # Differentiate segmentations by their labels\n",
    "    all = predicted_seg[slice_to_plot,:,:,1:4] # Deletion of class 0 (Keep only Core + Edema + Enhancing classes)\n",
    "    zero = predicted_seg[slice_to_plot,:,:,0] # Isolation of class 0, Background (kind of useless, it is the opposite of the \"all\")\n",
    "    first = predicted_seg[slice_to_plot,:,:,1] # Isolation of class 1, Core\n",
    "    second = predicted_seg[slice_to_plot,:,:,2] # Isolation of class 2, Edema\n",
    "    third = predicted_seg[slice_to_plot,:,:,3] # Isolation of class 3, Enhancing\n",
    "\n",
    "    convert_all = all.astype(np.float32) if all.dtype == np.float16 else all\n",
    "    convert_zero = zero.astype(np.float32) if zero.dtype == np.float16 else zero\n",
    "    convert_first = first.astype(np.float32) if first.dtype == np.float16 else first\n",
    "    convert_second = second.astype(np.float32) if second.dtype == np.float16 else second\n",
    "    convert_third = third.astype(np.float32) if third.dtype == np.float16 else third\n",
    "\n",
    "    # Plot Original segmentation & predicted segmentation\n",
    "    print(\"Patient number: \", random_sample)\n",
    "    fig, axstest = plt.subplots(1, 6, figsize=(25, 20))\n",
    "\n",
    "    # Original segmentation\n",
    "    axstest[0].imshow(seg, cmap, norm)\n",
    "    axstest[0].set_title('Original Segmentation')\n",
    "    \n",
    "    # Layers 1, 2, 3\n",
    "    axstest[1].imshow(convert_all)\n",
    "    axstest[1].set_title('Predicted Segmentation - all layers')\n",
    "    \n",
    "    # Layer 0\n",
    "    axstest[2].imshow(convert_zero)\n",
    "    axstest[2].set_title('Predicted Segmentation - layer 0')\n",
    "    \n",
    "    # Layer 1\n",
    "    axstest[3].imshow(convert_first)\n",
    "    axstest[3].set_title('Predicted Segmentation - layer 1')\n",
    "    \n",
    "    # Layer 2\n",
    "    axstest[4].imshow(convert_second)\n",
    "    axstest[4].set_title('Predicted Segmentation - layer 2')\n",
    "    \n",
    "    # Layer 3\n",
    "    axstest[5].imshow(convert_third)\n",
    "    axstest[5].set_title('Predicted Segmentation - layer 3')\n",
    "    \n",
    "    # Add space between subplots\n",
    "    plt.subplots_adjust(wspace=0.8)\n",
    "\n",
    "    plt.savefig(f'{PREDICT_PLT_DIR}/{random_sample}.png', dpi=300)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "cmap = mpl.colors.ListedColormap(['#440054', '#3b528b', '#18b880', '#e6d74f'])\n",
    "norm = mpl.colors.BoundaryNorm([-0.5, 0.5, 1.5, 2.5, 3.5], cmap.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predicted_segmentations(datas_test, 60, cmap, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predicted_segmentations(datas_test, 50, cmap, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predicted_segmentations(datas_test, 70, cmap, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_post_processed_segmentations(sample, slice_to_plot, cmap, norm):\n",
    "    \n",
    "    # Get path of this patient\n",
    "    sample_path = os.path.join(data_path_GLI_train_dir, sample, sample)\n",
    "    \n",
    "    # Predict patient's segmentation\n",
    "    predicted_seg = predict_segmentation(sample_path)\n",
    "   \n",
    "    # Load patient's original segmentation (Ground truth)\n",
    "    seg_path = sample_path + '-seg.nii.gz'\n",
    "    seg = nib.load(seg_path).get_fdata()\n",
    "    \n",
    "    # Resize original segmentation to the same dimensions of the predictions. (Add VOLUME_START_AT because original segmentation contains 155 slices vs only 75 for our prediction)\n",
    "    seg=cv2.resize(seg[:,:,slice_to_plot+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_NEAREST)\n",
    "    \n",
    "    # Fix 4 to 3 to have the same values as in the predicted segmentation, and then same colors\n",
    "    seg[seg==4] = 3\n",
    "    \n",
    "    # Remove background layer (0) from original segmentation\n",
    "    seg[seg==0] = np.nan\n",
    "    \n",
    "    # Post-processing\n",
    "    # Get indexes for each class of the highest probability pixels. Array will then contain only [0 1 2 3] instead of probabilities\n",
    "    my_pred = np.argmax(predicted_seg, axis=3)\n",
    "    my_pred = my_pred[slice_to_plot, :, :]\n",
    "\n",
    "    # Remove background layer (0) from post-processed predicted segmentation\n",
    "    # To fix 0 to np.nan, we need to convert array as a float\n",
    "    my_pred = my_pred.astype(float)\n",
    "    my_pred[my_pred == 0] = np.nan\n",
    "\n",
    "    # Remove background layer (0) from classical predicted segmentation\n",
    "    all = predicted_seg[slice_to_plot,:,:,1:4] \n",
    "\n",
    "    convert_all = all.astype(np.float32) if all.dtype == np.float16 else all\n",
    "    \n",
    "    # Plot Original segmentation & predicted segmentation without processing & predicted segmentation\n",
    "    print(\"Patient number: \", sample)\n",
    "    fig, axstest = plt.subplots(1, 3, figsize=(15, 10))\n",
    "\n",
    "    axstest[0].imshow(seg, cmap, norm)\n",
    "    axstest[0].set_title('Original Segmentation')\n",
    "    \n",
    "    axstest[1].imshow(convert_all)\n",
    "    axstest[1].set_title('Prediction (w/o post processing (layer 1,2,3)')\n",
    "    \n",
    "    axstest[2].imshow(my_pred, cmap, norm)\n",
    "    axstest[2].set_title('Prediction (w/ post processing (layer 1,2,3)')\n",
    "    \n",
    "    # Add space between subplots\n",
    "    plt.subplots_adjust(wspace=0.8)\n",
    "    plt.savefig(f'{PREDICT_PLT_DIR}/{sample}.png', dpi=300)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_post_processed_segmentations(sample = \"BraTS-GLI-00777-000\", slice_to_plot=60, cmap=cmap, norm=norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_post_processed_segmentations(sample = \"BraTS-GLI-00675-000\", slice_to_plot=50, cmap=cmap, norm=norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 - Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Evaluate the model on the test data\n",
    "test_generator = data_generators.get(DATA_GENERATOR_VERSION, DataGenerator_UnetV1)(TEST_PKL if DATA_GENERATOR_VERSION == 3 else datas_test)\n",
    "results = model.evaluate(test_generator, batch_size=200, callbacks= callbacks)\n",
    "\n",
    "descriptions = [\"Loss\", \"Accuracy\", \"MeanIOU\", \"Dice coefficient\", \"Precision\", \"Sensitivity\", \"Specificity\"]\n",
    "\n",
    "# Combine results list and descriptions list\n",
    "results_list = zip(results, descriptions)\n",
    "\n",
    "print(\"\\nModel evaluation on the test set:\")\n",
    "\n",
    "original_stdout = sys.stdout\n",
    "with open(f'{model_dir}/predict_result.log', 'w') as predict_log_file:\n",
    "    sys.stdout = predict_log_file\n",
    "\n",
    "    # Display each metric with its description\n",
    "    print(\"==================================\")\n",
    "    for i, (metric, description) in enumerate(results_list):\n",
    "        print(f\"{description} : {round(metric, 4)}\")\n",
    "    print(\"==================================\")\n",
    "\n",
    "sys.stdout = original_stdout"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aa84e851cfc8b4ce9eea0fba0960fb7c512de47d9926a3aadb9d11b047583128"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
