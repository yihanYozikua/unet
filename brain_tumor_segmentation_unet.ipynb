{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 5px solid green; padding: 10px; background-color:rgb(224, 247, 206);\">\n",
    "    <b>⚡️ Information:</b>\n",
    "    Yihan's customized unet experiment\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0 - Set & Check available memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limited GPU memory usage to 12GB\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "MEMORY_SIZE = 12\n",
    "memory_limit = MEMORY_SIZE * 1024\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memory_limit)]  # Set limit to 8GB\n",
    "        )\n",
    "        print(f\"Limited GPU memory usage to {MEMORY_SIZE}GB\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: GPU:0\n",
      "Current Memory Usage: 0 bytes\n",
      "Peak Memory Usage: 0 bytes\n",
      "Memory growth for PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'): None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        device_name = f\"GPU:{i}\"  # Properly format the device name\n",
    "        details = tf.config.experimental.get_memory_info(device_name)\n",
    "        print(f\"GPU: {device_name}\")\n",
    "        print(f\"Current Memory Usage: {details['current']} bytes\")\n",
    "        print(f\"Peak Memory Usage: {details['peak']} bytes\")\n",
    "else:\n",
    "    print(\"No GPU devices found.\")\n",
    "\n",
    "for gpu in gpus:\n",
    "    print(f\"Memory growth for {gpu}: {tf.config.experimental.get_memory_growth(gpu)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from skimage.transform import rotate\n",
    "from skimage.util import montage\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import cv2\n",
    "import tensorflow\n",
    "import random\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "import numpy as np\n",
    "from keras.callbacks import CSVLogger\n",
    "import keras.backend as K\n",
    "import zipfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### paths, VOLUME_*, IMG_SIZE, N_CHANNELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a sample path (here we will take the first patient of the Training dataset)\n",
    "brats_index = 'BraTS-GLI-00077-000'\n",
    "brats_sample_path = f'../brain_tumor_seg/data/raw_data/GLI_train/{brats_index}/{brats_index}-'\n",
    "\n",
    "# Specify the root data path of training data\n",
    "data_path_GLI_train_dir = f'../brain_tumor_seg/data/raw_data/GLI_train'\n",
    "\n",
    "\n",
    "# Define selected slices range\n",
    "VOLUME_START_AT = 0 \n",
    "VOLUME_SLICES_PLUS = 155 \n",
    "TUMOR_RATIO_LOWER_BOUND = 0.10\n",
    "TUMOR_RATIO_UPPER_BOUND = 0.15\n",
    "\n",
    "# For DataGenerator\n",
    "IMG_SIZE = 128\n",
    "N_CHANNELS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not a Step - Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 4 MRI modalities and the segmentation located in the patient's path using the nibabel library\n",
    "t1_img_sample=nib.load(brats_sample_path + 't1n.nii.gz')\n",
    "t1ce_img_sample=nib.load(brats_sample_path + 't1c.nii.gz')\n",
    "t2_img_sample=nib.load(brats_sample_path + 't2w.nii.gz')\n",
    "flair_img_sample=nib.load(brats_sample_path + 't2f.nii.gz')\n",
    "seg_img_sample=nib.load(brats_sample_path + 'seg.nii.gz')\n",
    "\n",
    "# Get the image data\n",
    "t1_data_sample = t1_img_sample.get_fdata()\n",
    "t1ce_data_sample = t1ce_img_sample.get_fdata()\n",
    "t2_data_sample = t2_img_sample.get_fdata()\n",
    "flair_data_sample = flair_img_sample.get_fdata()\n",
    "seg_data_sample = seg_img_sample.get_fdata()\n",
    "\n",
    "# Plot the 100th slice of the 4 RMI modalities and the segmentation\n",
    "slice_nb = 100\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(20,20))\n",
    "axs[0].imshow(t1_data_sample[:,:,slice_nb], cmap=\"gray\")\n",
    "axs[0].set_title('T1')\n",
    "axs[1].imshow(t1ce_data_sample[:,:,slice_nb], cmap=\"gray\")\n",
    "axs[1].set_title('T1CE')\n",
    "axs[2].imshow(t2_data_sample[:,:,slice_nb], cmap=\"gray\")\n",
    "axs[2].set_title('T2')\n",
    "axs[3].imshow(flair_data_sample[:,:,slice_nb], cmap=\"gray\")\n",
    "axs[3].set_title('FLAIR')\n",
    "axs[4].imshow(seg_data_sample[:,:,slice_nb], cmap=\"gray\")\n",
    "axs[4].set_title('Segmentation')\n",
    "plt.savefig(f'./plt/seg_classes_{brats_index}.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a RMI modality through all planes\n",
    "slice_nb = 100\n",
    "\n",
    "fig, axs2 = plt.subplots(1, 3, figsize=(10,10))\n",
    "\n",
    "# Apply a 90° rotation with an automatic resizing, otherwise the display is less obvious to analyze\n",
    "axs2[0].imshow(rotate(t1_data_sample[slice_nb,:,:], 90, resize=True), cmap=\"gray\")\n",
    "axs2[0].set_title('T1 - Sagittal View')\n",
    "\n",
    "axs2[1].imshow(rotate(t1_data_sample[:,slice_nb,:], 90, resize=True), cmap=\"gray\")\n",
    "axs2[1].set_title('T1 - Coronal View')\n",
    "\n",
    "axs2[2].imshow(t1_data_sample[:,:,slice_nb], cmap=\"gray\")\n",
    "axs2[2].set_title('T1 - Axial View')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize = (15,15))\n",
    "ax1.imshow(rotate(montage(t1_data_sample[:,:,:]), 90, resize=True), cmap ='gray')\n",
    "\n",
    "# montage allows us to concatenate multiple images of the same size horizontally and vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all slices of a segmentation\n",
    "fig, ax1 = plt.subplots(1, 1, figsize = (15,15))\n",
    "ax1.imshow(rotate(montage(seg_data_sample[:,:,:]), 90, resize=True), cmap ='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize = (15,15))\n",
    "ax1.imshow(rotate(montage(t1_data_sample[60:135,:,:]), 90, resize=True), cmap ='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a segmantation\n",
    "some_seg_img = nib.load(f'{brats_sample_path}seg.nii.gz').get_fdata()\n",
    "\n",
    "cmap = mpl.colors.ListedColormap(['#440054', '#3b528b', '#18b880', '#e6d74f'])\n",
    "norm = mpl.colors.BoundaryNorm([-0.5, 0.5, 1.5, 2.5, 3.5], cmap.N)\n",
    "\n",
    "plt.imshow(some_seg_img[100,:,:], cmap=cmap, norm=norm)\n",
    "plt.title(brats_index)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_samples = [os.path.join(data_path_GLI_train_dir, sample, f\"{sample}-seg.nii.gz\") for sample in os.listdir(data_path_GLI_train_dir) if not sample.endswith('.csv')]\n",
    "\n",
    "saved_values = []\n",
    "max_nb_values = 0\n",
    "for sample in seg_samples:\n",
    "    seg_img_sample = nib.load(sample).get_fdata()\n",
    "    unique_values = np.unique(seg_img_sample)\n",
    "    nb_unique_values = len(np.unique(seg_img_sample))\n",
    "    \n",
    "    if nb_unique_values > max_nb_values:\n",
    "        max_nb_values = nb_unique_values\n",
    "        saved_values = unique_values\n",
    "\n",
    "print(f\"Maximum number of values in all segmentation images: {max_nb_values}\")\n",
    "print(f\"Values: {saved_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletion of class 0\n",
    "seg_0 = some_seg_img.astype(float).copy()\n",
    "seg_0[seg_0 != 0] = np.nan\n",
    "\n",
    "# Isolation of class 1\n",
    "seg_1 = some_seg_img.astype(float).copy()\n",
    "seg_1[seg_1 != 1] = np.nan\n",
    "\n",
    "# Isolation of class 2\n",
    "seg_2 = some_seg_img.astype(float).copy()\n",
    "seg_2[seg_2 != 2] = np.nan\n",
    "\n",
    "# Isolation of class 4\n",
    "seg_3 = some_seg_img.astype(float).copy()\n",
    "seg_3[seg_3 != 4] = np.nan\n",
    "\n",
    "# Define legend\n",
    "class_names = ['class 0', 'class 1', 'class 2', 'class 3']\n",
    "legend = [plt.Rectangle((0, 0), 1, 1, color=cmap(i), label=class_names[i]) for i in range(len(class_names))]\n",
    "\n",
    "fig, axs3 = plt.subplots(1, 5, figsize=(15, 15))\n",
    "\n",
    "axs3[0].imshow(some_seg_img[100,:,:], cmap=cmap, norm=norm)\n",
    "axs3[0].set_title('Original Segmentation')\n",
    "axs3[0].legend(handles=legend, loc='upper right')\n",
    "\n",
    "axs3[1].imshow(seg_0[100,:,:], cmap=cmap, norm=norm)\n",
    "axs3[1].set_title('[Not Tumor] class 0')\n",
    "\n",
    "axs3[2].imshow(seg_1[100,:,:], cmap=cmap, norm=norm)\n",
    "axs3[2].set_title('[NCR] class 1')\n",
    "\n",
    "axs3[3].imshow(seg_2[100,:,:], cmap=cmap, norm=norm)\n",
    "axs3[3].set_title('[ED] class 2')\n",
    "\n",
    "axs3[4].imshow(seg_3[100,:,:], cmap=cmap, norm=norm)\n",
    "axs3[4].set_title('[ET] class 3')\n",
    "\n",
    "# Save the figure to a file\n",
    "plt.savefig('segmentation_classes.png', dpi=300)  # Saves the image as 'segmentation_classes.png'\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, counts = np.unique(some_seg_img, return_counts=True)\n",
    "print(f'distribution of 4 classes: {counts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modality shape\n",
    "print(f'modality shape: {t1_data_sample.shape}')\n",
    "\n",
    "# Segmentation shape\n",
    "print(f'segmentation shape: {seg_data_sample.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Load images and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 1251\n"
     ]
    }
   ],
   "source": [
    "# Retrieve all samples from path with listdir(). This method lists of all files + directories in the specified directory.\n",
    "all_datas = os.listdir(data_path_GLI_train_dir)\n",
    "print(\"Number of samples:\", len(all_datas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train length: 850\n",
      "Validation length: 251\n",
      "Test length: 150\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into train and validation sets\n",
    "datas_train, datas_val = train_test_split(all_datas, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the train set into the real train set and in a test set \n",
    "datas_train, datas_test = train_test_split(datas_train, test_size=0.15, random_state=42)\n",
    "\n",
    "# Print data distribution (Train: 68%, Test: 12%, Val: 20%)\n",
    "print(f\"Train length: {len(datas_train)}\")\n",
    "print(f\"Validation length: {len(datas_val)}\")\n",
    "print(f\"Test length: {len(datas_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: keras\n",
      "Version: 2.7.0\n",
      "Summary: Deep learning for humans.\n",
      "Home-page: https://keras.io/\n",
      "Author: Keras team\n",
      "Author-email: keras-users@googlegroups.com\n",
      "License: Apache 2.0\n",
      "Location: /home/cbel/Desktop/YIHAN/venv/lib/python3.8/site-packages\n",
      "Requires: \n",
      "Required-by: tensorflow\n",
      "---\n",
      "Name: tensorflow\n",
      "Version: 2.7.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /home/cbel/Desktop/YIHAN/venv/lib/python3.8/site-packages\n",
      "Requires: keras, wheel, libclang, protobuf, flatbuffers, six, astunparse, termcolor, gast, tensorflow-estimator, keras-preprocessing, tensorboard, h5py, opt-einsum, typing-extensions, wrapt, google-pasta, numpy, absl-py, grpcio, tensorflow-io-gcs-filesystem\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show keras tensorflow # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "tensorflow version: 2.7.0\n",
      "is built with CUDA: True\n",
      "GPU details: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU is available.\n",
      "===============================\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"===============================\")\n",
    "print(f'tensorflow version: {tf.__version__}')  # Should print 2.7.0\n",
    "print(f'is built with CUDA: {tf.test.is_built_with_cuda()}')  # Should return True\n",
    "print(f'GPU details: {tf.config.list_physical_devices(\"GPU\")}')  # Should show GPU details\n",
    "\n",
    "# Check if TensorFlow can detect a GPU\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available.\")\n",
    "else:\n",
    "    print(\"GPU is not available.\")\n",
    "\n",
    "print(\"===============================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step * Crop Nii files (skip if already done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dir processed_data existed.\n",
      "train: 11159 slices\n",
      "val: 3232 slices\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import nibabel as nib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "if not os.path.exists('./processed_data'):\n",
    "    os.makedirs('./processed_data')\n",
    "    print(\"Model dir processed_data created.\")\n",
    "else:\n",
    "    print(\"Model dir processed_data existed.\")\n",
    "\n",
    "total_slices_dict = {\n",
    "    \"train\": 0,\n",
    "    \"val\": 0,\n",
    "    \"test\": 0\n",
    "}\n",
    "\n",
    "def preprocess_and_save(data_list, save_path, log_path, tumor_ratio_lower_bound, tumor_ratio_upper_bound):\n",
    "    processed_data = {'X': [], 'y': []}\n",
    "    slice_info = {}  # Dictionary to store slice information for each NIfTI\n",
    "\n",
    "    with open(log_path, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(['NIfTI ID', 'Slice Index', 'Tumor Ratio', 'Brain Area'])\n",
    "\n",
    "        total_slices = 0\n",
    "\n",
    "        for i in data_list:\n",
    "            data_path = os.path.join(data_path_GLI_train_dir, i, i)\n",
    "            t1ce_path = data_path + '-t1c.nii.gz'\n",
    "            flair_path = data_path + '-t2f.nii.gz'\n",
    "            seg_path = data_path + '-seg.nii.gz'\n",
    "            \n",
    "            t1ce = nib.load(t1ce_path).get_fdata()\n",
    "            flair = nib.load(flair_path).get_fdata()\n",
    "            seg = nib.load(seg_path).get_fdata()\n",
    "\n",
    "            slice_info[i] = []  # Initialize list for each NIfTI\n",
    "\n",
    "            for j in range(VOLUME_SLICES_PLUS):\n",
    "                slice_seg = seg[:, :, j + VOLUME_START_AT]\n",
    "                slice_flair = flair[:, :, j + VOLUME_START_AT]\n",
    "                tumor_area = np.sum(slice_seg > 0)\n",
    "                brain_area = np.sum(slice_flair > 0)  # Use non-zero pixels in FLAIR as brain area\n",
    "\n",
    "                # Avoid division by zero\n",
    "                if brain_area == 0:\n",
    "                    continue\n",
    "\n",
    "                tumor_percentage = tumor_area / brain_area\n",
    "\n",
    "                if tumor_ratio_lower_bound < tumor_percentage <= tumor_ratio_upper_bound:\n",
    "                    X_slice = np.zeros((IMG_SIZE, IMG_SIZE, N_CHANNELS))\n",
    "                    X_slice[:, :, 0] = cv2.resize(slice_flair, (IMG_SIZE, IMG_SIZE))\n",
    "                    X_slice[:, :, 1] = cv2.resize(t1ce[:, :, j + VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n",
    "                    processed_data['X'].append(X_slice)\n",
    "                    processed_data['y'].append(slice_seg)\n",
    "                    slice_info[i].append(j + VOLUME_START_AT)  # Record the slice index\n",
    "\n",
    "                    # Write slice information to CSV file\n",
    "                    csv_writer.writerow([i, j + VOLUME_START_AT, round(tumor_percentage, 4), brain_area])\n",
    "                    total_slices += 1\n",
    "\n",
    "        total_slices_dict[log_path.split('/')[-1].split('_')[0]] = total_slices\n",
    "\n",
    "    # Save the processed data\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(processed_data, f)\n",
    "\n",
    "# Example usage\n",
    "preprocess_and_save(datas_train, './processed_data/processed_train_data.pkl', './processed_data/train_data_info.csv', tumor_ratio_lower_bound=TUMOR_RATIO_LOWER_BOUND, tumor_ratio_upper_bound=TUMOR_RATIO_UPPER_BOUND)\n",
    "preprocess_and_save(datas_val, './processed_data/processed_val_data.pkl', './processed_data/val_data_info.csv', tumor_ratio_lower_bound=TUMOR_RATIO_LOWER_BOUND, tumor_ratio_upper_bound=TUMOR_RATIO_UPPER_BOUND)\n",
    "\n",
    "print(f'train: {total_slices_dict[\"train\"]} slices')\n",
    "print(f'val: {total_slices_dict[\"val\"]} slices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Set up training compoenents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When generating `DataGenerator`**:\n",
    "- We use a data generator to be able to process and send our data to our neural network (since all our images cannot be stored in memory at once).\n",
    "- For each epoch (single pass of the entire training dataset through a neural network), the model will receive 250 samples (those contained in our training dataset).\n",
    "- For each sample, the model will have to analyze 150 slices (since there are two modalities, and 75(VOLUME_SLICES) selected slices for both of them), received in a (128, 128) shape, as an X array of a (128, 128, 75, 2) shape. This array will be provided with the ground truth segmentation of the patient, which will be One-Hot encoded and will then have a (75, 128, 128, 4) shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 1: DataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-1-1 DataGenerator_UnetV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# DataGenerator from Rastislav's notebook, https://www.kaggle.com/code/rastislav/3d-mri-brain-tumor-segmentation-u-net\n",
    "\n",
    "class DataGenerator_UnetV1(keras.utils.all_utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = N_CHANNELS, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim # Resized image dimensions (128 x 128)\n",
    "        self.batch_size = batch_size #  Number of images to load each time\n",
    "        self.list_IDs = list_IDs # Patients IDs\n",
    "        self.n_channels = n_channels # Number of channels (T1CE + FLAIR)\n",
    "        self.shuffle = shuffle # Indicates if data is shuffled for each epoch\n",
    "        self.on_epoch_end() # Updates indexes after each epoch\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Load & Generate data\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        'Generates data containing batch_size samples'\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size*VOLUME_SLICES_PLUS, *self.dim, self.n_channels))\n",
    "        y = np.zeros((self.batch_size*VOLUME_SLICES_PLUS, 240, 240))\n",
    "\n",
    "        # Generate data\n",
    "        for c, i in enumerate(Batch_ids):\n",
    "            \n",
    "            # Get path of each RMI modality and the segmentation\n",
    "            data_path = os.path.join(data_path_GLI_train_dir, i, i)\n",
    "            t1ce_path = data_path + '-t1c.nii.gz'\n",
    "            flair_path = data_path + '-t2f.nii.gz'\n",
    "            seg_path = data_path + '-seg.nii.gz'\n",
    "            #t1_path = sample_path + '_t1.nii.gz'\n",
    "            #t2_path = sample_path + '_t2.nii.gz'\n",
    "            \n",
    "            # Extract the data from these paths\n",
    "            t1ce = nib.load(t1ce_path).get_fdata()\n",
    "            flair = nib.load(flair_path).get_fdata()\n",
    "            seg = nib.load(seg_path).get_fdata()\n",
    "            #t1 = nib.load(t1_paths).get_fdata()\n",
    "            #t2 = nib.load(t2_path).get_fdata()\n",
    "        \n",
    "            for j in range(VOLUME_SLICES_PLUS):\n",
    "                 X[j +VOLUME_SLICES_PLUS*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n",
    "                 X[j +VOLUME_SLICES_PLUS*c,:,:,1] = cv2.resize(t1ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "                 y[j +VOLUME_SLICES_PLUS*c] = seg[:,:,j+VOLUME_START_AT]\n",
    "                    \n",
    "        # Masks / Segmentations\n",
    "        y[y==4] = 3\n",
    "        mask = tensorflow.one_hot(y, 4)\n",
    "        Y = tensorflow.image.resize(mask, (IMG_SIZE, IMG_SIZE))\n",
    "        \n",
    "        # Scale data between 0 and 1 (since the minimum value in the data is 0)\n",
    "        return X/np.max(X), Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-1-2 DataGenerator_UnetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# DataGenerator from Rastislav's notebook, https://www.kaggle.com/code/rastislav/3d-mri-brain-tumor-segmentation-u-net\n",
    "\n",
    "class DataGenerator_UnetV2(keras.utils.all_utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = N_CHANNELS, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim # Resized image dimensions (128 x 128)\n",
    "        self.batch_size = batch_size #  Number of images to load each time\n",
    "        self.list_IDs = list_IDs # Patients IDs\n",
    "        self.n_channels = n_channels # Number of channels (T1CE + FLAIR)\n",
    "        self.shuffle = shuffle # Indicates if data is shuffled for each epoch\n",
    "        self.on_epoch_end() # Updates indexes after each epoch\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Load & Generate data\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        'Generates data containing batch_size samples'\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size*VOLUME_SLICES_PLUS, *self.dim, self.n_channels))\n",
    "        y = np.zeros((self.batch_size*VOLUME_SLICES_PLUS, 240, 240))\n",
    "\n",
    "        # Generate data\n",
    "        for c, i in enumerate(Batch_ids):\n",
    "            \n",
    "            # Get path of each RMI modality and the segmentation\n",
    "            data_path = os.path.join(data_path_GLI_train_dir, i, i)\n",
    "            t1ce_path = data_path + '-t1c.nii.gz'\n",
    "            flair_path = data_path + '-t2f.nii.gz'\n",
    "            seg_path = data_path + '-seg.nii.gz'\n",
    "            #t1_path = sample_path + '_t1.nii.gz'\n",
    "            #t2_path = sample_path + '_t2.nii.gz'\n",
    "            \n",
    "            # Extract the data from these paths\n",
    "            t1ce = nib.load(t1ce_path).get_fdata()\n",
    "            flair = nib.load(flair_path).get_fdata()\n",
    "            seg = nib.load(seg_path).get_fdata()\n",
    "            #t1 = nib.load(t1_paths).get_fdata()\n",
    "            #t2 = nib.load(t2_path).get_fdata()\n",
    "        \n",
    "            for j in range(VOLUME_SLICES_PLUS):\n",
    "                 X[j +VOLUME_SLICES_PLUS*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "                 y[j +VOLUME_SLICES_PLUS*c] = seg[:,:,j+VOLUME_START_AT]\n",
    "                    \n",
    "        # Masks / Segmentations\n",
    "        y[y==4] = 3\n",
    "        mask = tensorflow.one_hot(y, 4)\n",
    "        Y = tensorflow.image.resize(mask, (IMG_SIZE, IMG_SIZE))\n",
    "        \n",
    "        # Scale data between 0 and 1 (since the minimum value in the data is 0)\n",
    "        return X/np.max(X), Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-1-3 DataGenerator_UnetV3_count_image_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# DataGenerator from Rastislav's notebook, https://www.kaggle.com/code/rastislav/3d-mri-brain-tumor-segmentation-u-net\n",
    "\n",
    "class DataGenerator_UnetV3_count_image_ratio(keras.utils.all_utils.Sequence):\n",
    "    def __init__(self, data_path, batch_size=1, shuffle=True):\n",
    "        with open(data_path, 'rb') as f:\n",
    "            self.data = pickle.load(f)\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(self.data['X']))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.data['X']) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        X_batch = [self.data['X'][k] for k in indexes]\n",
    "        y_batch = [self.data['y'][k] for k in indexes]\n",
    "\n",
    "        y_batch = np.array(y_batch)\n",
    "        y_batch[y_batch == 4] = 3\n",
    "        mask = tensorflow.one_hot(y_batch, 4)\n",
    "        Y = tensorflow.image.resize(mask, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        return np.array(X_batch) / np.max(X_batch), Y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 -2: U-Net model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-2-1 U-Net v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net implementation for BraTS 2019 by Naomi Fridman, https://naomi-fridman.medium.com/multi-class-image-segmentation-a5cc671e647a\n",
    "def unet_v1(inputs, ker_init, dropout):\n",
    "    print('****** using U-Net V1 ******')\n",
    "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(inputs)\n",
    "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv1)\n",
    "    \n",
    "    pool = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool)\n",
    "    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv2)\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv3)\n",
    "    \n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool4)\n",
    "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv5)\n",
    "    drop5 = Dropout(dropout)(conv5)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = 2)(drop5))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = 2)(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = 2)(conv8))\n",
    "    merge9 = concatenate([conv,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n",
    "    \n",
    "    up = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = 2)(conv9))\n",
    "    merge = concatenate([conv1,up], axis = 3)\n",
    "    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge)\n",
    "    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n",
    "    \n",
    "    conv10 = Conv2D(4, 1, activation = 'softmax')(conv)\n",
    "    \n",
    "    return Model(inputs = inputs, outputs = conv10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-2-2: U-Net V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_v2(inputs, ker_init, dropout=0.5):\n",
    "    print('****** using U-Net V2 ******')\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv1)\n",
    "\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv2)\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv3)\n",
    "    \n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv4)\n",
    "    drop4 = Dropout(dropout)(conv4)\n",
    "    \n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv5)\n",
    "    drop5 = Dropout(dropout)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n",
    "\n",
    "    conv10 = Conv2D(4, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    return Model(inputs = inputs, outputs = conv10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 3: Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metric between the predicted segmentation and the ground truth\n",
    "def dice_coef(y_true, y_pred, smooth=1.0):\n",
    "    class_num = 4\n",
    "    for i in range(class_num):\n",
    "        y_true_f = K.flatten(y_true[:,:,:,i])\n",
    "        y_pred_f = K.flatten(y_pred[:,:,:,i])\n",
    "        intersection = K.sum(y_true_f * y_pred_f)\n",
    "        loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n",
    "        if i == 0:\n",
    "            total_loss = loss\n",
    "        else:\n",
    "            total_loss = total_loss + loss\n",
    "    total_loss = total_loss / class_num\n",
    "    return total_loss\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())\n",
    "\n",
    "########################### my customized metrics ###########################\n",
    "\n",
    "def sensibility(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    false_positives = K.sum(K.round(K.clip(y_pred - y_true, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    # Calculate the sensibility\n",
    "    sensibility = 1 - (false_positives / (true_positives + possible_positives + K.epsilon()))\n",
    "    # Check for NaN or Inf values and return NaN if True\n",
    "    sensibility = tf.where(tf.math.is_nan(sensibility) | tf.math.is_inf(sensibility),\n",
    "                           tf.constant(float('NaN')),\n",
    "                           sensibility)\n",
    "    return sensibility\n",
    "\n",
    "\n",
    "def jaccard(y_true, y_pred):\n",
    "    # True positives, false positives, false negatives\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    false_positives = K.sum(K.round(K.clip(y_pred - y_true, 0, 1)))\n",
    "    false_negatives = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)))\n",
    "    # Calculate Jaccard index\n",
    "    denominator = true_positives + false_positives + false_negatives + K.epsilon()  # Add epsilon to avoid division by zero\n",
    "    result = true_positives / denominator\n",
    "    # Handle NaN or Inf cases\n",
    "    result = K.switch(K.is_inf(result) | K.is_nan(result), K.constant(float('NaN')), result)\n",
    "    return result\n",
    "\n",
    "\n",
    "# Hausdorff distance (approximation for use in Keras)\n",
    "def hausdorff(y_true, y_pred):\n",
    "    # Flatten the coordinates of the true and predicted segmentation masks\n",
    "    y_true_flat = K.flatten(y_true)\n",
    "    y_pred_flat = K.flatten(y_pred)\n",
    "    # Compute the Euclidean distance between every pair of points\n",
    "    dist_matrix = K.square(y_true_flat - y_pred_flat)\n",
    "    # Get the maximum distance in both directions (directed Hausdorff)\n",
    "    directed_hausdorff_1 = K.max(dist_matrix, axis=1)  # From y_true to y_pred\n",
    "    directed_hausdorff_2 = K.max(dist_matrix, axis=0)  # From y_pred to y_true\n",
    "    # Take the maximum of both directed Hausdorff distances\n",
    "    hausdorff_dist = K.maximum(directed_hausdorff_1, directed_hausdorff_2)\n",
    "    # Handle NaN or Inf values by replacing them with NaN (if needed)\n",
    "    hausdorff_dist = K.switch(K.is_inf(hausdorff_dist) | K.is_nan(hausdorff_dist), K.constant(float('NaN')), hausdorff_dist)\n",
    "    return hausdorff_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 4: Define training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input\n",
    "\n",
    "MODEL_VERSION = 1\n",
    "DATA_GENERATOR_VERSION = 3\n",
    "\n",
    "EPOCHS = 100\n",
    "STEPS_PER_EPOCH = len(datas_train)\n",
    "\n",
    "INPUT_LAYER = Input((IMG_SIZE, IMG_SIZE, N_CHANNELS))\n",
    "KER_INIT = 'he_normal'\n",
    "DROPOUT = 0.2\n",
    "LEARNING_RATE = 1e-4\n",
    "LOSS_FUNCTION = \"categorical_crossentropy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 5: Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** using U-Net V1 ******\n"
     ]
    }
   ],
   "source": [
    "# Build and compile the model\n",
    "model_builders = {\n",
    "    1: unet_v1,\n",
    "    2: unet_v2\n",
    "}\n",
    "model = model_builders.get(MODEL_VERSION, unet_v1)(inputs=INPUT_LAYER, ker_init=KER_INIT, dropout=DROPOUT)\n",
    "\n",
    "model.compile(loss=LOSS_FUNCTION, optimizer=tensorflow.keras.optimizers.Adam(learning_rate=LEARNING_RATE), metrics = ['accuracy',tensorflow.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 6: Set up DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generators = {\n",
    "    1: DataGenerator_UnetV1,\n",
    "    2: DataGenerator_UnetV2,\n",
    "    3: DataGenerator_UnetV3_count_image_ratio\n",
    "}\n",
    "\n",
    "training_generator = data_generators.get(DATA_GENERATOR_VERSION, DataGenerator_UnetV1)('./processed_data/processed_train_data.pkl' if DATA_GENERATOR_VERSION == 3 else datas_train)\n",
    "valid_generator = data_generators.get(DATA_GENERATOR_VERSION, DataGenerator_UnetV1)('./processed_data/processed_val_data.pkl' if DATA_GENERATOR_VERSION == 3 else datas_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 7: Do the GC and check the GPU and memory status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: GPU:0\n",
      "Current Memory Usage: 31040804 bytes\n",
      "Peak Memory Usage: 37721124 bytes\n",
      "Memory growth for PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'): None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        device_name = f\"GPU:{i}\"  # Properly format the device name\n",
    "        details = tf.config.experimental.get_memory_info(device_name)\n",
    "        print(f\"GPU: {device_name}\")\n",
    "        print(f\"Current Memory Usage: {details['current']} bytes\")\n",
    "        print(f\"Peak Memory Usage: {details['peak']} bytes\")\n",
    "else:\n",
    "    print(\"No GPU devices found.\")\n",
    "\n",
    "for gpu in gpus:\n",
    "    print(f\"Memory growth for {gpu}: {tf.config.experimental.get_memory_growth(gpu)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090, compute capability 8.6\n",
      "WARNING:tensorflow:From /home/cbel/Desktop/YIHAN/venv/lib/python3.8/site-packages/keras/mixed_precision/loss_scale.py:52: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 23:45:26.566338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "# Mixed Precision Training\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 8: Set up callbacks\n",
    "\n",
    "Callbacks are functions that can be executed during the training process. \n",
    "\n",
    "We will use three callbacks:\n",
    "\n",
    "- **ReduceLROnPlateau**: This callback reduces the learning rate when a metric has stopped improving (validation loss here). The learning rate is reduced by a factor of 0.2, the patience is set to 2 epochs, and the minimum learning rate is set to 0.000001.\n",
    "\n",
    "- **ModelCheckpoint**: Saves the best model weights (model that has obtained the lowest validation loss during the different epochs). Saving a model allows us to reuse it later or to share it, without having to retrain it from scratch. This will save us time and resources!\n",
    "\n",
    "- **CSVLogger**: Add metrics to a CSV file, which is named *training.log* (parameter `append` is set to `False` so the file is overwritten if it already exists). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dir ./model/model_v1_Mar-12_23-45-26 created.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Generate timestamp for filenames\n",
    "start_train_timestamp = datetime.now().strftime(\"%b-%d_%H-%M-%S\")\n",
    "\n",
    "model_dir = f'./model/model_v{MODEL_VERSION}_{start_train_timestamp}'\n",
    "\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    print(f\"Model dir {model_dir} created.\")\n",
    "else:\n",
    "    print(f\"Model dir {model_dir} existed.\")\n",
    "\n",
    "# Define file paths with timestamps\n",
    "training_log_filename = f\"{model_dir}/training-{start_train_timestamp}.log\"\n",
    "model_checkpoint_path = f\"{model_dir}/model_epoch{{epoch:02d}}-val_loss{{val_loss:.6f}}_{start_train_timestamp}.m5\"\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.000001, verbose=1),\n",
    "    \n",
    "    keras.callbacks.ModelCheckpoint(filepath=model_checkpoint_path, verbose=1, save_best_only=True, save_weights_only=True),\n",
    "\n",
    "    CSVLogger(training_log_filename, separator=',', append=False)  # Save logs with timestamp\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Train & Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - 1: log all cell outputs during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "model name: unet_v1\n",
      "epochs: 100\n",
      "steps_per_epoch: 850\n",
      "dimension: 128\n",
      "n_channels: 2\n",
      "input layer: KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 2), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
      "kernel init: he_normal\n",
      "dropout: 0.2\n",
      "learning rate: 0.0001\n",
      "loss function: categorical_crossentropy\n",
      "train cases: 850\n",
      "train slices: 11159\n",
      "validation cases: 251\n",
      "val slices: 3232\n",
      "test cases: 150\n",
      "start training at: Mar-12_23-45-26\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(f'----------')\n",
    "print(f'model name: {model_builders[MODEL_VERSION].__name__}')\n",
    "print(f'epochs: {EPOCHS}')\n",
    "print(f'steps_per_epoch: {STEPS_PER_EPOCH}')\n",
    "print(f'dimension: {IMG_SIZE}')\n",
    "print(f'n_channels: {N_CHANNELS}')\n",
    "print(f'input layer: {INPUT_LAYER}')\n",
    "print(f'kernel init: {KER_INIT}')\n",
    "print(f'dropout: {DROPOUT}')\n",
    "print(f'learning rate: {LEARNING_RATE}')\n",
    "print(f'loss function: {LOSS_FUNCTION}')\n",
    "    \n",
    "print(f\"train cases: {len(datas_train)}\")\n",
    "print(f'train slices: {total_slices_dict[\"train\"]}')\n",
    "print(f\"validation cases: {len(datas_val)}\")\n",
    "print(f'val slices: {total_slices_dict[\"val\"]}')\n",
    "print(f\"test cases: {len(datas_test)}\")\n",
    "\n",
    "print(f'start training at: {start_train_timestamp}')\n",
    "print(f'----------')\n",
    "\n",
    "original_stdout = sys.stdout\n",
    "with open(f'{model_dir}/info.log', 'w') as log_file:\n",
    "    sys.stdout = log_file\n",
    "    print(f'----------')\n",
    "    print(f'model name: {model_builders[MODEL_VERSION].__name__}')\n",
    "    print(f'epochs: {EPOCHS}')\n",
    "    print(f'steps_per_epoch: {STEPS_PER_EPOCH}')\n",
    "    print(f'dimension: {IMG_SIZE}')\n",
    "    print(f'n_channels: {N_CHANNELS}')\n",
    "    print(f'input layer: {INPUT_LAYER}')\n",
    "    print(f'kernel init: {KER_INIT}')\n",
    "    print(f'dropout: {DROPOUT}')\n",
    "    print(f'learning rate: {LEARNING_RATE}')\n",
    "    print(f'loss function: {LOSS_FUNCTION}')\n",
    "\n",
    "    print(f\"train cases: {len(datas_train)}\")\n",
    "    print(f'train slices: {total_slices_dict[\"train\"]}')\n",
    "    print(f\"validation cases: {len(datas_val)}\")\n",
    "    print(f'val slices: {total_slices_dict[\"val\"]}')\n",
    "    print(f\"test cases: {len(datas_test)}\")\n",
    "\n",
    "    print(f'start training at: {start_train_timestamp}')\n",
    "    print(f'----------')\n",
    "\n",
    "sys.stdout = original_stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - 2: train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 23:48:03.422602: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "849/850 [============================>.] - ETA: 0s - loss: 0.0997 - accuracy: 0.9720 - mean_io_u: 0.6520 - dice_coef: 0.3607 - precision: 0.9786 - sensitivity: 0.9599 - specificity: 0.9936\n",
      "Epoch 00001: val_loss improved from inf to 0.06340, saving model to ./model/model_v1_Mar-12_23-45-26/model_epoch01-val_loss0.063402_Mar-12_23-45-26.m5\n",
      "850/850 [==============================] - 27s 27ms/step - loss: 0.0997 - accuracy: 0.9720 - mean_io_u: 0.6521 - dice_coef: 0.3606 - precision: 0.9787 - sensitivity: 0.9599 - specificity: 0.9936 - val_loss: 0.0634 - val_accuracy: 0.9801 - val_mean_io_u: 0.7175 - val_dice_coef: 0.4208 - val_precision: 0.9896 - val_sensitivity: 0.9653 - val_specificity: 0.9962 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 0.9808 - mean_io_u: 0.7774 - dice_coef: 0.4458 - precision: 0.9871 - sensitivity: 0.9726 - specificity: 0.9955\n",
      "Epoch 00002: val_loss improved from 0.06340 to 0.04612, saving model to ./model/model_v1_Mar-12_23-45-26/model_epoch02-val_loss0.046124_Mar-12_23-45-26.m5\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0565 - accuracy: 0.9808 - mean_io_u: 0.7774 - dice_coef: 0.4458 - precision: 0.9871 - sensitivity: 0.9726 - specificity: 0.9955 - val_loss: 0.0461 - val_accuracy: 0.9848 - val_mean_io_u: 0.8276 - val_dice_coef: 0.4908 - val_precision: 0.9884 - val_sensitivity: 0.9789 - val_specificity: 0.9960 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.0499 - accuracy: 0.9833 - mean_io_u: 0.7498 - dice_coef: 0.4971 - precision: 0.9872 - sensitivity: 0.9775 - specificity: 0.9956\n",
      "Epoch 00003: val_loss did not improve from 0.04612\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0498 - accuracy: 0.9834 - mean_io_u: 0.7500 - dice_coef: 0.4971 - precision: 0.9872 - sensitivity: 0.9776 - specificity: 0.9956 - val_loss: 0.0496 - val_accuracy: 0.9836 - val_mean_io_u: 0.6925 - val_dice_coef: 0.4889 - val_precision: 0.9871 - val_sensitivity: 0.9781 - val_specificity: 0.9956 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.0417 - accuracy: 0.9859 - mean_io_u: 0.7545 - dice_coef: 0.5334 - precision: 0.9881 - sensitivity: 0.9818 - specificity: 0.9960\n",
      "Epoch 00004: val_loss improved from 0.04612 to 0.04573, saving model to ./model/model_v1_Mar-12_23-45-26/model_epoch04-val_loss0.045725_Mar-12_23-45-26.m5\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0417 - accuracy: 0.9859 - mean_io_u: 0.7539 - dice_coef: 0.5328 - precision: 0.9881 - sensitivity: 0.9818 - specificity: 0.9960 - val_loss: 0.0457 - val_accuracy: 0.9850 - val_mean_io_u: 0.7968 - val_dice_coef: 0.5385 - val_precision: 0.9871 - val_sensitivity: 0.9815 - val_specificity: 0.9957 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.0364 - accuracy: 0.9874 - mean_io_u: 0.7570 - dice_coef: 0.5656 - precision: 0.9890 - sensitivity: 0.9839 - specificity: 0.9963\n",
      "Epoch 00005: val_loss improved from 0.04573 to 0.03541, saving model to ./model/model_v1_Mar-12_23-45-26/model_epoch05-val_loss0.035412_Mar-12_23-45-26.m5\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0364 - accuracy: 0.9875 - mean_io_u: 0.7567 - dice_coef: 0.5653 - precision: 0.9890 - sensitivity: 0.9839 - specificity: 0.9963 - val_loss: 0.0354 - val_accuracy: 0.9878 - val_mean_io_u: 0.7539 - val_dice_coef: 0.5791 - val_precision: 0.9895 - val_sensitivity: 0.9843 - val_specificity: 0.9964 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9871 - mean_io_u: 0.7343 - dice_coef: 0.5689 - precision: 0.9886 - sensitivity: 0.9836 - specificity: 0.9961\n",
      "Epoch 00006: val_loss did not improve from 0.03541\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0383 - accuracy: 0.9871 - mean_io_u: 0.7343 - dice_coef: 0.5689 - precision: 0.9886 - sensitivity: 0.9836 - specificity: 0.9961 - val_loss: 0.0361 - val_accuracy: 0.9883 - val_mean_io_u: 0.7296 - val_dice_coef: 0.5657 - val_precision: 0.9902 - val_sensitivity: 0.9842 - val_specificity: 0.9967 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.0341 - accuracy: 0.9885 - mean_io_u: 0.7933 - dice_coef: 0.5910 - precision: 0.9895 - sensitivity: 0.9853 - specificity: 0.9964\n",
      "Epoch 00007: val_loss improved from 0.03541 to 0.03520, saving model to ./model/model_v1_Mar-12_23-45-26/model_epoch07-val_loss0.035205_Mar-12_23-45-26.m5\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0341 - accuracy: 0.9885 - mean_io_u: 0.7934 - dice_coef: 0.5914 - precision: 0.9895 - sensitivity: 0.9853 - specificity: 0.9964 - val_loss: 0.0352 - val_accuracy: 0.9884 - val_mean_io_u: 0.8485 - val_dice_coef: 0.6037 - val_precision: 0.9885 - val_sensitivity: 0.9864 - val_specificity: 0.9961 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.9890 - mean_io_u: 0.7602 - dice_coef: 0.6070 - precision: 0.9898 - sensitivity: 0.9860 - specificity: 0.9965\n",
      "Epoch 00008: val_loss improved from 0.03520 to 0.02947, saving model to ./model/model_v1_Mar-12_23-45-26/model_epoch08-val_loss0.029466_Mar-12_23-45-26.m5\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0322 - accuracy: 0.9890 - mean_io_u: 0.7602 - dice_coef: 0.6070 - precision: 0.9898 - sensitivity: 0.9860 - specificity: 0.9965 - val_loss: 0.0295 - val_accuracy: 0.9900 - val_mean_io_u: 0.8061 - val_dice_coef: 0.6229 - val_precision: 0.9904 - val_sensitivity: 0.9874 - val_specificity: 0.9968 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.0299 - accuracy: 0.9897 - mean_io_u: 0.7911 - dice_coef: 0.6128 - precision: 0.9903 - sensitivity: 0.9869 - specificity: 0.9967\n",
      "Epoch 00009: val_loss did not improve from 0.02947\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0298 - accuracy: 0.9897 - mean_io_u: 0.7910 - dice_coef: 0.6129 - precision: 0.9903 - sensitivity: 0.9869 - specificity: 0.9967 - val_loss: 0.0303 - val_accuracy: 0.9898 - val_mean_io_u: 0.7565 - val_dice_coef: 0.6386 - val_precision: 0.9898 - val_sensitivity: 0.9879 - val_specificity: 0.9966 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.0314 - accuracy: 0.9893 - mean_io_u: 0.7500 - dice_coef: 0.6161 - precision: 0.9898 - sensitivity: 0.9865 - specificity: 0.9965\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02947\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0314 - accuracy: 0.9892 - mean_io_u: 0.7502 - dice_coef: 0.6159 - precision: 0.9898 - sensitivity: 0.9865 - specificity: 0.9965 - val_loss: 0.0338 - val_accuracy: 0.9886 - val_mean_io_u: 0.8155 - val_dice_coef: 0.6132 - val_precision: 0.9890 - val_sensitivity: 0.9865 - val_specificity: 0.9963 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9912 - mean_io_u: 0.7878 - dice_coef: 0.6405 - precision: 0.9913 - sensitivity: 0.9886 - specificity: 0.9971\n",
      "Epoch 00011: val_loss improved from 0.02947 to 0.02642, saving model to ./model/model_v1_Mar-12_23-45-26/model_epoch11-val_loss0.026420_Mar-12_23-45-26.m5\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0255 - accuracy: 0.9911 - mean_io_u: 0.7878 - dice_coef: 0.6407 - precision: 0.9913 - sensitivity: 0.9886 - specificity: 0.9971 - val_loss: 0.0264 - val_accuracy: 0.9909 - val_mean_io_u: 0.7990 - val_dice_coef: 0.6435 - val_precision: 0.9908 - val_sensitivity: 0.9887 - val_specificity: 0.9969 - lr: 2.0000e-05\n",
      "Epoch 12/100\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.0240 - accuracy: 0.9916 - mean_io_u: 0.7941 - dice_coef: 0.6593 - precision: 0.9916 - sensitivity: 0.9892 - specificity: 0.9971\n",
      "Epoch 00012: val_loss improved from 0.02642 to 0.02580, saving model to ./model/model_v1_Mar-12_23-45-26/model_epoch12-val_loss0.025797_Mar-12_23-45-26.m5\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0240 - accuracy: 0.9916 - mean_io_u: 0.7941 - dice_coef: 0.6594 - precision: 0.9916 - sensitivity: 0.9892 - specificity: 0.9971 - val_loss: 0.0258 - val_accuracy: 0.9912 - val_mean_io_u: 0.7988 - val_dice_coef: 0.6368 - val_precision: 0.9913 - val_sensitivity: 0.9887 - val_specificity: 0.9971 - lr: 2.0000e-05\n",
      "Epoch 13/100\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.0237 - accuracy: 0.9917 - mean_io_u: 0.8068 - dice_coef: 0.6553 - precision: 0.9916 - sensitivity: 0.9893 - specificity: 0.9972\n",
      "Epoch 00013: val_loss improved from 0.02580 to 0.02573, saving model to ./model/model_v1_Mar-12_23-45-26/model_epoch13-val_loss0.025727_Mar-12_23-45-26.m5\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0237 - accuracy: 0.9917 - mean_io_u: 0.8068 - dice_coef: 0.6551 - precision: 0.9916 - sensitivity: 0.9893 - specificity: 0.9972 - val_loss: 0.0257 - val_accuracy: 0.9912 - val_mean_io_u: 0.8070 - val_dice_coef: 0.6412 - val_precision: 0.9913 - val_sensitivity: 0.9887 - val_specificity: 0.9971 - lr: 2.0000e-05\n",
      "Epoch 14/100\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.0228 - accuracy: 0.9921 - mean_io_u: 0.8013 - dice_coef: 0.6655 - precision: 0.9919 - sensitivity: 0.9898 - specificity: 0.9973\n",
      "Epoch 00014: val_loss improved from 0.02573 to 0.02505, saving model to ./model/model_v1_Mar-12_23-45-26/model_epoch14-val_loss0.025051_Mar-12_23-45-26.m5\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0229 - accuracy: 0.9921 - mean_io_u: 0.8013 - dice_coef: 0.6655 - precision: 0.9919 - sensitivity: 0.9898 - specificity: 0.9972 - val_loss: 0.0251 - val_accuracy: 0.9915 - val_mean_io_u: 0.8029 - val_dice_coef: 0.6531 - val_precision: 0.9913 - val_sensitivity: 0.9892 - val_specificity: 0.9971 - lr: 2.0000e-05\n",
      "Epoch 15/100\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9924 - mean_io_u: 0.8009 - dice_coef: 0.6739 - precision: 0.9921 - sensitivity: 0.9902 - specificity: 0.9973\n",
      "Epoch 00015: val_loss improved from 0.02505 to 0.02486, saving model to ./model/model_v1_Mar-12_23-45-26/model_epoch15-val_loss0.024865_Mar-12_23-45-26.m5\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0215 - accuracy: 0.9924 - mean_io_u: 0.8008 - dice_coef: 0.6741 - precision: 0.9921 - sensitivity: 0.9902 - specificity: 0.9973 - val_loss: 0.0249 - val_accuracy: 0.9916 - val_mean_io_u: 0.8043 - val_dice_coef: 0.6661 - val_precision: 0.9914 - val_sensitivity: 0.9896 - val_specificity: 0.9971 - lr: 2.0000e-05\n",
      "Epoch 16/100\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.0231 - accuracy: 0.9919 - mean_io_u: 0.7915 - dice_coef: 0.6602 - precision: 0.9918 - sensitivity: 0.9896 - specificity: 0.9972\n",
      "Epoch 00016: val_loss did not improve from 0.02486\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0231 - accuracy: 0.9919 - mean_io_u: 0.7915 - dice_coef: 0.6603 - precision: 0.9918 - sensitivity: 0.9896 - specificity: 0.9972 - val_loss: 0.0251 - val_accuracy: 0.9916 - val_mean_io_u: 0.8041 - val_dice_coef: 0.6716 - val_precision: 0.9912 - val_sensitivity: 0.9897 - val_specificity: 0.9971 - lr: 2.0000e-05\n",
      "Epoch 17/100\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.0220 - accuracy: 0.9922 - mean_io_u: 0.8098 - dice_coef: 0.6829 - precision: 0.9919 - sensitivity: 0.9899 - specificity: 0.9973\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.02486\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0219 - accuracy: 0.9922 - mean_io_u: 0.8099 - dice_coef: 0.6830 - precision: 0.9919 - sensitivity: 0.9899 - specificity: 0.9973 - val_loss: 0.0256 - val_accuracy: 0.9917 - val_mean_io_u: 0.8129 - val_dice_coef: 0.6808 - val_precision: 0.9913 - val_sensitivity: 0.9898 - val_specificity: 0.9971 - lr: 2.0000e-05\n",
      "Epoch 18/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9928 - mean_io_u: 0.8113 - dice_coef: 0.6834 - precision: 0.9924 - sensitivity: 0.9906 - specificity: 0.9974\n",
      "Epoch 00018: val_loss improved from 0.02486 to 0.02437, saving model to ./model/model_v1_Mar-12_23-45-26/model_epoch18-val_loss0.024369_Mar-12_23-45-26.m5\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0204 - accuracy: 0.9928 - mean_io_u: 0.8113 - dice_coef: 0.6834 - precision: 0.9924 - sensitivity: 0.9906 - specificity: 0.9974 - val_loss: 0.0244 - val_accuracy: 0.9918 - val_mean_io_u: 0.8211 - val_dice_coef: 0.6649 - val_precision: 0.9915 - val_sensitivity: 0.9897 - val_specificity: 0.9971 - lr: 4.0000e-06\n",
      "Epoch 19/100\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.0207 - accuracy: 0.9927 - mean_io_u: 0.8199 - dice_coef: 0.6811 - precision: 0.9923 - sensitivity: 0.9905 - specificity: 0.9974\n",
      "Epoch 00019: val_loss did not improve from 0.02437\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0207 - accuracy: 0.9927 - mean_io_u: 0.8200 - dice_coef: 0.6810 - precision: 0.9923 - sensitivity: 0.9905 - specificity: 0.9974 - val_loss: 0.0246 - val_accuracy: 0.9918 - val_mean_io_u: 0.8334 - val_dice_coef: 0.6737 - val_precision: 0.9915 - val_sensitivity: 0.9899 - val_specificity: 0.9972 - lr: 4.0000e-06\n",
      "Epoch 20/100\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.0203 - accuracy: 0.9929 - mean_io_u: 0.8302 - dice_coef: 0.6901 - precision: 0.9925 - sensitivity: 0.9907 - specificity: 0.9975\n",
      "Epoch 00020: val_loss improved from 0.02437 to 0.02424, saving model to ./model/model_v1_Mar-12_23-45-26/model_epoch20-val_loss0.024245_Mar-12_23-45-26.m5\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0203 - accuracy: 0.9929 - mean_io_u: 0.8303 - dice_coef: 0.6905 - precision: 0.9925 - sensitivity: 0.9908 - specificity: 0.9975 - val_loss: 0.0242 - val_accuracy: 0.9919 - val_mean_io_u: 0.8373 - val_dice_coef: 0.6694 - val_precision: 0.9916 - val_sensitivity: 0.9898 - val_specificity: 0.9972 - lr: 4.0000e-06\n",
      "Epoch 21/100\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.0201 - accuracy: 0.9929 - mean_io_u: 0.8301 - dice_coef: 0.6801 - precision: 0.9926 - sensitivity: 0.9907 - specificity: 0.9975\n",
      "Epoch 00021: val_loss did not improve from 0.02424\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0201 - accuracy: 0.9929 - mean_io_u: 0.8301 - dice_coef: 0.6802 - precision: 0.9926 - sensitivity: 0.9907 - specificity: 0.9975 - val_loss: 0.0243 - val_accuracy: 0.9919 - val_mean_io_u: 0.8388 - val_dice_coef: 0.6767 - val_precision: 0.9916 - val_sensitivity: 0.9900 - val_specificity: 0.9972 - lr: 4.0000e-06\n",
      "Epoch 22/100\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.9928 - mean_io_u: 0.8376 - dice_coef: 0.6866 - precision: 0.9925 - sensitivity: 0.9907 - specificity: 0.9975\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.02424 to 0.02419, saving model to ./model/model_v1_Mar-12_23-45-26/model_epoch22-val_loss0.024190_Mar-12_23-45-26.m5\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0202 - accuracy: 0.9928 - mean_io_u: 0.8377 - dice_coef: 0.6867 - precision: 0.9925 - sensitivity: 0.9907 - specificity: 0.9975 - val_loss: 0.0242 - val_accuracy: 0.9920 - val_mean_io_u: 0.8460 - val_dice_coef: 0.6743 - val_precision: 0.9917 - val_sensitivity: 0.9899 - val_specificity: 0.9972 - lr: 4.0000e-06\n",
      "Epoch 23/100\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.0208 - accuracy: 0.9927 - mean_io_u: 0.8357 - dice_coef: 0.6833 - precision: 0.9924 - sensitivity: 0.9904 - specificity: 0.9974\n",
      "Epoch 00023: val_loss improved from 0.02419 to 0.02398, saving model to ./model/model_v1_Mar-12_23-45-26/model_epoch23-val_loss0.023976_Mar-12_23-45-26.m5\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0208 - accuracy: 0.9927 - mean_io_u: 0.8358 - dice_coef: 0.6830 - precision: 0.9924 - sensitivity: 0.9904 - specificity: 0.9974 - val_loss: 0.0240 - val_accuracy: 0.9920 - val_mean_io_u: 0.8388 - val_dice_coef: 0.6758 - val_precision: 0.9917 - val_sensitivity: 0.9900 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 24/100\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.0199 - accuracy: 0.9929 - mean_io_u: 0.8302 - dice_coef: 0.7014 - precision: 0.9925 - sensitivity: 0.9908 - specificity: 0.9975\n",
      "Epoch 00024: val_loss improved from 0.02398 to 0.02394, saving model to ./model/model_v1_Mar-12_23-45-26/model_epoch24-val_loss0.023938_Mar-12_23-45-26.m5\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0199 - accuracy: 0.9929 - mean_io_u: 0.8302 - dice_coef: 0.7014 - precision: 0.9925 - sensitivity: 0.9908 - specificity: 0.9975 - val_loss: 0.0239 - val_accuracy: 0.9920 - val_mean_io_u: 0.8336 - val_dice_coef: 0.6761 - val_precision: 0.9917 - val_sensitivity: 0.9900 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 25/100\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.0199 - accuracy: 0.9930 - mean_io_u: 0.8307 - dice_coef: 0.6910 - precision: 0.9926 - sensitivity: 0.9909 - specificity: 0.9975\n",
      "Epoch 00025: val_loss did not improve from 0.02394\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0199 - accuracy: 0.9930 - mean_io_u: 0.8307 - dice_coef: 0.6912 - precision: 0.9926 - sensitivity: 0.9909 - specificity: 0.9975 - val_loss: 0.0240 - val_accuracy: 0.9920 - val_mean_io_u: 0.8353 - val_dice_coef: 0.6762 - val_precision: 0.9916 - val_sensitivity: 0.9900 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 26/100\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.9927 - mean_io_u: 0.8298 - dice_coef: 0.6982 - precision: 0.9923 - sensitivity: 0.9905 - specificity: 0.9974\n",
      "Epoch 00026: val_loss did not improve from 0.02394\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0205 - accuracy: 0.9927 - mean_io_u: 0.8298 - dice_coef: 0.6983 - precision: 0.9923 - sensitivity: 0.9905 - specificity: 0.9974 - val_loss: 0.0240 - val_accuracy: 0.9920 - val_mean_io_u: 0.8327 - val_dice_coef: 0.6753 - val_precision: 0.9917 - val_sensitivity: 0.9900 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 27/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9928 - mean_io_u: 0.8298 - dice_coef: 0.6923 - precision: 0.9924 - sensitivity: 0.9906 - specificity: 0.9974\n",
      "Epoch 00027: val_loss did not improve from 0.02394\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0203 - accuracy: 0.9928 - mean_io_u: 0.8298 - dice_coef: 0.6923 - precision: 0.9924 - sensitivity: 0.9906 - specificity: 0.9974 - val_loss: 0.0240 - val_accuracy: 0.9920 - val_mean_io_u: 0.8361 - val_dice_coef: 0.6756 - val_precision: 0.9917 - val_sensitivity: 0.9900 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 28/100\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.0203 - accuracy: 0.9929 - mean_io_u: 0.8316 - dice_coef: 0.6907 - precision: 0.9925 - sensitivity: 0.9907 - specificity: 0.9975\n",
      "Epoch 00028: val_loss did not improve from 0.02394\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0203 - accuracy: 0.9929 - mean_io_u: 0.8316 - dice_coef: 0.6909 - precision: 0.9925 - sensitivity: 0.9907 - specificity: 0.9975 - val_loss: 0.0240 - val_accuracy: 0.9920 - val_mean_io_u: 0.8368 - val_dice_coef: 0.6748 - val_precision: 0.9916 - val_sensitivity: 0.9900 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 29/100\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.0203 - accuracy: 0.9928 - mean_io_u: 0.8358 - dice_coef: 0.6848 - precision: 0.9924 - sensitivity: 0.9907 - specificity: 0.9974\n",
      "Epoch 00029: val_loss improved from 0.02394 to 0.02387, saving model to ./model/model_v1_Mar-12_23-45-26/model_epoch29-val_loss0.023865_Mar-12_23-45-26.m5\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0203 - accuracy: 0.9928 - mean_io_u: 0.8358 - dice_coef: 0.6850 - precision: 0.9924 - sensitivity: 0.9907 - specificity: 0.9974 - val_loss: 0.0239 - val_accuracy: 0.9920 - val_mean_io_u: 0.8384 - val_dice_coef: 0.6728 - val_precision: 0.9917 - val_sensitivity: 0.9899 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 30/100\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9930 - mean_io_u: 0.8344 - dice_coef: 0.6881 - precision: 0.9926 - sensitivity: 0.9908 - specificity: 0.9975\n",
      "Epoch 00030: val_loss improved from 0.02387 to 0.02386, saving model to ./model/model_v1_Mar-12_23-45-26/model_epoch30-val_loss0.023857_Mar-12_23-45-26.m5\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0196 - accuracy: 0.9930 - mean_io_u: 0.8344 - dice_coef: 0.6879 - precision: 0.9926 - sensitivity: 0.9908 - specificity: 0.9975 - val_loss: 0.0239 - val_accuracy: 0.9920 - val_mean_io_u: 0.8397 - val_dice_coef: 0.6766 - val_precision: 0.9917 - val_sensitivity: 0.9900 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 31/100\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.9930 - mean_io_u: 0.8365 - dice_coef: 0.6993 - precision: 0.9925 - sensitivity: 0.9908 - specificity: 0.9975\n",
      "Epoch 00031: val_loss did not improve from 0.02386\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0198 - accuracy: 0.9930 - mean_io_u: 0.8365 - dice_coef: 0.6992 - precision: 0.9925 - sensitivity: 0.9908 - specificity: 0.9975 - val_loss: 0.0239 - val_accuracy: 0.9920 - val_mean_io_u: 0.8402 - val_dice_coef: 0.6759 - val_precision: 0.9917 - val_sensitivity: 0.9900 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 32/100\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.0199 - accuracy: 0.9930 - mean_io_u: 0.8343 - dice_coef: 0.6984 - precision: 0.9925 - sensitivity: 0.9907 - specificity: 0.9975\n",
      "Epoch 00032: val_loss did not improve from 0.02386\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0199 - accuracy: 0.9930 - mean_io_u: 0.8343 - dice_coef: 0.6986 - precision: 0.9925 - sensitivity: 0.9907 - specificity: 0.9975 - val_loss: 0.0239 - val_accuracy: 0.9920 - val_mean_io_u: 0.8413 - val_dice_coef: 0.6806 - val_precision: 0.9916 - val_sensitivity: 0.9901 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 33/100\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9932 - mean_io_u: 0.8384 - dice_coef: 0.6967 - precision: 0.9927 - sensitivity: 0.9911 - specificity: 0.9976\n",
      "Epoch 00033: val_loss did not improve from 0.02386\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0192 - accuracy: 0.9932 - mean_io_u: 0.8385 - dice_coef: 0.6964 - precision: 0.9927 - sensitivity: 0.9911 - specificity: 0.9975 - val_loss: 0.0240 - val_accuracy: 0.9920 - val_mean_io_u: 0.8415 - val_dice_coef: 0.6785 - val_precision: 0.9916 - val_sensitivity: 0.9900 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 34/100\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.0197 - accuracy: 0.9930 - mean_io_u: 0.8363 - dice_coef: 0.6904 - precision: 0.9926 - sensitivity: 0.9908 - specificity: 0.9975\n",
      "Epoch 00034: val_loss did not improve from 0.02386\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0198 - accuracy: 0.9930 - mean_io_u: 0.8362 - dice_coef: 0.6905 - precision: 0.9925 - sensitivity: 0.9908 - specificity: 0.9975 - val_loss: 0.0240 - val_accuracy: 0.9920 - val_mean_io_u: 0.8405 - val_dice_coef: 0.6816 - val_precision: 0.9916 - val_sensitivity: 0.9901 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 35/100\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.0197 - accuracy: 0.9931 - mean_io_u: 0.8335 - dice_coef: 0.6946 - precision: 0.9926 - sensitivity: 0.9910 - specificity: 0.9975\n",
      "Epoch 00035: val_loss did not improve from 0.02386\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0197 - accuracy: 0.9931 - mean_io_u: 0.8334 - dice_coef: 0.6948 - precision: 0.9926 - sensitivity: 0.9910 - specificity: 0.9975 - val_loss: 0.0239 - val_accuracy: 0.9920 - val_mean_io_u: 0.8369 - val_dice_coef: 0.6812 - val_precision: 0.9916 - val_sensitivity: 0.9901 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 36/100\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.9933 - mean_io_u: 0.8371 - dice_coef: 0.6895 - precision: 0.9929 - sensitivity: 0.9912 - specificity: 0.9976\n",
      "Epoch 00036: val_loss improved from 0.02386 to 0.02378, saving model to ./model/model_v1_Mar-12_23-45-26/model_epoch36-val_loss0.023775_Mar-12_23-45-26.m5\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0191 - accuracy: 0.9933 - mean_io_u: 0.8372 - dice_coef: 0.6900 - precision: 0.9929 - sensitivity: 0.9912 - specificity: 0.9976 - val_loss: 0.0238 - val_accuracy: 0.9920 - val_mean_io_u: 0.8392 - val_dice_coef: 0.6763 - val_precision: 0.9917 - val_sensitivity: 0.9900 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 37/100\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9930 - mean_io_u: 0.8389 - dice_coef: 0.6833 - precision: 0.9926 - sensitivity: 0.9909 - specificity: 0.9975\n",
      "Epoch 00037: val_loss did not improve from 0.02378\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0196 - accuracy: 0.9930 - mean_io_u: 0.8388 - dice_coef: 0.6837 - precision: 0.9926 - sensitivity: 0.9909 - specificity: 0.9975 - val_loss: 0.0239 - val_accuracy: 0.9920 - val_mean_io_u: 0.8427 - val_dice_coef: 0.6776 - val_precision: 0.9917 - val_sensitivity: 0.9901 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 38/100\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.0193 - accuracy: 0.9932 - mean_io_u: 0.8390 - dice_coef: 0.6923 - precision: 0.9927 - sensitivity: 0.9911 - specificity: 0.9975\n",
      "Epoch 00038: val_loss did not improve from 0.02378\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0193 - accuracy: 0.9932 - mean_io_u: 0.8391 - dice_coef: 0.6920 - precision: 0.9928 - sensitivity: 0.9911 - specificity: 0.9975 - val_loss: 0.0240 - val_accuracy: 0.9920 - val_mean_io_u: 0.8449 - val_dice_coef: 0.6823 - val_precision: 0.9916 - val_sensitivity: 0.9901 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 39/100\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.0204 - accuracy: 0.9928 - mean_io_u: 0.8379 - dice_coef: 0.6915 - precision: 0.9924 - sensitivity: 0.9906 - specificity: 0.9974\n",
      "Epoch 00039: val_loss did not improve from 0.02378\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0204 - accuracy: 0.9928 - mean_io_u: 0.8379 - dice_coef: 0.6917 - precision: 0.9924 - sensitivity: 0.9906 - specificity: 0.9974 - val_loss: 0.0239 - val_accuracy: 0.9920 - val_mean_io_u: 0.8392 - val_dice_coef: 0.6803 - val_precision: 0.9916 - val_sensitivity: 0.9901 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 40/100\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.9930 - mean_io_u: 0.8373 - dice_coef: 0.6966 - precision: 0.9926 - sensitivity: 0.9908 - specificity: 0.9975\n",
      "Epoch 00040: val_loss did not improve from 0.02378\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0198 - accuracy: 0.9930 - mean_io_u: 0.8374 - dice_coef: 0.6967 - precision: 0.9926 - sensitivity: 0.9908 - specificity: 0.9975 - val_loss: 0.0239 - val_accuracy: 0.9921 - val_mean_io_u: 0.8408 - val_dice_coef: 0.6790 - val_precision: 0.9917 - val_sensitivity: 0.9901 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 41/100\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.0195 - accuracy: 0.9931 - mean_io_u: 0.8389 - dice_coef: 0.6966 - precision: 0.9927 - sensitivity: 0.9909 - specificity: 0.9975\n",
      "Epoch 00041: val_loss did not improve from 0.02378\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0195 - accuracy: 0.9931 - mean_io_u: 0.8389 - dice_coef: 0.6966 - precision: 0.9927 - sensitivity: 0.9909 - specificity: 0.9975 - val_loss: 0.0240 - val_accuracy: 0.9921 - val_mean_io_u: 0.8453 - val_dice_coef: 0.6796 - val_precision: 0.9917 - val_sensitivity: 0.9901 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 42/100\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.9930 - mean_io_u: 0.8380 - dice_coef: 0.6929 - precision: 0.9926 - sensitivity: 0.9908 - specificity: 0.9975\n",
      "Epoch 00042: val_loss did not improve from 0.02378\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0198 - accuracy: 0.9930 - mean_io_u: 0.8380 - dice_coef: 0.6928 - precision: 0.9926 - sensitivity: 0.9908 - specificity: 0.9975 - val_loss: 0.0238 - val_accuracy: 0.9920 - val_mean_io_u: 0.8415 - val_dice_coef: 0.6773 - val_precision: 0.9917 - val_sensitivity: 0.9900 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 43/100\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.0204 - accuracy: 0.9928 - mean_io_u: 0.8371 - dice_coef: 0.6903 - precision: 0.9924 - sensitivity: 0.9906 - specificity: 0.9974\n",
      "Epoch 00043: val_loss did not improve from 0.02378\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0204 - accuracy: 0.9928 - mean_io_u: 0.8371 - dice_coef: 0.6902 - precision: 0.9924 - sensitivity: 0.9906 - specificity: 0.9974 - val_loss: 0.0238 - val_accuracy: 0.9920 - val_mean_io_u: 0.8383 - val_dice_coef: 0.6767 - val_precision: 0.9917 - val_sensitivity: 0.9900 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 44/100\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.0193 - accuracy: 0.9932 - mean_io_u: 0.8350 - dice_coef: 0.6945 - precision: 0.9927 - sensitivity: 0.9910 - specificity: 0.9975\n",
      "Epoch 00044: val_loss did not improve from 0.02378\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0193 - accuracy: 0.9932 - mean_io_u: 0.8349 - dice_coef: 0.6946 - precision: 0.9927 - sensitivity: 0.9910 - specificity: 0.9975 - val_loss: 0.0239 - val_accuracy: 0.9921 - val_mean_io_u: 0.8418 - val_dice_coef: 0.6824 - val_precision: 0.9917 - val_sensitivity: 0.9902 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 45/100\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.0199 - accuracy: 0.9929 - mean_io_u: 0.8361 - dice_coef: 0.6998 - precision: 0.9925 - sensitivity: 0.9907 - specificity: 0.9975\n",
      "Epoch 00045: val_loss did not improve from 0.02378\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0199 - accuracy: 0.9929 - mean_io_u: 0.8361 - dice_coef: 0.6998 - precision: 0.9925 - sensitivity: 0.9907 - specificity: 0.9975 - val_loss: 0.0238 - val_accuracy: 0.9921 - val_mean_io_u: 0.8396 - val_dice_coef: 0.6778 - val_precision: 0.9917 - val_sensitivity: 0.9901 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 46/100\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.0200 - accuracy: 0.9929 - mean_io_u: 0.8341 - dice_coef: 0.6880 - precision: 0.9924 - sensitivity: 0.9908 - specificity: 0.9975\n",
      "Epoch 00046: val_loss improved from 0.02378 to 0.02371, saving model to ./model/model_v1_Mar-12_23-45-26/model_epoch46-val_loss0.023710_Mar-12_23-45-26.m5\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0201 - accuracy: 0.9929 - mean_io_u: 0.8342 - dice_coef: 0.6877 - precision: 0.9924 - sensitivity: 0.9907 - specificity: 0.9974 - val_loss: 0.0237 - val_accuracy: 0.9921 - val_mean_io_u: 0.8357 - val_dice_coef: 0.6810 - val_precision: 0.9917 - val_sensitivity: 0.9901 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 47/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9932 - mean_io_u: 0.8345 - dice_coef: 0.6929 - precision: 0.9927 - sensitivity: 0.9911 - specificity: 0.9975\n",
      "Epoch 00047: val_loss did not improve from 0.02371\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0195 - accuracy: 0.9932 - mean_io_u: 0.8345 - dice_coef: 0.6929 - precision: 0.9927 - sensitivity: 0.9911 - specificity: 0.9975 - val_loss: 0.0237 - val_accuracy: 0.9921 - val_mean_io_u: 0.8377 - val_dice_coef: 0.6781 - val_precision: 0.9917 - val_sensitivity: 0.9901 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 48/100\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.0203 - accuracy: 0.9929 - mean_io_u: 0.8327 - dice_coef: 0.6943 - precision: 0.9925 - sensitivity: 0.9907 - specificity: 0.9975\n",
      "Epoch 00048: val_loss did not improve from 0.02371\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0203 - accuracy: 0.9929 - mean_io_u: 0.8328 - dice_coef: 0.6943 - precision: 0.9925 - sensitivity: 0.9907 - specificity: 0.9975 - val_loss: 0.0237 - val_accuracy: 0.9921 - val_mean_io_u: 0.8383 - val_dice_coef: 0.6813 - val_precision: 0.9917 - val_sensitivity: 0.9901 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 49/100\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.9931 - mean_io_u: 0.8363 - dice_coef: 0.6866 - precision: 0.9927 - sensitivity: 0.9910 - specificity: 0.9975\n",
      "Epoch 00049: val_loss did not improve from 0.02371\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0194 - accuracy: 0.9931 - mean_io_u: 0.8363 - dice_coef: 0.6867 - precision: 0.9927 - sensitivity: 0.9910 - specificity: 0.9975 - val_loss: 0.0238 - val_accuracy: 0.9921 - val_mean_io_u: 0.8397 - val_dice_coef: 0.6841 - val_precision: 0.9917 - val_sensitivity: 0.9902 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 50/100\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.0199 - accuracy: 0.9930 - mean_io_u: 0.8366 - dice_coef: 0.6955 - precision: 0.9926 - sensitivity: 0.9908 - specificity: 0.9975\n",
      "Epoch 00050: val_loss did not improve from 0.02371\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0199 - accuracy: 0.9930 - mean_io_u: 0.8365 - dice_coef: 0.6953 - precision: 0.9926 - sensitivity: 0.9908 - specificity: 0.9975 - val_loss: 0.0238 - val_accuracy: 0.9921 - val_mean_io_u: 0.8424 - val_dice_coef: 0.6806 - val_precision: 0.9917 - val_sensitivity: 0.9901 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 51/100\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.0199 - accuracy: 0.9930 - mean_io_u: 0.8366 - dice_coef: 0.6932 - precision: 0.9926 - sensitivity: 0.9908 - specificity: 0.9975\n",
      "Epoch 00051: val_loss improved from 0.02371 to 0.02370, saving model to ./model/model_v1_Mar-12_23-45-26/model_epoch51-val_loss0.023695_Mar-12_23-45-26.m5\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0199 - accuracy: 0.9930 - mean_io_u: 0.8366 - dice_coef: 0.6935 - precision: 0.9925 - sensitivity: 0.9908 - specificity: 0.9975 - val_loss: 0.0237 - val_accuracy: 0.9921 - val_mean_io_u: 0.8401 - val_dice_coef: 0.6792 - val_precision: 0.9917 - val_sensitivity: 0.9901 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 52/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9932 - mean_io_u: 0.8373 - dice_coef: 0.6841 - precision: 0.9927 - sensitivity: 0.9911 - specificity: 0.9976\n",
      "Epoch 00052: val_loss did not improve from 0.02370\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0193 - accuracy: 0.9932 - mean_io_u: 0.8373 - dice_coef: 0.6841 - precision: 0.9927 - sensitivity: 0.9911 - specificity: 0.9976 - val_loss: 0.0238 - val_accuracy: 0.9920 - val_mean_io_u: 0.8414 - val_dice_coef: 0.6788 - val_precision: 0.9917 - val_sensitivity: 0.9901 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 53/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9931 - mean_io_u: 0.8345 - dice_coef: 0.6898 - precision: 0.9926 - sensitivity: 0.9909 - specificity: 0.9975\n",
      "Epoch 00053: val_loss did not improve from 0.02370\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0195 - accuracy: 0.9931 - mean_io_u: 0.8345 - dice_coef: 0.6898 - precision: 0.9926 - sensitivity: 0.9909 - specificity: 0.9975 - val_loss: 0.0238 - val_accuracy: 0.9921 - val_mean_io_u: 0.8414 - val_dice_coef: 0.6827 - val_precision: 0.9917 - val_sensitivity: 0.9902 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 54/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9932 - mean_io_u: 0.8409 - dice_coef: 0.6962 - precision: 0.9927 - sensitivity: 0.9911 - specificity: 0.9975\n",
      "Epoch 00054: val_loss improved from 0.02370 to 0.02364, saving model to ./model/model_v1_Mar-12_23-45-26/model_epoch54-val_loss0.023644_Mar-12_23-45-26.m5\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0190 - accuracy: 0.9932 - mean_io_u: 0.8409 - dice_coef: 0.6962 - precision: 0.9927 - sensitivity: 0.9911 - specificity: 0.9975 - val_loss: 0.0236 - val_accuracy: 0.9921 - val_mean_io_u: 0.8444 - val_dice_coef: 0.6784 - val_precision: 0.9917 - val_sensitivity: 0.9901 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 55/100\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.9935 - mean_io_u: 0.8422 - dice_coef: 0.6999 - precision: 0.9930 - sensitivity: 0.9914 - specificity: 0.9976\n",
      "Epoch 00055: val_loss did not improve from 0.02364\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0184 - accuracy: 0.9935 - mean_io_u: 0.8422 - dice_coef: 0.7001 - precision: 0.9930 - sensitivity: 0.9914 - specificity: 0.9976 - val_loss: 0.0237 - val_accuracy: 0.9921 - val_mean_io_u: 0.8421 - val_dice_coef: 0.6851 - val_precision: 0.9917 - val_sensitivity: 0.9902 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 56/100\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.9933 - mean_io_u: 0.8398 - dice_coef: 0.6996 - precision: 0.9928 - sensitivity: 0.9912 - specificity: 0.9976\n",
      "Epoch 00056: val_loss did not improve from 0.02364\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0191 - accuracy: 0.9933 - mean_io_u: 0.8396 - dice_coef: 0.6997 - precision: 0.9928 - sensitivity: 0.9912 - specificity: 0.9976 - val_loss: 0.0239 - val_accuracy: 0.9921 - val_mean_io_u: 0.8459 - val_dice_coef: 0.6847 - val_precision: 0.9917 - val_sensitivity: 0.9902 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 57/100\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.9933 - mean_io_u: 0.8410 - dice_coef: 0.6991 - precision: 0.9928 - sensitivity: 0.9912 - specificity: 0.9976\n",
      "Epoch 00057: val_loss did not improve from 0.02364\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0191 - accuracy: 0.9933 - mean_io_u: 0.8409 - dice_coef: 0.6991 - precision: 0.9928 - sensitivity: 0.9912 - specificity: 0.9976 - val_loss: 0.0237 - val_accuracy: 0.9921 - val_mean_io_u: 0.8428 - val_dice_coef: 0.6823 - val_precision: 0.9917 - val_sensitivity: 0.9902 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 58/100\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.9932 - mean_io_u: 0.8393 - dice_coef: 0.7042 - precision: 0.9927 - sensitivity: 0.9911 - specificity: 0.9975\n",
      "Epoch 00058: val_loss did not improve from 0.02364\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0191 - accuracy: 0.9932 - mean_io_u: 0.8394 - dice_coef: 0.7042 - precision: 0.9927 - sensitivity: 0.9911 - specificity: 0.9975 - val_loss: 0.0238 - val_accuracy: 0.9921 - val_mean_io_u: 0.8436 - val_dice_coef: 0.6857 - val_precision: 0.9917 - val_sensitivity: 0.9902 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 59/100\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9932 - mean_io_u: 0.8373 - dice_coef: 0.7009 - precision: 0.9927 - sensitivity: 0.9910 - specificity: 0.9975\n",
      "Epoch 00059: val_loss did not improve from 0.02364\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0196 - accuracy: 0.9932 - mean_io_u: 0.8373 - dice_coef: 0.7011 - precision: 0.9927 - sensitivity: 0.9910 - specificity: 0.9975 - val_loss: 0.0238 - val_accuracy: 0.9921 - val_mean_io_u: 0.8440 - val_dice_coef: 0.6838 - val_precision: 0.9917 - val_sensitivity: 0.9902 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 60/100\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.9933 - mean_io_u: 0.8369 - dice_coef: 0.7007 - precision: 0.9928 - sensitivity: 0.9912 - specificity: 0.9976\n",
      "Epoch 00060: val_loss did not improve from 0.02364\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0190 - accuracy: 0.9933 - mean_io_u: 0.8369 - dice_coef: 0.7009 - precision: 0.9928 - sensitivity: 0.9912 - specificity: 0.9976 - val_loss: 0.0238 - val_accuracy: 0.9921 - val_mean_io_u: 0.8417 - val_dice_coef: 0.6842 - val_precision: 0.9917 - val_sensitivity: 0.9902 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 61/100\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.0193 - accuracy: 0.9932 - mean_io_u: 0.8377 - dice_coef: 0.6914 - precision: 0.9927 - sensitivity: 0.9911 - specificity: 0.9975\n",
      "Epoch 00061: val_loss did not improve from 0.02364\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0193 - accuracy: 0.9932 - mean_io_u: 0.8376 - dice_coef: 0.6912 - precision: 0.9927 - sensitivity: 0.9911 - specificity: 0.9975 - val_loss: 0.0239 - val_accuracy: 0.9921 - val_mean_io_u: 0.8424 - val_dice_coef: 0.6870 - val_precision: 0.9917 - val_sensitivity: 0.9902 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 62/100\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.0193 - accuracy: 0.9931 - mean_io_u: 0.8376 - dice_coef: 0.6955 - precision: 0.9927 - sensitivity: 0.9911 - specificity: 0.9975\n",
      "Epoch 00062: val_loss did not improve from 0.02364\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0193 - accuracy: 0.9931 - mean_io_u: 0.8375 - dice_coef: 0.6958 - precision: 0.9927 - sensitivity: 0.9911 - specificity: 0.9975 - val_loss: 0.0239 - val_accuracy: 0.9921 - val_mean_io_u: 0.8418 - val_dice_coef: 0.6869 - val_precision: 0.9917 - val_sensitivity: 0.9902 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 63/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9933 - mean_io_u: 0.8392 - dice_coef: 0.6937 - precision: 0.9928 - sensitivity: 0.9912 - specificity: 0.9976\n",
      "Epoch 00063: val_loss did not improve from 0.02364\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0190 - accuracy: 0.9933 - mean_io_u: 0.8392 - dice_coef: 0.6937 - precision: 0.9928 - sensitivity: 0.9912 - specificity: 0.9976 - val_loss: 0.0237 - val_accuracy: 0.9921 - val_mean_io_u: 0.8400 - val_dice_coef: 0.6845 - val_precision: 0.9917 - val_sensitivity: 0.9902 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 64/100\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9933 - mean_io_u: 0.8349 - dice_coef: 0.6987 - precision: 0.9928 - sensitivity: 0.9912 - specificity: 0.9976\n",
      "Epoch 00064: val_loss did not improve from 0.02364\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0190 - accuracy: 0.9933 - mean_io_u: 0.8349 - dice_coef: 0.6988 - precision: 0.9928 - sensitivity: 0.9912 - specificity: 0.9976 - val_loss: 0.0237 - val_accuracy: 0.9922 - val_mean_io_u: 0.8421 - val_dice_coef: 0.6827 - val_precision: 0.9918 - val_sensitivity: 0.9902 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 65/100\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9933 - mean_io_u: 0.8383 - dice_coef: 0.7018 - precision: 0.9928 - sensitivity: 0.9912 - specificity: 0.9976\n",
      "Epoch 00065: val_loss did not improve from 0.02364\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0190 - accuracy: 0.9933 - mean_io_u: 0.8384 - dice_coef: 0.7022 - precision: 0.9928 - sensitivity: 0.9912 - specificity: 0.9976 - val_loss: 0.0237 - val_accuracy: 0.9921 - val_mean_io_u: 0.8411 - val_dice_coef: 0.6849 - val_precision: 0.9917 - val_sensitivity: 0.9902 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 66/100\n",
      "845/850 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9932 - mean_io_u: 0.8365 - dice_coef: 0.7008 - precision: 0.9928 - sensitivity: 0.9912 - specificity: 0.9976\n",
      "Epoch 00066: val_loss did not improve from 0.02364\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0190 - accuracy: 0.9932 - mean_io_u: 0.8364 - dice_coef: 0.7007 - precision: 0.9928 - sensitivity: 0.9912 - specificity: 0.9976 - val_loss: 0.0238 - val_accuracy: 0.9922 - val_mean_io_u: 0.8422 - val_dice_coef: 0.6869 - val_precision: 0.9918 - val_sensitivity: 0.9903 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 67/100\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9934 - mean_io_u: 0.8383 - dice_coef: 0.7024 - precision: 0.9929 - sensitivity: 0.9913 - specificity: 0.9976\n",
      "Epoch 00067: val_loss did not improve from 0.02364\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0187 - accuracy: 0.9934 - mean_io_u: 0.8383 - dice_coef: 0.7028 - precision: 0.9929 - sensitivity: 0.9913 - specificity: 0.9976 - val_loss: 0.0237 - val_accuracy: 0.9921 - val_mean_io_u: 0.8426 - val_dice_coef: 0.6849 - val_precision: 0.9918 - val_sensitivity: 0.9902 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 68/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9932 - mean_io_u: 0.8374 - dice_coef: 0.6964 - precision: 0.9927 - sensitivity: 0.9911 - specificity: 0.9975\n",
      "Epoch 00068: val_loss did not improve from 0.02364\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0191 - accuracy: 0.9932 - mean_io_u: 0.8374 - dice_coef: 0.6964 - precision: 0.9927 - sensitivity: 0.9911 - specificity: 0.9975 - val_loss: 0.0239 - val_accuracy: 0.9921 - val_mean_io_u: 0.8443 - val_dice_coef: 0.6888 - val_precision: 0.9917 - val_sensitivity: 0.9903 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 69/100\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.9932 - mean_io_u: 0.8412 - dice_coef: 0.6989 - precision: 0.9928 - sensitivity: 0.9911 - specificity: 0.9976\n",
      "Epoch 00069: val_loss did not improve from 0.02364\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0190 - accuracy: 0.9932 - mean_io_u: 0.8413 - dice_coef: 0.6988 - precision: 0.9928 - sensitivity: 0.9911 - specificity: 0.9976 - val_loss: 0.0237 - val_accuracy: 0.9921 - val_mean_io_u: 0.8446 - val_dice_coef: 0.6847 - val_precision: 0.9917 - val_sensitivity: 0.9902 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 70/100\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9933 - mean_io_u: 0.8409 - dice_coef: 0.7063 - precision: 0.9927 - sensitivity: 0.9911 - specificity: 0.9975\n",
      "Epoch 00070: val_loss did not improve from 0.02364\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0190 - accuracy: 0.9933 - mean_io_u: 0.8409 - dice_coef: 0.7063 - precision: 0.9927 - sensitivity: 0.9912 - specificity: 0.9975 - val_loss: 0.0238 - val_accuracy: 0.9922 - val_mean_io_u: 0.8464 - val_dice_coef: 0.6874 - val_precision: 0.9917 - val_sensitivity: 0.9903 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 71/100\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.9932 - mean_io_u: 0.8418 - dice_coef: 0.7006 - precision: 0.9927 - sensitivity: 0.9911 - specificity: 0.9975\n",
      "Epoch 00071: val_loss did not improve from 0.02364\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0195 - accuracy: 0.9932 - mean_io_u: 0.8418 - dice_coef: 0.7004 - precision: 0.9927 - sensitivity: 0.9911 - specificity: 0.9975 - val_loss: 0.0237 - val_accuracy: 0.9921 - val_mean_io_u: 0.8432 - val_dice_coef: 0.6798 - val_precision: 0.9918 - val_sensitivity: 0.9901 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 72/100\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.9931 - mean_io_u: 0.8388 - dice_coef: 0.6967 - precision: 0.9927 - sensitivity: 0.9910 - specificity: 0.9975\n",
      "Epoch 00072: val_loss did not improve from 0.02364\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0194 - accuracy: 0.9931 - mean_io_u: 0.8388 - dice_coef: 0.6967 - precision: 0.9927 - sensitivity: 0.9910 - specificity: 0.9975 - val_loss: 0.0239 - val_accuracy: 0.9921 - val_mean_io_u: 0.8459 - val_dice_coef: 0.6880 - val_precision: 0.9917 - val_sensitivity: 0.9903 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 73/100\n",
      "848/850 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9933 - mean_io_u: 0.8401 - dice_coef: 0.6963 - precision: 0.9928 - sensitivity: 0.9911 - specificity: 0.9976\n",
      "Epoch 00073: val_loss did not improve from 0.02364\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0192 - accuracy: 0.9933 - mean_io_u: 0.8401 - dice_coef: 0.6966 - precision: 0.9928 - sensitivity: 0.9912 - specificity: 0.9976 - val_loss: 0.0238 - val_accuracy: 0.9921 - val_mean_io_u: 0.8439 - val_dice_coef: 0.6884 - val_precision: 0.9917 - val_sensitivity: 0.9903 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 74/100\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9932 - mean_io_u: 0.8398 - dice_coef: 0.7032 - precision: 0.9927 - sensitivity: 0.9910 - specificity: 0.9975\n",
      "Epoch 00074: val_loss did not improve from 0.02364\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0192 - accuracy: 0.9932 - mean_io_u: 0.8398 - dice_coef: 0.7030 - precision: 0.9927 - sensitivity: 0.9910 - specificity: 0.9975 - val_loss: 0.0237 - val_accuracy: 0.9922 - val_mean_io_u: 0.8466 - val_dice_coef: 0.6867 - val_precision: 0.9918 - val_sensitivity: 0.9903 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 75/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9932 - mean_io_u: 0.8425 - dice_coef: 0.6937 - precision: 0.9927 - sensitivity: 0.9910 - specificity: 0.9975\n",
      "Epoch 00075: val_loss did not improve from 0.02364\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0193 - accuracy: 0.9932 - mean_io_u: 0.8425 - dice_coef: 0.6937 - precision: 0.9927 - sensitivity: 0.9910 - specificity: 0.9975 - val_loss: 0.0237 - val_accuracy: 0.9922 - val_mean_io_u: 0.8467 - val_dice_coef: 0.6855 - val_precision: 0.9918 - val_sensitivity: 0.9903 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 76/100\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.9934 - mean_io_u: 0.8449 - dice_coef: 0.7025 - precision: 0.9929 - sensitivity: 0.9913 - specificity: 0.9976\n",
      "Epoch 00076: val_loss did not improve from 0.02364\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0184 - accuracy: 0.9934 - mean_io_u: 0.8448 - dice_coef: 0.7024 - precision: 0.9929 - sensitivity: 0.9913 - specificity: 0.9976 - val_loss: 0.0240 - val_accuracy: 0.9921 - val_mean_io_u: 0.8507 - val_dice_coef: 0.6923 - val_precision: 0.9917 - val_sensitivity: 0.9903 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 77/100\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9935 - mean_io_u: 0.8453 - dice_coef: 0.7068 - precision: 0.9929 - sensitivity: 0.9914 - specificity: 0.9976\n",
      "Epoch 00077: val_loss did not improve from 0.02364\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0186 - accuracy: 0.9934 - mean_io_u: 0.8453 - dice_coef: 0.7069 - precision: 0.9929 - sensitivity: 0.9914 - specificity: 0.9976 - val_loss: 0.0239 - val_accuracy: 0.9921 - val_mean_io_u: 0.8508 - val_dice_coef: 0.6897 - val_precision: 0.9917 - val_sensitivity: 0.9903 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 78/100\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9933 - mean_io_u: 0.8432 - dice_coef: 0.7117 - precision: 0.9928 - sensitivity: 0.9912 - specificity: 0.9976\n",
      "Epoch 00078: val_loss did not improve from 0.02364\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0191 - accuracy: 0.9933 - mean_io_u: 0.8430 - dice_coef: 0.7115 - precision: 0.9928 - sensitivity: 0.9912 - specificity: 0.9976 - val_loss: 0.0238 - val_accuracy: 0.9921 - val_mean_io_u: 0.8481 - val_dice_coef: 0.6859 - val_precision: 0.9917 - val_sensitivity: 0.9902 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 79/100\n",
      "845/850 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.9931 - mean_io_u: 0.8423 - dice_coef: 0.7007 - precision: 0.9926 - sensitivity: 0.9910 - specificity: 0.9975\n",
      "Epoch 00079: val_loss improved from 0.02364 to 0.02346, saving model to ./model/model_v1_Mar-12_23-45-26/model_epoch79-val_loss0.023458_Mar-12_23-45-26.m5\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0194 - accuracy: 0.9931 - mean_io_u: 0.8423 - dice_coef: 0.7006 - precision: 0.9926 - sensitivity: 0.9910 - specificity: 0.9975 - val_loss: 0.0235 - val_accuracy: 0.9922 - val_mean_io_u: 0.8432 - val_dice_coef: 0.6828 - val_precision: 0.9918 - val_sensitivity: 0.9902 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 80/100\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9935 - mean_io_u: 0.8423 - dice_coef: 0.6995 - precision: 0.9929 - sensitivity: 0.9913 - specificity: 0.9976\n",
      "Epoch 00080: val_loss did not improve from 0.02346\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0185 - accuracy: 0.9935 - mean_io_u: 0.8424 - dice_coef: 0.6992 - precision: 0.9930 - sensitivity: 0.9914 - specificity: 0.9976 - val_loss: 0.0236 - val_accuracy: 0.9922 - val_mean_io_u: 0.8481 - val_dice_coef: 0.6871 - val_precision: 0.9918 - val_sensitivity: 0.9903 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 81/100\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9935 - mean_io_u: 0.8462 - dice_coef: 0.7080 - precision: 0.9930 - sensitivity: 0.9914 - specificity: 0.9976\n",
      "Epoch 00081: val_loss did not improve from 0.02346\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0185 - accuracy: 0.9935 - mean_io_u: 0.8463 - dice_coef: 0.7078 - precision: 0.9930 - sensitivity: 0.9914 - specificity: 0.9976 - val_loss: 0.0237 - val_accuracy: 0.9922 - val_mean_io_u: 0.8495 - val_dice_coef: 0.6891 - val_precision: 0.9918 - val_sensitivity: 0.9903 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 82/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9934 - mean_io_u: 0.8484 - dice_coef: 0.7044 - precision: 0.9929 - sensitivity: 0.9913 - specificity: 0.9976\n",
      "Epoch 00082: val_loss did not improve from 0.02346\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0188 - accuracy: 0.9934 - mean_io_u: 0.8484 - dice_coef: 0.7044 - precision: 0.9929 - sensitivity: 0.9913 - specificity: 0.9976 - val_loss: 0.0235 - val_accuracy: 0.9922 - val_mean_io_u: 0.8499 - val_dice_coef: 0.6850 - val_precision: 0.9918 - val_sensitivity: 0.9902 - val_specificity: 0.9973 - lr: 1.0000e-06\n",
      "Epoch 83/100\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.9934 - mean_io_u: 0.8451 - dice_coef: 0.7010 - precision: 0.9930 - sensitivity: 0.9913 - specificity: 0.9976\n",
      "Epoch 00083: val_loss did not improve from 0.02346\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0187 - accuracy: 0.9934 - mean_io_u: 0.8452 - dice_coef: 0.7008 - precision: 0.9930 - sensitivity: 0.9913 - specificity: 0.9976 - val_loss: 0.0237 - val_accuracy: 0.9922 - val_mean_io_u: 0.8509 - val_dice_coef: 0.6912 - val_precision: 0.9917 - val_sensitivity: 0.9903 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 84/100\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9934 - mean_io_u: 0.8469 - dice_coef: 0.7022 - precision: 0.9929 - sensitivity: 0.9914 - specificity: 0.9976\n",
      "Epoch 00084: val_loss did not improve from 0.02346\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0185 - accuracy: 0.9934 - mean_io_u: 0.8468 - dice_coef: 0.7018 - precision: 0.9929 - sensitivity: 0.9914 - specificity: 0.9976 - val_loss: 0.0236 - val_accuracy: 0.9922 - val_mean_io_u: 0.8500 - val_dice_coef: 0.6874 - val_precision: 0.9918 - val_sensitivity: 0.9903 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 85/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9934 - mean_io_u: 0.8444 - dice_coef: 0.7063 - precision: 0.9929 - sensitivity: 0.9913 - specificity: 0.9976\n",
      "Epoch 00085: val_loss did not improve from 0.02346\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0186 - accuracy: 0.9934 - mean_io_u: 0.8444 - dice_coef: 0.7063 - precision: 0.9929 - sensitivity: 0.9913 - specificity: 0.9976 - val_loss: 0.0237 - val_accuracy: 0.9922 - val_mean_io_u: 0.8493 - val_dice_coef: 0.6909 - val_precision: 0.9917 - val_sensitivity: 0.9903 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 86/100\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9931 - mean_io_u: 0.8457 - dice_coef: 0.6990 - precision: 0.9926 - sensitivity: 0.9910 - specificity: 0.9975\n",
      "Epoch 00086: val_loss did not improve from 0.02346\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0196 - accuracy: 0.9931 - mean_io_u: 0.8457 - dice_coef: 0.6987 - precision: 0.9926 - sensitivity: 0.9910 - specificity: 0.9975 - val_loss: 0.0236 - val_accuracy: 0.9922 - val_mean_io_u: 0.8472 - val_dice_coef: 0.6827 - val_precision: 0.9918 - val_sensitivity: 0.9902 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 87/100\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.0188 - accuracy: 0.9933 - mean_io_u: 0.8416 - dice_coef: 0.7052 - precision: 0.9929 - sensitivity: 0.9912 - specificity: 0.9976\n",
      "Epoch 00087: val_loss did not improve from 0.02346\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0188 - accuracy: 0.9933 - mean_io_u: 0.8417 - dice_coef: 0.7054 - precision: 0.9928 - sensitivity: 0.9912 - specificity: 0.9976 - val_loss: 0.0236 - val_accuracy: 0.9922 - val_mean_io_u: 0.8487 - val_dice_coef: 0.6881 - val_precision: 0.9918 - val_sensitivity: 0.9903 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 88/100\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.9934 - mean_io_u: 0.8443 - dice_coef: 0.6985 - precision: 0.9929 - sensitivity: 0.9913 - specificity: 0.9976\n",
      "Epoch 00088: val_loss did not improve from 0.02346\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0186 - accuracy: 0.9934 - mean_io_u: 0.8442 - dice_coef: 0.6986 - precision: 0.9929 - sensitivity: 0.9913 - specificity: 0.9976 - val_loss: 0.0235 - val_accuracy: 0.9922 - val_mean_io_u: 0.8470 - val_dice_coef: 0.6880 - val_precision: 0.9918 - val_sensitivity: 0.9903 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 89/100\n",
      "845/850 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9932 - mean_io_u: 0.8416 - dice_coef: 0.6953 - precision: 0.9927 - sensitivity: 0.9911 - specificity: 0.9975\n",
      "Epoch 00089: val_loss did not improve from 0.02346\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0192 - accuracy: 0.9932 - mean_io_u: 0.8416 - dice_coef: 0.6951 - precision: 0.9927 - sensitivity: 0.9911 - specificity: 0.9975 - val_loss: 0.0235 - val_accuracy: 0.9922 - val_mean_io_u: 0.8426 - val_dice_coef: 0.6863 - val_precision: 0.9918 - val_sensitivity: 0.9902 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 90/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9935 - mean_io_u: 0.8418 - dice_coef: 0.7020 - precision: 0.9930 - sensitivity: 0.9914 - specificity: 0.9976\n",
      "Epoch 00090: val_loss did not improve from 0.02346\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0182 - accuracy: 0.9935 - mean_io_u: 0.8418 - dice_coef: 0.7020 - precision: 0.9930 - sensitivity: 0.9914 - specificity: 0.9976 - val_loss: 0.0237 - val_accuracy: 0.9922 - val_mean_io_u: 0.8495 - val_dice_coef: 0.6892 - val_precision: 0.9918 - val_sensitivity: 0.9903 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 91/100\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9932 - mean_io_u: 0.8444 - dice_coef: 0.7045 - precision: 0.9928 - sensitivity: 0.9912 - specificity: 0.9976\n",
      "Epoch 00091: val_loss did not improve from 0.02346\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0190 - accuracy: 0.9933 - mean_io_u: 0.8444 - dice_coef: 0.7041 - precision: 0.9928 - sensitivity: 0.9912 - specificity: 0.9976 - val_loss: 0.0237 - val_accuracy: 0.9922 - val_mean_io_u: 0.8487 - val_dice_coef: 0.6909 - val_precision: 0.9918 - val_sensitivity: 0.9904 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 92/100\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.9935 - mean_io_u: 0.8466 - dice_coef: 0.7055 - precision: 0.9930 - sensitivity: 0.9915 - specificity: 0.9976\n",
      "Epoch 00092: val_loss did not improve from 0.02346\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0184 - accuracy: 0.9935 - mean_io_u: 0.8466 - dice_coef: 0.7052 - precision: 0.9930 - sensitivity: 0.9915 - specificity: 0.9976 - val_loss: 0.0236 - val_accuracy: 0.9922 - val_mean_io_u: 0.8469 - val_dice_coef: 0.6882 - val_precision: 0.9918 - val_sensitivity: 0.9903 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 93/100\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.9935 - mean_io_u: 0.8428 - dice_coef: 0.7092 - precision: 0.9930 - sensitivity: 0.9914 - specificity: 0.9976\n",
      "Epoch 00093: val_loss did not improve from 0.02346\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0183 - accuracy: 0.9935 - mean_io_u: 0.8429 - dice_coef: 0.7092 - precision: 0.9930 - sensitivity: 0.9914 - specificity: 0.9976 - val_loss: 0.0236 - val_accuracy: 0.9922 - val_mean_io_u: 0.8480 - val_dice_coef: 0.6893 - val_precision: 0.9918 - val_sensitivity: 0.9903 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 94/100\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.9935 - mean_io_u: 0.8438 - dice_coef: 0.7066 - precision: 0.9930 - sensitivity: 0.9914 - specificity: 0.9976\n",
      "Epoch 00094: val_loss did not improve from 0.02346\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0186 - accuracy: 0.9935 - mean_io_u: 0.8437 - dice_coef: 0.7068 - precision: 0.9930 - sensitivity: 0.9914 - specificity: 0.9976 - val_loss: 0.0236 - val_accuracy: 0.9922 - val_mean_io_u: 0.8485 - val_dice_coef: 0.6892 - val_precision: 0.9918 - val_sensitivity: 0.9903 - val_specificity: 0.9973 - lr: 1.0000e-06\n",
      "Epoch 95/100\n",
      "847/850 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9935 - mean_io_u: 0.8426 - dice_coef: 0.7080 - precision: 0.9929 - sensitivity: 0.9914 - specificity: 0.9976\n",
      "Epoch 00095: val_loss did not improve from 0.02346\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0182 - accuracy: 0.9935 - mean_io_u: 0.8426 - dice_coef: 0.7080 - precision: 0.9929 - sensitivity: 0.9914 - specificity: 0.9976 - val_loss: 0.0236 - val_accuracy: 0.9922 - val_mean_io_u: 0.8465 - val_dice_coef: 0.6901 - val_precision: 0.9918 - val_sensitivity: 0.9903 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 96/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9933 - mean_io_u: 0.8425 - dice_coef: 0.7002 - precision: 0.9928 - sensitivity: 0.9913 - specificity: 0.9976\n",
      "Epoch 00096: val_loss did not improve from 0.02346\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0190 - accuracy: 0.9933 - mean_io_u: 0.8425 - dice_coef: 0.7002 - precision: 0.9928 - sensitivity: 0.9913 - specificity: 0.9976 - val_loss: 0.0237 - val_accuracy: 0.9922 - val_mean_io_u: 0.8470 - val_dice_coef: 0.6900 - val_precision: 0.9917 - val_sensitivity: 0.9903 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 97/100\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9934 - mean_io_u: 0.8434 - dice_coef: 0.7013 - precision: 0.9929 - sensitivity: 0.9913 - specificity: 0.9976\n",
      "Epoch 00097: val_loss did not improve from 0.02346\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0187 - accuracy: 0.9934 - mean_io_u: 0.8434 - dice_coef: 0.7010 - precision: 0.9929 - sensitivity: 0.9913 - specificity: 0.9976 - val_loss: 0.0236 - val_accuracy: 0.9922 - val_mean_io_u: 0.8486 - val_dice_coef: 0.6865 - val_precision: 0.9918 - val_sensitivity: 0.9903 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 98/100\n",
      "846/850 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9935 - mean_io_u: 0.8471 - dice_coef: 0.7066 - precision: 0.9930 - sensitivity: 0.9914 - specificity: 0.9976\n",
      "Epoch 00098: val_loss did not improve from 0.02346\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0183 - accuracy: 0.9935 - mean_io_u: 0.8470 - dice_coef: 0.7067 - precision: 0.9930 - sensitivity: 0.9914 - specificity: 0.9976 - val_loss: 0.0238 - val_accuracy: 0.9922 - val_mean_io_u: 0.8500 - val_dice_coef: 0.6941 - val_precision: 0.9917 - val_sensitivity: 0.9904 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 99/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9935 - mean_io_u: 0.8439 - dice_coef: 0.7167 - precision: 0.9930 - sensitivity: 0.9914 - specificity: 0.9976\n",
      "Epoch 00099: val_loss did not improve from 0.02346\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0183 - accuracy: 0.9935 - mean_io_u: 0.8439 - dice_coef: 0.7167 - precision: 0.9930 - sensitivity: 0.9914 - specificity: 0.9976 - val_loss: 0.0238 - val_accuracy: 0.9922 - val_mean_io_u: 0.8521 - val_dice_coef: 0.6928 - val_precision: 0.9918 - val_sensitivity: 0.9904 - val_specificity: 0.9972 - lr: 1.0000e-06\n",
      "Epoch 100/100\n",
      "849/850 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9935 - mean_io_u: 0.8467 - dice_coef: 0.7056 - precision: 0.9929 - sensitivity: 0.9915 - specificity: 0.9976\n",
      "Epoch 00100: val_loss did not improve from 0.02346\n",
      "850/850 [==============================] - 23s 27ms/step - loss: 0.0185 - accuracy: 0.9935 - mean_io_u: 0.8467 - dice_coef: 0.7056 - precision: 0.9929 - sensitivity: 0.9915 - specificity: 0.9976 - val_loss: 0.0236 - val_accuracy: 0.9922 - val_mean_io_u: 0.8496 - val_dice_coef: 0.6904 - val_precision: 0.9918 - val_sensitivity: 0.9904 - val_specificity: 0.9972 - lr: 1.0000e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f41bc9b32b0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_generator,\n",
    "          epochs=EPOCHS,\n",
    "          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=valid_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - 3: Plot the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plt image will be saved in: ./model/model_v1_Mar-12_23-45-26/training-Mar-12_23-45-26.log\n",
      "with name: training-Mar-12_23-45-26\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "model_dir = model_dir\n",
    "training_log_filename = glob.glob(os.path.join(model_dir, 'training-*.log'))[0]\n",
    "plt_filename = os.path.splitext(os.path.basename(training_log_filename))[0]\n",
    "print(f'plt image will be saved in: {training_log_filename}\\nwith name: {plt_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the CSVlogger file that contains all our metrics (accuracy, loss, dice_coef, ...) of our training\n",
    "history = pd.read_csv(training_log_filename, sep=',', engine='python')\n",
    "\n",
    "# Plot training and validation metrics\n",
    "fig, axs = plt.subplots(1, 3, figsize=(16, 8))\n",
    "# fig, axs = plt.subplots(1, 4, figsize=(16, 8))\n",
    "\n",
    "axs[0].plot(history['epoch'], history['accuracy'], 'b', label='Training Accuracy')\n",
    "axs[0].plot(history['epoch'], history['val_accuracy'], 'r', label='Validation Accuracy')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Accuracy')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(history['epoch'], history['loss'], 'b', label='Training Loss')\n",
    "axs[1].plot(history['epoch'], history['val_loss'], 'r', label='Validation Loss')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[1].legend()\n",
    "\n",
    "axs[2].plot(history['epoch'], history['dice_coef'], 'b', label='Training dice coef')\n",
    "axs[2].plot(history['epoch'], history['val_dice_coef'], 'r', label='Validation dice coef')\n",
    "axs[2].set_xlabel('Epoch')\n",
    "axs[2].set_ylabel('Dice Coefficient')\n",
    "axs[2].legend()\n",
    "\n",
    "# axs[3].plot(history['epoch'], history['mean_io_u'], 'b', label='Training mean IOU')\n",
    "# axs[3].plot(history['epoch'], history['val_mean_io_u'], 'r', label='Validation mean IOU')\n",
    "# axs[3].set_xlabel('Epoch')\n",
    "# axs[3].set_ylabel('Mean IOU')\n",
    "# axs[3].legend()\n",
    "\n",
    "# Add space between subplots\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "plt.savefig(f'./plt/{plt_filename}.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile a model and load our saved weights\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "INPUT_LAYER = Input((IMG_SIZE, IMG_SIZE, N_CHANNELS))\n",
    "KER_INIT = KER_INIT\n",
    "DROPOUT = DROPOUT\n",
    "LEARNING_RATE = LEARNING_RATE\n",
    "\n",
    "best_saved_model = unet_v2(inputs = INPUT_LAYER, ker_init = KER_INIT, dropout = DROPOUT)\n",
    "\n",
    "best_saved_model.compile(loss=\"categorical_crossentropy\", optimizer=tensorflow.keras.optimizers.Adam(learning_rate=LEARNING_RATE), metrics = ['accuracy',tensorflow.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity] )\n",
    "\n",
    "TRAINED_MODEL = 'model_epoch28-val_loss0.014139_Mar-08_09-52-06.m5'\n",
    "\n",
    "best_saved_model.load_weights(f'./model_Mar-08_09-52-0/{TRAINED_MODEL}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_segmentation(sample_path):\n",
    "    # Load NIfTI (.nii) files of the sample (patient)\n",
    "    t1ce_path = sample_path + '-t1c.nii.gz'\n",
    "    flair_path = sample_path + '-t2f.nii.gz'\n",
    "    #t1_path = sample_path + '_t1.nii'\n",
    "    #t2_path = sample_path + '_t2.nii'\n",
    "            \n",
    "    # Extract the data from these paths\n",
    "    t1ce = nib.load(t1ce_path).get_fdata()\n",
    "    flair = nib.load(flair_path).get_fdata()\n",
    "    \n",
    "    # Create an empty array\n",
    "    X = np.empty((VOLUME_SLICES_PLUS, IMG_SIZE, IMG_SIZE, 2))\n",
    "    \n",
    "    # Perform the same operations as our DataGenerator, to keep the same input shape\n",
    "    for j in range(VOLUME_SLICES_PLUS):\n",
    "        X[j,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n",
    "        X[j,:,:,1] = cv2.resize(t1ce[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n",
    "        \n",
    "    # Send our images to the CNN model and return predicted segmentation \n",
    "    return model.predict(X/np.max(X), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predicted_segmentations(samples_list, slice_to_plot, cmap, norm):\n",
    "    # Choose a random patient\n",
    "    random_sample = random.choice(samples_list)\n",
    "    print(f'random_sample: {random_sample}')\n",
    "    \n",
    "    # Get path of this patient\n",
    "    random_sample_path = os.path.join(data_path_GLI_train_dir, random_sample, random_sample)\n",
    "    print(f'random_sample_path: {random_sample_path}')\n",
    "    \n",
    "    # Predict patient's segmentation\n",
    "    predicted_seg = predict_segmentation(random_sample_path)\n",
    "   \n",
    "    # Load patient's original segmentation (Ground truth)\n",
    "    seg_path = random_sample_path + '-seg.nii.gz'\n",
    "    seg = nib.load(seg_path).get_fdata()\n",
    "    \n",
    "    # Resize original segmentation to the same dimensions of the predictions. (Add VOLUME_START_AT because original segmentation contains 155 slices vs only 75 for our prediction)\n",
    "    seg=cv2.resize(seg[:,:,slice_to_plot+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_NEAREST)\n",
    "    \n",
    "    # Differentiate segmentations by their labels\n",
    "    all = predicted_seg[slice_to_plot,:,:,1:4] # Deletion of class 0 (Keep only Core + Edema + Enhancing classes)\n",
    "    zero = predicted_seg[slice_to_plot,:,:,0] # Isolation of class 0, Background (kind of useless, it is the opposite of the \"all\")\n",
    "    first = predicted_seg[slice_to_plot,:,:,1] # Isolation of class 1, Core\n",
    "    second = predicted_seg[slice_to_plot,:,:,2] # Isolation of class 2, Edema\n",
    "    third = predicted_seg[slice_to_plot,:,:,3] # Isolation of class 3, Enhancing\n",
    "\n",
    "    # Plot Original segmentation & predicted segmentation\n",
    "    print(\"Patient number: \", random_sample)\n",
    "    fig, axstest = plt.subplots(1, 6, figsize=(25, 20))\n",
    "\n",
    "    # Original segmentation\n",
    "    axstest[0].imshow(seg, cmap, norm)\n",
    "    axstest[0].set_title('Original Segmentation')\n",
    "    \n",
    "    # Layers 1, 2, 3\n",
    "    axstest[1].imshow(all)\n",
    "    axstest[1].set_title('Predicted Segmentation - all layers')\n",
    "    \n",
    "    # Layer 0\n",
    "    axstest[2].imshow(zero)\n",
    "    axstest[2].set_title('Predicted Segmentation - layer 0')\n",
    "    \n",
    "    # Layer 1\n",
    "    axstest[3].imshow(first)\n",
    "    axstest[3].set_title('Predicted Segmentation - layer 1')\n",
    "    \n",
    "    # Layer 2\n",
    "    axstest[4].imshow(second)\n",
    "    axstest[4].set_title('Predicted Segmentation - layer 2')\n",
    "    \n",
    "    # Layer 3\n",
    "    axstest[5].imshow(third)\n",
    "    axstest[5].set_title('Predicted Segmentation - layer 3')\n",
    "    \n",
    "    # Add space between subplots\n",
    "    plt.subplots_adjust(wspace=0.8)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predicted_segmentations(datas_test, 60, cmap, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predicted_segmentations(datas_test, 50, cmap, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predicted_segmentations(datas_test, 70, cmap, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_post_processed_segmentations(sample, slice_to_plot, cmap, norm):\n",
    "    \n",
    "    # Get path of this patient\n",
    "    sample_path = os.path.join(data_path_GLI_train_dir, sample, sample)\n",
    "    \n",
    "    # Predict patient's segmentation\n",
    "    predicted_seg = predict_segmentation(sample_path)\n",
    "   \n",
    "    # Load patient's original segmentation (Ground truth)\n",
    "    seg_path = sample_path + '-seg.nii.gz'\n",
    "    seg = nib.load(seg_path).get_fdata()\n",
    "    \n",
    "    # Resize original segmentation to the same dimensions of the predictions. (Add VOLUME_START_AT because original segmentation contains 155 slices vs only 75 for our prediction)\n",
    "    seg=cv2.resize(seg[:,:,slice_to_plot+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_NEAREST)\n",
    "    \n",
    "    # Fix 4 to 3 to have the same values as in the predicted segmentation, and then same colors\n",
    "    seg[seg==4] = 3\n",
    "    \n",
    "    # Remove background layer (0) from original segmentation\n",
    "    seg[seg==0] = np.nan\n",
    "    \n",
    "    # Post-processing\n",
    "    # Get indexes for each class of the highest probability pixels. Array will then contain only [0 1 2 3] instead of probabilities\n",
    "    my_pred = np.argmax(predicted_seg, axis=3)\n",
    "    my_pred = my_pred[slice_to_plot, :, :]\n",
    "\n",
    "    # Remove background layer (0) from post-processed predicted segmentation\n",
    "    # To fix 0 to np.nan, we need to convert array as a float\n",
    "    my_pred = my_pred.astype(float)\n",
    "    my_pred[my_pred == 0] = np.nan\n",
    "\n",
    "    # Remove background layer (0) from classical predicted segmentation\n",
    "    all = predicted_seg[slice_to_plot,:,:,1:4] \n",
    "    \n",
    "    # Plot Original segmentation & predicted segmentation without processing & predicted segmentation\n",
    "    print(\"Patient number: \", sample)\n",
    "    fig, axstest = plt.subplots(1, 3, figsize=(15, 10))\n",
    "\n",
    "    axstest[0].imshow(seg, cmap, norm)\n",
    "    axstest[0].set_title('Original Segmentation')\n",
    "    \n",
    "    axstest[1].imshow(all)\n",
    "    axstest[1].set_title('Prediction (w/o post processing (layer 1,2,3)')\n",
    "    \n",
    "    axstest[2].imshow(my_pred, cmap, norm)\n",
    "    axstest[2].set_title('Prediction (w/ post processing (layer 1,2,3)')\n",
    "    \n",
    "    # Add space between subplots\n",
    "    plt.subplots_adjust(wspace=0.8)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_post_processed_segmentations(sample = \"BraTS-GLI-00777-000\", slice_to_plot=60, cmap=cmap, norm=norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_post_processed_segmentations(sample = \"BraTS-GLI-00675-000\", slice_to_plot=50, cmap=cmap, norm=norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 - Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_generator = DataGenerator_UnetV1(datas_test) if DATA_GENERATOR_VERSION == 1 else DataGenerator_UnetV2(datas_test)\n",
    "results = model.evaluate(test_generator, batch_size=100, callbacks= callbacks)\n",
    "\n",
    "descriptions = [\"Loss\", \"Accuracy\", \"MeanIOU\", \"Dice coefficient\", \"Precision\", \"Sensitivity\", \"Specificity\"]\n",
    "\n",
    "# Combine results list and descriptions list\n",
    "results_list = zip(results, descriptions)\n",
    "\n",
    "# Display each metric with its description\n",
    "print(\"\\nModel evaluation on the test set:\")\n",
    "print(\"==================================\")\n",
    "for i, (metric, description) in enumerate(results_list):\n",
    "    print(f\"{description} : {round(metric, 4)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aa84e851cfc8b4ce9eea0fba0960fb7c512de47d9926a3aadb9d11b047583128"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
