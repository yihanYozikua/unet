{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 5px solid green; padding: 10px; background-color:rgb(224, 247, 206);\">\n",
    "    <b>⚡️ Information:</b>\n",
    "    Yihan's customized unet experiment\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0 - Set & Check available memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limited GPU memory usage to 12GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 00:54:54.034457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-03-11 00:54:54.038939: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-03-11 00:54:54.039420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "MEMORY_SIZE = 12\n",
    "memory_limit = MEMORY_SIZE * 1024\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memory_limit)]  # Set limit to 8GB\n",
    "        )\n",
    "        print(f\"Limited GPU memory usage to {MEMORY_SIZE}GB\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: GPU:0\n",
      "Current Memory Usage: 0 bytes\n",
      "Peak Memory Usage: 0 bytes\n",
      "Memory growth for PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'): None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 00:54:57.548870: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-11 00:54:57.549501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-03-11 00:54:57.550338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-03-11 00:54:57.551052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-03-11 00:54:57.894727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-03-11 00:54:57.895250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-03-11 00:54:57.895710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-03-11 00:54:57.896144: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:214] Using CUDA malloc Async allocator for GPU: 0\n",
      "2025-03-11 00:54:57.896578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 12288 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        device_name = f\"GPU:{i}\"  # Properly format the device name\n",
    "        details = tf.config.experimental.get_memory_info(device_name)\n",
    "        print(f\"GPU: {device_name}\")\n",
    "        print(f\"Current Memory Usage: {details['current']} bytes\")\n",
    "        print(f\"Peak Memory Usage: {details['peak']} bytes\")\n",
    "else:\n",
    "    print(\"No GPU devices found.\")\n",
    "\n",
    "for gpu in gpus:\n",
    "    print(f\"Memory growth for {gpu}: {tf.config.experimental.get_memory_growth(gpu)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from skimage.transform import rotate\n",
    "from skimage.util import montage\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import cv2\n",
    "import tensorflow\n",
    "import random\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "import numpy as np\n",
    "from keras.callbacks import CSVLogger\n",
    "import keras.backend as K\n",
    "import zipfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### paths, VOLUME_*, IMG_SIZE, N_CHANNELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a sample path (here we will take the first patient of the Training dataset)\n",
    "brats_index = 'BraTS-GLI-00077-000'\n",
    "brats_sample_path = f'../brain_tumor_seg/data/raw_data/GLI_train/{brats_index}/{brats_index}-'\n",
    "\n",
    "# Specify the root data path of training data\n",
    "data_path_GLI_train_dir = f'../brain_tumor_seg/data/raw_data/GLI_train'\n",
    "\n",
    "\n",
    "# Define selected slices range\n",
    "VOLUME_START_AT = 60 \n",
    "VOLUME_SLICES = 75 \n",
    "\n",
    "# For DataGenerator\n",
    "IMG_SIZE = 256\n",
    "N_CHANNELS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not a Step - Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 4 MRI modalities and the segmentation located in the patient's path using the nibabel library\n",
    "t1_img_sample=nib.load(brats_sample_path + 't1n.nii.gz')\n",
    "t1ce_img_sample=nib.load(brats_sample_path + 't1c.nii.gz')\n",
    "t2_img_sample=nib.load(brats_sample_path + 't2w.nii.gz')\n",
    "flair_img_sample=nib.load(brats_sample_path + 't2f.nii.gz')\n",
    "seg_img_sample=nib.load(brats_sample_path + 'seg.nii.gz')\n",
    "\n",
    "# Get the image data\n",
    "t1_data_sample = t1_img_sample.get_fdata()\n",
    "t1ce_data_sample = t1ce_img_sample.get_fdata()\n",
    "t2_data_sample = t2_img_sample.get_fdata()\n",
    "flair_data_sample = flair_img_sample.get_fdata()\n",
    "seg_data_sample = seg_img_sample.get_fdata()\n",
    "\n",
    "# Plot the 100th slice of the 4 RMI modalities and the segmentation\n",
    "slice_nb = 100\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(20,20))\n",
    "axs[0].imshow(t1_data_sample[:,:,slice_nb], cmap=\"gray\")\n",
    "axs[0].set_title('T1')\n",
    "axs[1].imshow(t1ce_data_sample[:,:,slice_nb], cmap=\"gray\")\n",
    "axs[1].set_title('T1CE')\n",
    "axs[2].imshow(t2_data_sample[:,:,slice_nb], cmap=\"gray\")\n",
    "axs[2].set_title('T2')\n",
    "axs[3].imshow(flair_data_sample[:,:,slice_nb], cmap=\"gray\")\n",
    "axs[3].set_title('FLAIR')\n",
    "axs[4].imshow(seg_data_sample[:,:,slice_nb], cmap=\"gray\")\n",
    "axs[4].set_title('Segmentation')\n",
    "plt.savefig(f'./plt/seg_classes_{brats_index}.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a RMI modality through all planes\n",
    "slice_nb = 100\n",
    "\n",
    "fig, axs2 = plt.subplots(1, 3, figsize=(10,10))\n",
    "\n",
    "# Apply a 90° rotation with an automatic resizing, otherwise the display is less obvious to analyze\n",
    "axs2[0].imshow(rotate(t1_data_sample[slice_nb,:,:], 90, resize=True), cmap=\"gray\")\n",
    "axs2[0].set_title('T1 - Sagittal View')\n",
    "\n",
    "axs2[1].imshow(rotate(t1_data_sample[:,slice_nb,:], 90, resize=True), cmap=\"gray\")\n",
    "axs2[1].set_title('T1 - Coronal View')\n",
    "\n",
    "axs2[2].imshow(t1_data_sample[:,:,slice_nb], cmap=\"gray\")\n",
    "axs2[2].set_title('T1 - Axial View')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize = (15,15))\n",
    "ax1.imshow(rotate(montage(t1_data_sample[:,:,:]), 90, resize=True), cmap ='gray')\n",
    "\n",
    "# montage allows us to concatenate multiple images of the same size horizontally and vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all slices of a segmentation\n",
    "fig, ax1 = plt.subplots(1, 1, figsize = (15,15))\n",
    "ax1.imshow(rotate(montage(seg_data_sample[:,:,:]), 90, resize=True), cmap ='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize = (15,15))\n",
    "ax1.imshow(rotate(montage(t1_data_sample[60:135,:,:]), 90, resize=True), cmap ='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a segmantation\n",
    "some_seg_img = nib.load(f'{brats_sample_path}seg.nii.gz').get_fdata()\n",
    "\n",
    "cmap = mpl.colors.ListedColormap(['#440054', '#3b528b', '#18b880', '#e6d74f'])\n",
    "norm = mpl.colors.BoundaryNorm([-0.5, 0.5, 1.5, 2.5, 3.5], cmap.N)\n",
    "\n",
    "plt.imshow(some_seg_img[100,:,:], cmap=cmap, norm=norm)\n",
    "plt.title(brats_index)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_samples = [os.path.join(data_path_GLI_train_dir, sample, f\"{sample}-seg.nii.gz\") for sample in os.listdir(data_path_GLI_train_dir) if not sample.endswith('.csv')]\n",
    "\n",
    "saved_values = []\n",
    "max_nb_values = 0\n",
    "for sample in seg_samples:\n",
    "    seg_img_sample = nib.load(sample).get_fdata()\n",
    "    unique_values = np.unique(seg_img_sample)\n",
    "    nb_unique_values = len(np.unique(seg_img_sample))\n",
    "    \n",
    "    if nb_unique_values > max_nb_values:\n",
    "        max_nb_values = nb_unique_values\n",
    "        saved_values = unique_values\n",
    "\n",
    "print(f\"Maximum number of values in all segmentation images: {max_nb_values}\")\n",
    "print(f\"Values: {saved_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletion of class 0\n",
    "seg_0 = some_seg_img.astype(float).copy()\n",
    "seg_0[seg_0 != 0] = np.nan\n",
    "\n",
    "# Isolation of class 1\n",
    "seg_1 = some_seg_img.astype(float).copy()\n",
    "seg_1[seg_1 != 1] = np.nan\n",
    "\n",
    "# Isolation of class 2\n",
    "seg_2 = some_seg_img.astype(float).copy()\n",
    "seg_2[seg_2 != 2] = np.nan\n",
    "\n",
    "# Isolation of class 4\n",
    "seg_3 = some_seg_img.astype(float).copy()\n",
    "seg_3[seg_3 != 4] = np.nan\n",
    "\n",
    "# Define legend\n",
    "class_names = ['class 0', 'class 1', 'class 2', 'class 3']\n",
    "legend = [plt.Rectangle((0, 0), 1, 1, color=cmap(i), label=class_names[i]) for i in range(len(class_names))]\n",
    "\n",
    "fig, axs3 = plt.subplots(1, 5, figsize=(15, 15))\n",
    "\n",
    "axs3[0].imshow(some_seg_img[100,:,:], cmap=cmap, norm=norm)\n",
    "axs3[0].set_title('Original Segmentation')\n",
    "axs3[0].legend(handles=legend, loc='upper right')\n",
    "\n",
    "axs3[1].imshow(seg_0[100,:,:], cmap=cmap, norm=norm)\n",
    "axs3[1].set_title('[Not Tumor] class 0')\n",
    "\n",
    "axs3[2].imshow(seg_1[100,:,:], cmap=cmap, norm=norm)\n",
    "axs3[2].set_title('[NCR] class 1')\n",
    "\n",
    "axs3[3].imshow(seg_2[100,:,:], cmap=cmap, norm=norm)\n",
    "axs3[3].set_title('[ED] class 2')\n",
    "\n",
    "axs3[4].imshow(seg_3[100,:,:], cmap=cmap, norm=norm)\n",
    "axs3[4].set_title('[ET] class 3')\n",
    "\n",
    "# Save the figure to a file\n",
    "plt.savefig('segmentation_classes.png', dpi=300)  # Saves the image as 'segmentation_classes.png'\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, counts = np.unique(some_seg_img, return_counts=True)\n",
    "print(f'distribution of 4 classes: {counts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modality shape\n",
    "print(f'modality shape: {t1_data_sample.shape}')\n",
    "\n",
    "# Segmentation shape\n",
    "print(f'segmentation shape: {seg_data_sample.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Load images and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 1251\n"
     ]
    }
   ],
   "source": [
    "# Retrieve all samples from path with listdir(). This method lists of all files + directories in the specified directory.\n",
    "all_datas = os.listdir(data_path_GLI_train_dir)\n",
    "print(\"Number of samples:\", len(all_datas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train length: 850\n",
      "Validation length: 251\n",
      "Test length: 150\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into train and validation sets\n",
    "datas_train, datas_val = train_test_split(all_datas, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the train set into the real train set and in a test set \n",
    "datas_train, datas_test = train_test_split(datas_train, test_size=0.15, random_state=42)\n",
    "\n",
    "# Print data distribution (Train: 68%, Test: 12%, Val: 20%)\n",
    "print(f\"Train length: {len(datas_train)}\")\n",
    "print(f\"Validation length: {len(datas_val)}\")\n",
    "print(f\"Test length: {len(datas_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: keras\n",
      "Version: 2.7.0\n",
      "Summary: Deep learning for humans.\n",
      "Home-page: https://keras.io/\n",
      "Author: Keras team\n",
      "Author-email: keras-users@googlegroups.com\n",
      "License: Apache 2.0\n",
      "Location: /home/cbel/Desktop/YIHAN/venv/lib/python3.8/site-packages\n",
      "Requires: \n",
      "Required-by: tensorflow\n",
      "---\n",
      "Name: tensorflow\n",
      "Version: 2.7.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /home/cbel/Desktop/YIHAN/venv/lib/python3.8/site-packages\n",
      "Requires: h5py, keras-preprocessing, google-pasta, tensorboard, protobuf, flatbuffers, six, wrapt, numpy, termcolor, keras, typing-extensions, grpcio, tensorflow-io-gcs-filesystem, opt-einsum, libclang, astunparse, gast, absl-py, tensorflow-estimator, wheel\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show keras tensorflow # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "tensorflow version: 2.7.0\n",
      "is built with CUDA: True\n",
      "GPU details: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU is available.\n",
      "===============================\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"===============================\")\n",
    "print(f'tensorflow version: {tf.__version__}')  # Should print 2.7.0\n",
    "print(f'is built with CUDA: {tf.test.is_built_with_cuda()}')  # Should return True\n",
    "print(f'GPU details: {tf.config.list_physical_devices(\"GPU\")}')  # Should show GPU details\n",
    "\n",
    "# Check if TensorFlow can detect a GPU\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available.\")\n",
    "else:\n",
    "    print(\"GPU is not available.\")\n",
    "\n",
    "print(\"===============================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Set up training compoenents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When generating `DataGenerator`**:\n",
    "- We use a data generator to be able to process and send our data to our neural network (since all our images cannot be stored in memory at once).\n",
    "- For each epoch (single pass of the entire training dataset through a neural network), the model will receive 250 samples (those contained in our training dataset).\n",
    "- For each sample, the model will have to analyze 150 slices (since there are two modalities, and 75(VOLUME_SLICES) selected slices for both of them), received in a (128, 128) shape, as an X array of a (128, 128, 75, 2) shape. This array will be provided with the ground truth segmentation of the patient, which will be One-Hot encoded and will then have a (75, 128, 128, 4) shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 1: DataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-1-1 DataGenerator_UnetV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# DataGenerator from Rastislav's notebook, https://www.kaggle.com/code/rastislav/3d-mri-brain-tumor-segmentation-u-net\n",
    "\n",
    "class DataGenerator_UnetV1(keras.utils.all_utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = N_CHANNELS, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim # Resized image dimensions (128 x 128)\n",
    "        self.batch_size = batch_size #  Number of images to load each time\n",
    "        self.list_IDs = list_IDs # Patients IDs\n",
    "        self.n_channels = n_channels # Number of channels (T1CE + FLAIR)\n",
    "        self.shuffle = shuffle # Indicates if data is shuffled for each epoch\n",
    "        self.on_epoch_end() # Updates indexes after each epoch\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Load & Generate data\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        'Generates data containing batch_size samples'\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n",
    "        y = np.zeros((self.batch_size*VOLUME_SLICES, 240, 240))\n",
    "\n",
    "        # Generate data\n",
    "        for c, i in enumerate(Batch_ids):\n",
    "            \n",
    "            # Get path of each RMI modality and the segmentation\n",
    "            data_path = os.path.join(data_path_GLI_train_dir, i, i)\n",
    "            t1ce_path = data_path + '-t1c.nii.gz'\n",
    "            flair_path = data_path + '-t2f.nii.gz'\n",
    "            seg_path = data_path + '-seg.nii.gz'\n",
    "            #t1_path = sample_path + '_t1.nii.gz'\n",
    "            #t2_path = sample_path + '_t2.nii.gz'\n",
    "            \n",
    "            # Extract the data from these paths\n",
    "            t1ce = nib.load(t1ce_path).get_fdata()\n",
    "            flair = nib.load(flair_path).get_fdata()\n",
    "            seg = nib.load(seg_path).get_fdata()\n",
    "            #t1 = nib.load(t1_paths).get_fdata()\n",
    "            #t2 = nib.load(t2_path).get_fdata()\n",
    "        \n",
    "            for j in range(VOLUME_SLICES):\n",
    "                 X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n",
    "                 X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(t1ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "                 y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT]\n",
    "                    \n",
    "        # Masks / Segmentations\n",
    "        y[y==4] = 3\n",
    "        mask = tensorflow.one_hot(y, 4)\n",
    "        Y = tensorflow.image.resize(mask, (IMG_SIZE, IMG_SIZE))\n",
    "        \n",
    "        # Scale data between 0 and 1 (since the minimum value in the data is 0)\n",
    "        return X/np.max(X), Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-1-2 DataGenerator_UnetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# DataGenerator from Rastislav's notebook, https://www.kaggle.com/code/rastislav/3d-mri-brain-tumor-segmentation-u-net\n",
    "\n",
    "class DataGenerator_UnetV2(keras.utils.all_utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = N_CHANNELS, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim # Resized image dimensions (128 x 128)\n",
    "        self.batch_size = batch_size #  Number of images to load each time\n",
    "        self.list_IDs = list_IDs # Patients IDs\n",
    "        self.n_channels = n_channels # Number of channels (T1CE + FLAIR)\n",
    "        self.shuffle = shuffle # Indicates if data is shuffled for each epoch\n",
    "        self.on_epoch_end() # Updates indexes after each epoch\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Load & Generate data\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        'Generates data containing batch_size samples'\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n",
    "        y = np.zeros((self.batch_size*VOLUME_SLICES, 240, 240))\n",
    "\n",
    "        # Generate data\n",
    "        for c, i in enumerate(Batch_ids):\n",
    "            \n",
    "            # Get path of each RMI modality and the segmentation\n",
    "            data_path = os.path.join(data_path_GLI_train_dir, i, i)\n",
    "            t1ce_path = data_path + '-t1c.nii.gz'\n",
    "            flair_path = data_path + '-t2f.nii.gz'\n",
    "            seg_path = data_path + '-seg.nii.gz'\n",
    "            #t1_path = sample_path + '_t1.nii.gz'\n",
    "            #t2_path = sample_path + '_t2.nii.gz'\n",
    "            \n",
    "            # Extract the data from these paths\n",
    "            t1ce = nib.load(t1ce_path).get_fdata()\n",
    "            flair = nib.load(flair_path).get_fdata()\n",
    "            seg = nib.load(seg_path).get_fdata()\n",
    "            #t1 = nib.load(t1_paths).get_fdata()\n",
    "            #t2 = nib.load(t2_path).get_fdata()\n",
    "        \n",
    "            for j in range(VOLUME_SLICES):\n",
    "                 X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "                 y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT]\n",
    "                    \n",
    "        # Masks / Segmentations\n",
    "        y[y==4] = 3\n",
    "        mask = tensorflow.one_hot(y, 4)\n",
    "        Y = tensorflow.image.resize(mask, (IMG_SIZE, IMG_SIZE))\n",
    "        \n",
    "        # Scale data between 0 and 1 (since the minimum value in the data is 0)\n",
    "        return X/np.max(X), Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 -2: U-Net model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-2-1 U-Net v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net implementation for BraTS 2019 by Naomi Fridman, https://naomi-fridman.medium.com/multi-class-image-segmentation-a5cc671e647a\n",
    "def unet_v1(inputs, ker_init, dropout):\n",
    "    print('****** using U-Net V1 ******')\n",
    "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(inputs)\n",
    "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv1)\n",
    "    \n",
    "    pool = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool)\n",
    "    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv2)\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv3)\n",
    "    \n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool4)\n",
    "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv5)\n",
    "    drop5 = Dropout(dropout)(conv5)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = 2)(drop5))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = 2)(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = 2)(conv8))\n",
    "    merge9 = concatenate([conv,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n",
    "    \n",
    "    up = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = 2)(conv9))\n",
    "    merge = concatenate([conv1,up], axis = 3)\n",
    "    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge)\n",
    "    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n",
    "    \n",
    "    conv10 = Conv2D(4, 1, activation = 'softmax')(conv)\n",
    "    \n",
    "    return Model(inputs = inputs, outputs = conv10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-2-2: U-Net V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_v2(inputs, ker_init, dropout=0.5):\n",
    "    print('****** using U-Net V2 ******')\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv1)\n",
    "\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv2)\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv3)\n",
    "    \n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv4)\n",
    "    drop4 = Dropout(dropout)(conv4)\n",
    "    \n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv5)\n",
    "    drop5 = Dropout(dropout)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n",
    "\n",
    "    conv10 = Conv2D(4, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    return Model(inputs = inputs, outputs = conv10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 3: Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metric between the predicted segmentation and the ground truth\n",
    "def dice_coef(y_true, y_pred, smooth=1.0):\n",
    "    class_num = 4\n",
    "    for i in range(class_num):\n",
    "        y_true_f = K.flatten(y_true[:,:,:,i])\n",
    "        y_pred_f = K.flatten(y_pred[:,:,:,i])\n",
    "        intersection = K.sum(y_true_f * y_pred_f)\n",
    "        loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n",
    "        if i == 0:\n",
    "            total_loss = loss\n",
    "        else:\n",
    "            total_loss = total_loss + loss\n",
    "    total_loss = total_loss / class_num\n",
    "    return total_loss\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())\n",
    "\n",
    "########################### my customized metrics ###########################\n",
    "\n",
    "def sensibility(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    false_positives = K.sum(K.round(K.clip(y_pred - y_true, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    # Calculate the sensibility\n",
    "    sensibility = 1 - (false_positives / (true_positives + possible_positives + K.epsilon()))\n",
    "    # Check for NaN or Inf values and return NaN if True\n",
    "    sensibility = tf.where(tf.math.is_nan(sensibility) | tf.math.is_inf(sensibility),\n",
    "                           tf.constant(float('NaN')),\n",
    "                           sensibility)\n",
    "    return sensibility\n",
    "\n",
    "\n",
    "def jaccard(y_true, y_pred):\n",
    "    # True positives, false positives, false negatives\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    false_positives = K.sum(K.round(K.clip(y_pred - y_true, 0, 1)))\n",
    "    false_negatives = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)))\n",
    "    # Calculate Jaccard index\n",
    "    denominator = true_positives + false_positives + false_negatives + K.epsilon()  # Add epsilon to avoid division by zero\n",
    "    result = true_positives / denominator\n",
    "    # Handle NaN or Inf cases\n",
    "    result = K.switch(K.is_inf(result) | K.is_nan(result), K.constant(float('NaN')), result)\n",
    "    return result\n",
    "\n",
    "\n",
    "# Hausdorff distance (approximation for use in Keras)\n",
    "def hausdorff(y_true, y_pred):\n",
    "    # Flatten the coordinates of the true and predicted segmentation masks\n",
    "    y_true_flat = K.flatten(y_true)\n",
    "    y_pred_flat = K.flatten(y_pred)\n",
    "    # Compute the Euclidean distance between every pair of points\n",
    "    dist_matrix = K.square(y_true_flat - y_pred_flat)\n",
    "    # Get the maximum distance in both directions (directed Hausdorff)\n",
    "    directed_hausdorff_1 = K.max(dist_matrix, axis=1)  # From y_true to y_pred\n",
    "    directed_hausdorff_2 = K.max(dist_matrix, axis=0)  # From y_pred to y_true\n",
    "    # Take the maximum of both directed Hausdorff distances\n",
    "    hausdorff_dist = K.maximum(directed_hausdorff_1, directed_hausdorff_2)\n",
    "    # Handle NaN or Inf values by replacing them with NaN (if needed)\n",
    "    hausdorff_dist = K.switch(K.is_inf(hausdorff_dist) | K.is_nan(hausdorff_dist), K.constant(float('NaN')), hausdorff_dist)\n",
    "    return hausdorff_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 4: Define training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input\n",
    "\n",
    "MODEL_DATA_GENERATOR_VERSION = 1 # see the dict of `model_builders`\n",
    "EPOCHS = 100\n",
    "STEPS_PER_EPOCH = len(datas_train)\n",
    "\n",
    "INPUT_LAYER = Input((IMG_SIZE, IMG_SIZE, N_CHANNELS))\n",
    "KER_INIT = 'he_normal'\n",
    "DROPOUT = 0.2\n",
    "LEARNING_RATE = 1e-4\n",
    "LOSS_FUNCTION = \"categorical_crossentropy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 5: Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** using U-Net V1 ******\n"
     ]
    }
   ],
   "source": [
    "MODEL_VERSION = MODEL_DATA_GENERATOR_VERSION\n",
    "\n",
    "# Build and compile the model\n",
    "model_builders = {\n",
    "    1: unet_v1,\n",
    "    2: unet_v2\n",
    "}\n",
    "model = model_builders.get(MODEL_VERSION, unet_v1)(inputs=INPUT_LAYER, ker_init=KER_INIT, dropout=DROPOUT)\n",
    "\n",
    "model.compile(loss=LOSS_FUNCTION, optimizer=tensorflow.keras.optimizers.Adam(learning_rate=LEARNING_RATE), metrics = ['accuracy',tensorflow.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 6: Set up DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_GENERATOR_VERSION = MODEL_DATA_GENERATOR_VERSION\n",
    "data_generators = {\n",
    "    1: DataGenerator_UnetV1,\n",
    "    2: DataGenerator_UnetV2\n",
    "}\n",
    "\n",
    "training_generator = data_generators.get(DATA_GENERATOR_VERSION, DataGenerator_UnetV1)(datas_train)\n",
    "valid_generator = data_generators.get(DATA_GENERATOR_VERSION, DataGenerator_UnetV1)(datas_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 7: Do the GC and check the GPU and memory status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: GPU:0\n",
      "Current Memory Usage: 31040804 bytes\n",
      "Peak Memory Usage: 37721124 bytes\n",
      "Memory growth for PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'): None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        device_name = f\"GPU:{i}\"  # Properly format the device name\n",
    "        details = tf.config.experimental.get_memory_info(device_name)\n",
    "        print(f\"GPU: {device_name}\")\n",
    "        print(f\"Current Memory Usage: {details['current']} bytes\")\n",
    "        print(f\"Peak Memory Usage: {details['peak']} bytes\")\n",
    "else:\n",
    "    print(\"No GPU devices found.\")\n",
    "\n",
    "for gpu in gpus:\n",
    "    print(f\"Memory growth for {gpu}: {tf.config.experimental.get_memory_growth(gpu)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090, compute capability 8.6\n",
      "WARNING:tensorflow:From /home/cbel/Desktop/YIHAN/venv/lib/python3.8/site-packages/keras/mixed_precision/loss_scale.py:52: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 00:55:22.839236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "# Mixed Precision Training\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - 8: Set up callbacks\n",
    "\n",
    "Callbacks are functions that can be executed during the training process. \n",
    "\n",
    "We will use three callbacks:\n",
    "\n",
    "- **ReduceLROnPlateau**: This callback reduces the learning rate when a metric has stopped improving (validation loss here). The learning rate is reduced by a factor of 0.2, the patience is set to 2 epochs, and the minimum learning rate is set to 0.000001.\n",
    "\n",
    "- **ModelCheckpoint**: Saves the best model weights (model that has obtained the lowest validation loss during the different epochs). Saving a model allows us to reuse it later or to share it, without having to retrain it from scratch. This will save us time and resources!\n",
    "\n",
    "- **CSVLogger**: Add metrics to a CSV file, which is named *training.log* (parameter `append` is set to `False` so the file is overwritten if it already exists). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dir ./model_v1_Mar-11_00-55-22 created.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Generate timestamp for filenames\n",
    "start_train_timestamp = datetime.now().strftime(\"%b-%d_%H-%M-%S\")\n",
    "\n",
    "model_dir = f'./model_v{MODEL_DATA_GENERATOR_VERSION}_{start_train_timestamp}'\n",
    "\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    print(f\"Model dir {model_dir} created.\")\n",
    "else:\n",
    "    print(f\"Model dir {model_dir} existed.\")\n",
    "\n",
    "# Define file paths with timestamps\n",
    "training_log_filename = f\"{model_dir}/training-{start_train_timestamp}.log\"\n",
    "model_checkpoint_path = f\"{model_dir}/model_epoch{{epoch:02d}}-val_loss{{val_loss:.6f}}_{start_train_timestamp}.m5\"\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.000001, verbose=1),\n",
    "    \n",
    "    keras.callbacks.ModelCheckpoint(filepath=model_checkpoint_path, verbose=1, save_best_only=True, save_weights_only=True),\n",
    "\n",
    "    CSVLogger(training_log_filename, separator=',', append=False)  # Save logs with timestamp\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Train & Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - 1: log all cell outputs during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "model name: unet_v1\n",
      "epochs: 100\n",
      "steps_per_epoch: 850\n",
      "dimension: 256\n",
      "n_channels: 2\n",
      "input layer: KerasTensor(type_spec=TensorSpec(shape=(None, 256, 256, 2), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
      "kernel init: he_normal\n",
      "dropout: 0.2\n",
      "learning rate: 0.0001\n",
      "loss function: categorical_crossentropy\n",
      "start training at: Mar-11_00-55-22\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(f'----------')\n",
    "print(f'model name: {model_builders[MODEL_DATA_GENERATOR_VERSION].__name__}')\n",
    "print(f'epochs: {EPOCHS}')\n",
    "print(f'steps_per_epoch: {STEPS_PER_EPOCH}')\n",
    "print(f'dimension: {IMG_SIZE}')\n",
    "print(f'n_channels: {N_CHANNELS}')\n",
    "print(f'input layer: {INPUT_LAYER}')\n",
    "print(f'kernel init: {KER_INIT}')\n",
    "print(f'dropout: {DROPOUT}')\n",
    "print(f'learning rate: {LEARNING_RATE}')\n",
    "print(f'loss function: {LOSS_FUNCTION}')\n",
    "print(f'start training at: {start_train_timestamp}')\n",
    "print(f'----------')\n",
    "\n",
    "original_stdout = sys.stdout\n",
    "with open(f'{model_dir}/info.log', 'w') as log_file:\n",
    "    sys.stdout = log_file\n",
    "    print(f'----------')\n",
    "    print(f'model name: {model_builders[MODEL_DATA_GENERATOR_VERSION].__name__}')\n",
    "    print(f'epochs: {EPOCHS}')\n",
    "    print(f'steps_per_epoch: {STEPS_PER_EPOCH}')\n",
    "    print(f'dimension: {IMG_SIZE}')\n",
    "    print(f'n_channels: {N_CHANNELS}')\n",
    "    print(f'input layer: {INPUT_LAYER}')\n",
    "    print(f'kernel init: {KER_INIT}')\n",
    "    print(f'dropout: {DROPOUT}')\n",
    "    print(f'learning rate: {LEARNING_RATE}')\n",
    "    print(f'loss function: {LOSS_FUNCTION}')\n",
    "\n",
    "    print(f\"train length: {len(datas_train)}\")\n",
    "    print(f\"validation length: {len(datas_val)}\")\n",
    "    print(f\"test length: {len(datas_test)}\")\n",
    "\n",
    "    print(f'start training at: {start_train_timestamp}')\n",
    "    print(f'----------')\n",
    "\n",
    "sys.stdout = original_stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - 2: train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 54/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9967 - mean_io_u: 0.8500 - dice_coef: 0.7635 - precision: 0.9962 - sensitivity: 0.9957 - specificity: 0.9987\n",
      "Epoch 00054: val_loss did not improve from 0.01337\n",
      "850/850 [==============================] - 563s 662ms/step - loss: 0.0093 - accuracy: 0.9967 - mean_io_u: 0.8500 - dice_coef: 0.7635 - precision: 0.9962 - sensitivity: 0.9957 - specificity: 0.9987 - val_loss: 0.0137 - val_accuracy: 0.9957 - val_mean_io_u: 0.8521 - val_dice_coef: 0.7306 - val_precision: 0.9953 - val_sensitivity: 0.9948 - val_specificity: 0.9984 - lr: 1.0000e-06\n",
      "Epoch 55/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9967 - mean_io_u: 0.8509 - dice_coef: 0.7640 - precision: 0.9962 - sensitivity: 0.9957 - specificity: 0.9987\n",
      "Epoch 00055: val_loss did not improve from 0.01337\n",
      "850/850 [==============================] - 564s 663ms/step - loss: 0.0093 - accuracy: 0.9967 - mean_io_u: 0.8509 - dice_coef: 0.7640 - precision: 0.9962 - sensitivity: 0.9957 - specificity: 0.9987 - val_loss: 0.0137 - val_accuracy: 0.9957 - val_mean_io_u: 0.8509 - val_dice_coef: 0.7302 - val_precision: 0.9953 - val_sensitivity: 0.9948 - val_specificity: 0.9984 - lr: 1.0000e-06\n",
      "Epoch 56/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9967 - mean_io_u: 0.8502 - dice_coef: 0.7643 - precision: 0.9962 - sensitivity: 0.9957 - specificity: 0.9987\n",
      "Epoch 00057: val_loss did not improve from 0.01337\n",
      "850/850 [==============================] - 564s 663ms/step - loss: 0.0092 - accuracy: 0.9967 - mean_io_u: 0.8502 - dice_coef: 0.7643 - precision: 0.9962 - sensitivity: 0.9957 - specificity: 0.9987 - val_loss: 0.0138 - val_accuracy: 0.9957 - val_mean_io_u: 0.8526 - val_dice_coef: 0.7315 - val_precision: 0.9953 - val_sensitivity: 0.9948 - val_specificity: 0.9984 - lr: 1.0000e-06\n",
      "Epoch 58/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9967 - mean_io_u: 0.8509 - dice_coef: 0.7647 - precision: 0.9962 - sensitivity: 0.9957 - specificity: 0.9987\n",
      "Epoch 00058: val_loss did not improve from 0.01337\n",
      "850/850 [==============================] - 565s 664ms/step - loss: 0.0092 - accuracy: 0.9967 - mean_io_u: 0.8509 - dice_coef: 0.7647 - precision: 0.9962 - sensitivity: 0.9957 - specificity: 0.9987 - val_loss: 0.0137 - val_accuracy: 0.9957 - val_mean_io_u: 0.8510 - val_dice_coef: 0.7313 - val_precision: 0.9953 - val_sensitivity: 0.9948 - val_specificity: 0.9984 - lr: 1.0000e-06\n",
      "Epoch 59/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9967 - mean_io_u: 0.8508 - dice_coef: 0.7647 - precision: 0.9962 - sensitivity: 0.9957 - specificity: 0.9987\n",
      "Epoch 00059: val_loss did not improve from 0.01337\n",
      "850/850 [==============================] - 564s 663ms/step - loss: 0.0092 - accuracy: 0.9967 - mean_io_u: 0.8508 - dice_coef: 0.7647 - precision: 0.9962 - sensitivity: 0.9957 - specificity: 0.9987 - val_loss: 0.0137 - val_accuracy: 0.9957 - val_mean_io_u: 0.8510 - val_dice_coef: 0.7316 - val_precision: 0.9953 - val_sensitivity: 0.9948 - val_specificity: 0.9984 - lr: 1.0000e-06\n",
      "Epoch 60/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9967 - mean_io_u: 0.8510 - dice_coef: 0.7650 - precision: 0.9962 - sensitivity: 0.9957 - specificity: 0.9987\n",
      "Epoch 00060: val_loss did not improve from 0.01337\n",
      "850/850 [==============================] - 564s 664ms/step - loss: 0.0092 - accuracy: 0.9967 - mean_io_u: 0.8510 - dice_coef: 0.7650 - precision: 0.9962 - sensitivity: 0.9957 - specificity: 0.9987 - val_loss: 0.0139 - val_accuracy: 0.9957 - val_mean_io_u: 0.8526 - val_dice_coef: 0.7318 - val_precision: 0.9953 - val_sensitivity: 0.9948 - val_specificity: 0.9984 - lr: 1.0000e-06\n",
      "Epoch 61/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9967 - mean_io_u: 0.8511 - dice_coef: 0.7651 - precision: 0.9962 - sensitivity: 0.9957 - specificity: 0.9987\n",
      "Epoch 00061: val_loss did not improve from 0.01337\n",
      "850/850 [==============================] - 562s 662ms/step - loss: 0.0092 - accuracy: 0.9967 - mean_io_u: 0.8511 - dice_coef: 0.7651 - precision: 0.9962 - sensitivity: 0.9957 - specificity: 0.9987 - val_loss: 0.0137 - val_accuracy: 0.9957 - val_mean_io_u: 0.8517 - val_dice_coef: 0.7313 - val_precision: 0.9953 - val_sensitivity: 0.9948 - val_specificity: 0.9984 - lr: 1.0000e-06\n",
      "Epoch 62/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9967 - mean_io_u: 0.8507 - dice_coef: 0.7648 - precision: 0.9962 - sensitivity: 0.9957 - specificity: 0.9987\n",
      "Epoch 00062: val_loss did not improve from 0.01337\n",
      "850/850 [==============================] - 562s 661ms/step - loss: 0.0092 - accuracy: 0.9967 - mean_io_u: 0.8507 - dice_coef: 0.7648 - precision: 0.9962 - sensitivity: 0.9957 - specificity: 0.9987 - val_loss: 0.0139 - val_accuracy: 0.9957 - val_mean_io_u: 0.8534 - val_dice_coef: 0.7328 - val_precision: 0.9953 - val_sensitivity: 0.9948 - val_specificity: 0.9984 - lr: 1.0000e-06\n",
      "Epoch 63/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9968 - mean_io_u: 0.8517 - dice_coef: 0.7661 - precision: 0.9962 - sensitivity: 0.9957 - specificity: 0.9987\n",
      "Epoch 00063: val_loss did not improve from 0.01337\n",
      "850/850 [==============================] - 561s 660ms/step - loss: 0.0092 - accuracy: 0.9968 - mean_io_u: 0.8517 - dice_coef: 0.7661 - precision: 0.9962 - sensitivity: 0.9957 - specificity: 0.9987 - val_loss: 0.0138 - val_accuracy: 0.9957 - val_mean_io_u: 0.8516 - val_dice_coef: 0.7319 - val_precision: 0.9953 - val_sensitivity: 0.9948 - val_specificity: 0.9984 - lr: 1.0000e-06\n",
      "Epoch 64/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9968 - mean_io_u: 0.8510 - dice_coef: 0.7657 - precision: 0.9962 - sensitivity: 0.9957 - specificity: 0.9987\n",
      "Epoch 00064: val_loss did not improve from 0.01337\n",
      "850/850 [==============================] - 561s 660ms/step - loss: 0.0091 - accuracy: 0.9968 - mean_io_u: 0.8510 - dice_coef: 0.7657 - precision: 0.9962 - sensitivity: 0.9957 - specificity: 0.9987 - val_loss: 0.0139 - val_accuracy: 0.9957 - val_mean_io_u: 0.8543 - val_dice_coef: 0.7323 - val_precision: 0.9953 - val_sensitivity: 0.9948 - val_specificity: 0.9984 - lr: 1.0000e-06\n",
      "Epoch 65/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9968 - mean_io_u: 0.8512 - dice_coef: 0.7660 - precision: 0.9962 - sensitivity: 0.9957 - specificity: 0.9987\n",
      "Epoch 00065: val_loss did not improve from 0.01337\n",
      "850/850 [==============================] - 561s 660ms/step - loss: 0.0091 - accuracy: 0.9968 - mean_io_u: 0.8512 - dice_coef: 0.7660 - precision: 0.9962 - sensitivity: 0.9957 - specificity: 0.9987 - val_loss: 0.0138 - val_accuracy: 0.9957 - val_mean_io_u: 0.8536 - val_dice_coef: 0.7322 - val_precision: 0.9953 - val_sensitivity: 0.9948 - val_specificity: 0.9984 - lr: 1.0000e-06\n",
      "Epoch 66/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9968 - mean_io_u: 0.8518 - dice_coef: 0.7663 - precision: 0.9962 - sensitivity: 0.9957 - specificity: 0.9987\n",
      "Epoch 00066: val_loss did not improve from 0.01337\n",
      "850/850 [==============================] - 562s 661ms/step - loss: 0.0091 - accuracy: 0.9968 - mean_io_u: 0.8518 - dice_coef: 0.7663 - precision: 0.9962 - sensitivity: 0.9957 - specificity: 0.9987 - val_loss: 0.0138 - val_accuracy: 0.9957 - val_mean_io_u: 0.8522 - val_dice_coef: 0.7323 - val_precision: 0.9953 - val_sensitivity: 0.9948 - val_specificity: 0.9984 - lr: 1.0000e-06\n",
      "Epoch 67/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9968 - mean_io_u: 0.8520 - dice_coef: 0.7663 - precision: 0.9963 - sensitivity: 0.9957 - specificity: 0.9987\n",
      "Epoch 00067: val_loss did not improve from 0.01337\n",
      "850/850 [==============================] - 562s 661ms/step - loss: 0.0091 - accuracy: 0.9968 - mean_io_u: 0.8520 - dice_coef: 0.7663 - precision: 0.9963 - sensitivity: 0.9957 - specificity: 0.9987 - val_loss: 0.0138 - val_accuracy: 0.9957 - val_mean_io_u: 0.8531 - val_dice_coef: 0.7323 - val_precision: 0.9953 - val_sensitivity: 0.9948 - val_specificity: 0.9984 - lr: 1.0000e-06\n",
      "Epoch 68/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9968 - mean_io_u: 0.8519 - dice_coef: 0.7666 - precision: 0.9963 - sensitivity: 0.9958 - specificity: 0.9987\n",
      "Epoch 00068: val_loss did not improve from 0.01337\n",
      "850/850 [==============================] - 562s 661ms/step - loss: 0.0091 - accuracy: 0.9968 - mean_io_u: 0.8519 - dice_coef: 0.7666 - precision: 0.9963 - sensitivity: 0.9958 - specificity: 0.9987 - val_loss: 0.0138 - val_accuracy: 0.9957 - val_mean_io_u: 0.8532 - val_dice_coef: 0.7325 - val_precision: 0.9953 - val_sensitivity: 0.9948 - val_specificity: 0.9984 - lr: 1.0000e-06\n",
      "Epoch 69/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9968 - mean_io_u: 0.8519 - dice_coef: 0.7666 - precision: 0.9963 - sensitivity: 0.9958 - specificity: 0.9987\n",
      "Epoch 00069: val_loss did not improve from 0.01337\n",
      "850/850 [==============================] - 561s 660ms/step - loss: 0.0091 - accuracy: 0.9968 - mean_io_u: 0.8519 - dice_coef: 0.7666 - precision: 0.9963 - sensitivity: 0.9958 - specificity: 0.9987 - val_loss: 0.0139 - val_accuracy: 0.9957 - val_mean_io_u: 0.8530 - val_dice_coef: 0.7335 - val_precision: 0.9953 - val_sensitivity: 0.9948 - val_specificity: 0.9984 - lr: 1.0000e-06\n",
      "Epoch 70/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9968 - mean_io_u: 0.8518 - dice_coef: 0.7673 - precision: 0.9963 - sensitivity: 0.9958 - specificity: 0.9987\n",
      "Epoch 00070: val_loss did not improve from 0.01337\n",
      "850/850 [==============================] - 561s 660ms/step - loss: 0.0091 - accuracy: 0.9968 - mean_io_u: 0.8518 - dice_coef: 0.7673 - precision: 0.9963 - sensitivity: 0.9958 - specificity: 0.9987 - val_loss: 0.0138 - val_accuracy: 0.9957 - val_mean_io_u: 0.8537 - val_dice_coef: 0.7327 - val_precision: 0.9953 - val_sensitivity: 0.9948 - val_specificity: 0.9984 - lr: 1.0000e-06\n",
      "Epoch 71/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9968 - mean_io_u: 0.8523 - dice_coef: 0.7670 - precision: 0.9963 - sensitivity: 0.9958 - specificity: 0.9987\n",
      "Epoch 00071: val_loss did not improve from 0.01337\n",
      "850/850 [==============================] - 562s 661ms/step - loss: 0.0090 - accuracy: 0.9968 - mean_io_u: 0.8523 - dice_coef: 0.7670 - precision: 0.9963 - sensitivity: 0.9958 - specificity: 0.9987 - val_loss: 0.0139 - val_accuracy: 0.9957 - val_mean_io_u: 0.8541 - val_dice_coef: 0.7336 - val_precision: 0.9953 - val_sensitivity: 0.9948 - val_specificity: 0.9984 - lr: 1.0000e-06\n",
      "Epoch 72/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9968 - mean_io_u: 0.8523 - dice_coef: 0.7675 - precision: 0.9963 - sensitivity: 0.9958 - specificity: 0.9987\n",
      "Epoch 00072: val_loss did not improve from 0.01337\n",
      "850/850 [==============================] - 561s 660ms/step - loss: 0.0090 - accuracy: 0.9968 - mean_io_u: 0.8523 - dice_coef: 0.7675 - precision: 0.9963 - sensitivity: 0.9958 - specificity: 0.9987 - val_loss: 0.0139 - val_accuracy: 0.9957 - val_mean_io_u: 0.8548 - val_dice_coef: 0.7335 - val_precision: 0.9953 - val_sensitivity: 0.9948 - val_specificity: 0.9984 - lr: 1.0000e-06\n",
      "Epoch 73/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9968 - mean_io_u: 0.8524 - dice_coef: 0.7679 - precision: 0.9963 - sensitivity: 0.9958 - specificity: 0.9987\n",
      "Epoch 00073: val_loss did not improve from 0.01337\n",
      "850/850 [==============================] - 561s 660ms/step - loss: 0.0090 - accuracy: 0.9968 - mean_io_u: 0.8524 - dice_coef: 0.7679 - precision: 0.9963 - sensitivity: 0.9958 - specificity: 0.9987 - val_loss: 0.0138 - val_accuracy: 0.9957 - val_mean_io_u: 0.8541 - val_dice_coef: 0.7333 - val_precision: 0.9953 - val_sensitivity: 0.9948 - val_specificity: 0.9984 - lr: 1.0000e-06\n",
      "Epoch 74/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9968 - mean_io_u: 0.8523 - dice_coef: 0.7679 - precision: 0.9963 - sensitivity: 0.9958 - specificity: 0.9987\n",
      "Epoch 00074: val_loss did not improve from 0.01337\n",
      "850/850 [==============================] - 562s 661ms/step - loss: 0.0090 - accuracy: 0.9968 - mean_io_u: 0.8523 - dice_coef: 0.7679 - precision: 0.9963 - sensitivity: 0.9958 - specificity: 0.9987 - val_loss: 0.0139 - val_accuracy: 0.9957 - val_mean_io_u: 0.8546 - val_dice_coef: 0.7333 - val_precision: 0.9953 - val_sensitivity: 0.9948 - val_specificity: 0.9984 - lr: 1.0000e-06\n",
      "Epoch 75/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9968 - mean_io_u: 0.8527 - dice_coef: 0.7679 - precision: 0.9963 - sensitivity: 0.9958 - specificity: 0.9987\n",
      "Epoch 00075: val_loss did not improve from 0.01337\n",
      "850/850 [==============================] - 561s 660ms/step - loss: 0.0090 - accuracy: 0.9968 - mean_io_u: 0.8527 - dice_coef: 0.7679 - precision: 0.9963 - sensitivity: 0.9958 - specificity: 0.9987 - val_loss: 0.0139 - val_accuracy: 0.9957 - val_mean_io_u: 0.8550 - val_dice_coef: 0.7335 - val_precision: 0.9953 - val_sensitivity: 0.9948 - val_specificity: 0.9984 - lr: 1.0000e-06\n",
      "Epoch 76/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9968 - mean_io_u: 0.8532 - dice_coef: 0.7685 - precision: 0.9963 - sensitivity: 0.9958 - specificity: 0.9988\n",
      "Epoch 00076: val_loss did not improve from 0.01337\n",
      "850/850 [==============================] - 561s 660ms/step - loss: 0.0090 - accuracy: 0.9968 - mean_io_u: 0.8532 - dice_coef: 0.7685 - precision: 0.9963 - sensitivity: 0.9958 - specificity: 0.9988 - val_loss: 0.0139 - val_accuracy: 0.9957 - val_mean_io_u: 0.8548 - val_dice_coef: 0.7333 - val_precision: 0.9953 - val_sensitivity: 0.9948 - val_specificity: 0.9984 - lr: 1.0000e-06\n",
      "Epoch 77/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9968 - mean_io_u: 0.8526 - dice_coef: 0.7684 - precision: 0.9963 - sensitivity: 0.9958 - specificity: 0.9988\n",
      "Epoch 00077: val_loss did not improve from 0.01337\n",
      "850/850 [==============================] - 561s 660ms/step - loss: 0.0090 - accuracy: 0.9968 - mean_io_u: 0.8526 - dice_coef: 0.7684 - precision: 0.9963 - sensitivity: 0.9958 - specificity: 0.9988 - val_loss: 0.0139 - val_accuracy: 0.9957 - val_mean_io_u: 0.8542 - val_dice_coef: 0.7337 - val_precision: 0.9953 - val_sensitivity: 0.9948 - val_specificity: 0.9984 - lr: 1.0000e-06\n",
      "Epoch 78/100\n",
      "471/850 [===============>..............] - ETA: 3:36 - loss: 0.0089 - accuracy: 0.9969 - mean_io_u: 0.8524 - dice_coef: 0.7654 - precision: 0.9963 - sensitivity: 0.9959 - specificity: 0.9988"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 00:55:39.690911: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850/850 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.9800 - mean_io_u: 0.7468 - dice_coef: 0.3066 - precision: 0.9828 - sensitivity: 0.9706 - specificity: 0.9952\n",
      "Epoch 00001: val_loss improved from inf to 0.06398, saving model to ./model_v1_Mar-11_00-55-22/model_epoch01-val_loss0.063975_Mar-11_00-55-22.m5\n",
      "850/850 [==============================] - 567s 656ms/step - loss: 0.0843 - accuracy: 0.9800 - mean_io_u: 0.7468 - dice_coef: 0.3066 - precision: 0.9828 - sensitivity: 0.9706 - specificity: 0.9952 - val_loss: 0.0640 - val_accuracy: 0.9834 - val_mean_io_u: 0.7524 - val_dice_coef: 0.3354 - val_precision: 0.9895 - val_sensitivity: 0.9757 - val_specificity: 0.9964 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9856 - mean_io_u: 0.7944 - dice_coef: 0.3799 - precision: 0.9894 - sensitivity: 0.9813 - specificity: 0.9964\n",
      "Epoch 00002: val_loss improved from 0.06398 to 0.04864, saving model to ./model_v1_Mar-11_00-55-22/model_epoch02-val_loss0.048638_Mar-11_00-55-22.m5\n",
      "850/850 [==============================] - 560s 658ms/step - loss: 0.0487 - accuracy: 0.9856 - mean_io_u: 0.7944 - dice_coef: 0.3799 - precision: 0.9894 - sensitivity: 0.9813 - specificity: 0.9964 - val_loss: 0.0486 - val_accuracy: 0.9837 - val_mean_io_u: 0.7954 - val_dice_coef: 0.3552 - val_precision: 0.9859 - val_sensitivity: 0.9826 - val_specificity: 0.9953 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 0.9878 - mean_io_u: 0.8097 - dice_coef: 0.4403 - precision: 0.9903 - sensitivity: 0.9846 - specificity: 0.9967\n",
      "Epoch 00003: val_loss improved from 0.04864 to 0.03366, saving model to ./model_v1_Mar-11_00-55-22/model_epoch03-val_loss0.033664_Mar-11_00-55-22.m5\n",
      "850/850 [==============================] - 556s 653ms/step - loss: 0.0395 - accuracy: 0.9878 - mean_io_u: 0.8097 - dice_coef: 0.4403 - precision: 0.9903 - sensitivity: 0.9846 - specificity: 0.9967 - val_loss: 0.0337 - val_accuracy: 0.9889 - val_mean_io_u: 0.8045 - val_dice_coef: 0.4719 - val_precision: 0.9900 - val_sensitivity: 0.9871 - val_specificity: 0.9966 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.9893 - mean_io_u: 0.8095 - dice_coef: 0.4928 - precision: 0.9910 - sensitivity: 0.9866 - specificity: 0.9969\n",
      "Epoch 00004: val_loss improved from 0.03366 to 0.03186, saving model to ./model_v1_Mar-11_00-55-22/model_epoch04-val_loss0.031863_Mar-11_00-55-22.m5\n",
      "850/850 [==============================] - 555s 653ms/step - loss: 0.0343 - accuracy: 0.9893 - mean_io_u: 0.8095 - dice_coef: 0.4928 - precision: 0.9910 - sensitivity: 0.9866 - specificity: 0.9969 - val_loss: 0.0319 - val_accuracy: 0.9899 - val_mean_io_u: 0.8113 - val_dice_coef: 0.4745 - val_precision: 0.9916 - val_sensitivity: 0.9875 - val_specificity: 0.9972 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 0.9913 - mean_io_u: 0.8048 - dice_coef: 0.5586 - precision: 0.9922 - sensitivity: 0.9893 - specificity: 0.9974\n",
      "Epoch 00005: val_loss improved from 0.03186 to 0.02415, saving model to ./model_v1_Mar-11_00-55-22/model_epoch05-val_loss0.024145_Mar-11_00-55-22.m5\n",
      "850/850 [==============================] - 555s 652ms/step - loss: 0.0271 - accuracy: 0.9913 - mean_io_u: 0.8048 - dice_coef: 0.5586 - precision: 0.9922 - sensitivity: 0.9893 - specificity: 0.9974 - val_loss: 0.0241 - val_accuracy: 0.9921 - val_mean_io_u: 0.8152 - val_dice_coef: 0.5371 - val_precision: 0.9931 - val_sensitivity: 0.9902 - val_specificity: 0.9977 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9920 - mean_io_u: 0.8087 - dice_coef: 0.5899 - precision: 0.9928 - sensitivity: 0.9903 - specificity: 0.9975\n",
      "Epoch 00006: val_loss improved from 0.02415 to 0.02220, saving model to ./model_v1_Mar-11_00-55-22/model_epoch06-val_loss0.022200_Mar-11_00-55-22.m5\n",
      "850/850 [==============================] - 555s 653ms/step - loss: 0.0248 - accuracy: 0.9920 - mean_io_u: 0.8087 - dice_coef: 0.5899 - precision: 0.9928 - sensitivity: 0.9903 - specificity: 0.9975 - val_loss: 0.0222 - val_accuracy: 0.9931 - val_mean_io_u: 0.7959 - val_dice_coef: 0.5826 - val_precision: 0.9937 - val_sensitivity: 0.9914 - val_specificity: 0.9978 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9928 - mean_io_u: 0.8101 - dice_coef: 0.6159 - precision: 0.9933 - sensitivity: 0.9911 - specificity: 0.9977\n",
      "Epoch 00007: val_loss did not improve from 0.02220\n",
      "850/850 [==============================] - 555s 653ms/step - loss: 0.0220 - accuracy: 0.9928 - mean_io_u: 0.8101 - dice_coef: 0.6159 - precision: 0.9933 - sensitivity: 0.9911 - specificity: 0.9977 - val_loss: 0.0239 - val_accuracy: 0.9927 - val_mean_io_u: 0.8180 - val_dice_coef: 0.6126 - val_precision: 0.9928 - val_sensitivity: 0.9917 - val_specificity: 0.9976 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 0.9933 - mean_io_u: 0.8203 - dice_coef: 0.6333 - precision: 0.9936 - sensitivity: 0.9917 - specificity: 0.9978\n",
      "Epoch 00008: val_loss improved from 0.02220 to 0.01815, saving model to ./model_v1_Mar-11_00-55-22/model_epoch08-val_loss0.018152_Mar-11_00-55-22.m5\n",
      "850/850 [==============================] - 558s 656ms/step - loss: 0.0205 - accuracy: 0.9933 - mean_io_u: 0.8203 - dice_coef: 0.6333 - precision: 0.9936 - sensitivity: 0.9917 - specificity: 0.9978 - val_loss: 0.0182 - val_accuracy: 0.9941 - val_mean_io_u: 0.8281 - val_dice_coef: 0.6450 - val_precision: 0.9942 - val_sensitivity: 0.9929 - val_specificity: 0.9981 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9938 - mean_io_u: 0.8184 - dice_coef: 0.6539 - precision: 0.9940 - sensitivity: 0.9924 - specificity: 0.9980\n",
      "Epoch 00009: val_loss did not improve from 0.01815\n",
      "850/850 [==============================] - 557s 655ms/step - loss: 0.0185 - accuracy: 0.9938 - mean_io_u: 0.8184 - dice_coef: 0.6539 - precision: 0.9940 - sensitivity: 0.9924 - specificity: 0.9980 - val_loss: 0.0206 - val_accuracy: 0.9933 - val_mean_io_u: 0.8325 - val_dice_coef: 0.6309 - val_precision: 0.9935 - val_sensitivity: 0.9922 - val_specificity: 0.9978 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9938 - mean_io_u: 0.8109 - dice_coef: 0.6546 - precision: 0.9940 - sensitivity: 0.9924 - specificity: 0.9980\n",
      "Epoch 00010: val_loss improved from 0.01815 to 0.01714, saving model to ./model_v1_Mar-11_00-55-22/model_epoch10-val_loss0.017136_Mar-11_00-55-22.m5\n",
      "850/850 [==============================] - 556s 654ms/step - loss: 0.0187 - accuracy: 0.9938 - mean_io_u: 0.8109 - dice_coef: 0.6546 - precision: 0.9940 - sensitivity: 0.9924 - specificity: 0.9980 - val_loss: 0.0171 - val_accuracy: 0.9943 - val_mean_io_u: 0.8158 - val_dice_coef: 0.6467 - val_precision: 0.9945 - val_sensitivity: 0.9929 - val_specificity: 0.9981 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.9944 - mean_io_u: 0.8190 - dice_coef: 0.6728 - precision: 0.9944 - sensitivity: 0.9930 - specificity: 0.9981\n",
      "Epoch 00011: val_loss did not improve from 0.01714\n",
      "850/850 [==============================] - 555s 653ms/step - loss: 0.0167 - accuracy: 0.9944 - mean_io_u: 0.8190 - dice_coef: 0.6728 - precision: 0.9944 - sensitivity: 0.9930 - specificity: 0.9981 - val_loss: 0.0184 - val_accuracy: 0.9938 - val_mean_io_u: 0.8277 - val_dice_coef: 0.6302 - val_precision: 0.9945 - val_sensitivity: 0.9920 - val_specificity: 0.9981 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9942 - mean_io_u: 0.8198 - dice_coef: 0.6727 - precision: 0.9943 - sensitivity: 0.9928 - specificity: 0.9981\n",
      "Epoch 00012: val_loss improved from 0.01714 to 0.01699, saving model to ./model_v1_Mar-11_00-55-22/model_epoch12-val_loss0.016990_Mar-11_00-55-22.m5\n",
      "850/850 [==============================] - 555s 653ms/step - loss: 0.0172 - accuracy: 0.9942 - mean_io_u: 0.8198 - dice_coef: 0.6727 - precision: 0.9943 - sensitivity: 0.9928 - specificity: 0.9981 - val_loss: 0.0170 - val_accuracy: 0.9945 - val_mean_io_u: 0.8149 - val_dice_coef: 0.6654 - val_precision: 0.9945 - val_sensitivity: 0.9932 - val_specificity: 0.9981 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9946 - mean_io_u: 0.8254 - dice_coef: 0.6846 - precision: 0.9946 - sensitivity: 0.9934 - specificity: 0.9982\n",
      "Epoch 00013: val_loss improved from 0.01699 to 0.01537, saving model to ./model_v1_Mar-11_00-55-22/model_epoch13-val_loss0.015374_Mar-11_00-55-22.m5\n",
      "850/850 [==============================] - 555s 652ms/step - loss: 0.0157 - accuracy: 0.9946 - mean_io_u: 0.8254 - dice_coef: 0.6846 - precision: 0.9946 - sensitivity: 0.9934 - specificity: 0.9982 - val_loss: 0.0154 - val_accuracy: 0.9950 - val_mean_io_u: 0.8224 - val_dice_coef: 0.6740 - val_precision: 0.9949 - val_sensitivity: 0.9938 - val_specificity: 0.9983 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9949 - mean_io_u: 0.8248 - dice_coef: 0.6952 - precision: 0.9948 - sensitivity: 0.9937 - specificity: 0.9982\n",
      "Epoch 00014: val_loss did not improve from 0.01537\n",
      "850/850 [==============================] - 554s 652ms/step - loss: 0.0148 - accuracy: 0.9949 - mean_io_u: 0.8248 - dice_coef: 0.6952 - precision: 0.9948 - sensitivity: 0.9937 - specificity: 0.9982 - val_loss: 0.0172 - val_accuracy: 0.9944 - val_mean_io_u: 0.8409 - val_dice_coef: 0.6508 - val_precision: 0.9943 - val_sensitivity: 0.9932 - val_specificity: 0.9981 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9950 - mean_io_u: 0.8276 - dice_coef: 0.6996 - precision: 0.9948 - sensitivity: 0.9937 - specificity: 0.9983\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01537\n",
      "850/850 [==============================] - 554s 652ms/step - loss: 0.0146 - accuracy: 0.9950 - mean_io_u: 0.8276 - dice_coef: 0.6996 - precision: 0.9948 - sensitivity: 0.9937 - specificity: 0.9983 - val_loss: 0.0166 - val_accuracy: 0.9948 - val_mean_io_u: 0.8606 - val_dice_coef: 0.6798 - val_precision: 0.9948 - val_sensitivity: 0.9937 - val_specificity: 0.9982 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9958 - mean_io_u: 0.8365 - dice_coef: 0.7236 - precision: 0.9955 - sensitivity: 0.9946 - specificity: 0.9985\n",
      "Epoch 00016: val_loss improved from 0.01537 to 0.01409, saving model to ./model_v1_Mar-11_00-55-22/model_epoch16-val_loss0.014092_Mar-11_00-55-22.m5\n",
      "850/850 [==============================] - 555s 653ms/step - loss: 0.0120 - accuracy: 0.9958 - mean_io_u: 0.8365 - dice_coef: 0.7236 - precision: 0.9955 - sensitivity: 0.9946 - specificity: 0.9985 - val_loss: 0.0141 - val_accuracy: 0.9954 - val_mean_io_u: 0.8387 - val_dice_coef: 0.7094 - val_precision: 0.9951 - val_sensitivity: 0.9943 - val_specificity: 0.9984 - lr: 2.0000e-05\n",
      "Epoch 17/100\n",
      "850/850 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9960 - mean_io_u: 0.8380 - dice_coef: 0.7346 - precision: 0.9956 - sensitivity: 0.9948 - specificity: 0.9985"
     ]
    }
   ],
   "source": [
    "model.fit(training_generator,\n",
    "          epochs=EPOCHS,\n",
    "          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=valid_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - 3: Plot the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "model_dir = model_dir\n",
    "training_log_filename = glob.glob(os.path.join(model_dir, 'training-*.log'))[0]\n",
    "plt_filename = os.path.splitext(os.path.basename(training_log_filename))[0]\n",
    "print(f'plt image will be saved in: {training_log_filename}\\nwith name: {plt_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSVlogger file that contains all our metrics (accuracy, loss, dice_coef, ...) of our training\n",
    "history = pd.read_csv(training_log_filename, sep=',', engine='python')\n",
    "\n",
    "# Plot training and validation metrics\n",
    "fig, axs = plt.subplots(1, 3, figsize=(16, 8))\n",
    "# fig, axs = plt.subplots(1, 4, figsize=(16, 8))\n",
    "\n",
    "axs[0].plot(history['epoch'], history['accuracy'], 'b', label='Training Accuracy')\n",
    "axs[0].plot(history['epoch'], history['val_accuracy'], 'r', label='Validation Accuracy')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Accuracy')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(history['epoch'], history['loss'], 'b', label='Training Loss')\n",
    "axs[1].plot(history['epoch'], history['val_loss'], 'r', label='Validation Loss')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[1].legend()\n",
    "\n",
    "axs[2].plot(history['epoch'], history['dice_coef'], 'b', label='Training dice coef')\n",
    "axs[2].plot(history['epoch'], history['val_dice_coef'], 'r', label='Validation dice coef')\n",
    "axs[2].set_xlabel('Epoch')\n",
    "axs[2].set_ylabel('Dice Coefficient')\n",
    "axs[2].legend()\n",
    "\n",
    "# axs[3].plot(history['epoch'], history['mean_io_u'], 'b', label='Training mean IOU')\n",
    "# axs[3].plot(history['epoch'], history['val_mean_io_u'], 'r', label='Validation mean IOU')\n",
    "# axs[3].set_xlabel('Epoch')\n",
    "# axs[3].set_ylabel('Mean IOU')\n",
    "# axs[3].legend()\n",
    "\n",
    "# Add space between subplots\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "plt.savefig(f'./plt/{plt_filename}.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile a model and load our saved weights\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "INPUT_LAYER = Input((IMG_SIZE, IMG_SIZE, N_CHANNELS))\n",
    "KER_INIT = KER_INIT\n",
    "DROPOUT = DROPOUT\n",
    "LEARNING_RATE = LEARNING_RATE\n",
    "\n",
    "best_saved_model = unet_v2(inputs = INPUT_LAYER, ker_init = KER_INIT, dropout = DROPOUT)\n",
    "\n",
    "best_saved_model.compile(loss=\"categorical_crossentropy\", optimizer=tensorflow.keras.optimizers.Adam(learning_rate=LEARNING_RATE), metrics = ['accuracy',tensorflow.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity] )\n",
    "\n",
    "TRAINED_MODEL = 'model_epoch28-val_loss0.014139_Mar-08_09-52-06.m5'\n",
    "\n",
    "best_saved_model.load_weights(f'./model_Mar-08_09-52-0/{TRAINED_MODEL}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_segmentation(sample_path):\n",
    "    # Load NIfTI (.nii) files of the sample (patient)\n",
    "    t1ce_path = sample_path + '-t1c.nii.gz'\n",
    "    flair_path = sample_path + '-t2f.nii.gz'\n",
    "    #t1_path = sample_path + '_t1.nii'\n",
    "    #t2_path = sample_path + '_t2.nii'\n",
    "            \n",
    "    # Extract the data from these paths\n",
    "    t1ce = nib.load(t1ce_path).get_fdata()\n",
    "    flair = nib.load(flair_path).get_fdata()\n",
    "    \n",
    "    # Create an empty array\n",
    "    X = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 2))\n",
    "    \n",
    "    # Perform the same operations as our DataGenerator, to keep the same input shape\n",
    "    for j in range(VOLUME_SLICES):\n",
    "        X[j,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n",
    "        X[j,:,:,1] = cv2.resize(t1ce[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n",
    "        \n",
    "    # Send our images to the CNN model and return predicted segmentation \n",
    "    return model.predict(X/np.max(X), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predicted_segmentations(samples_list, slice_to_plot, cmap, norm):\n",
    "    # Choose a random patient\n",
    "    random_sample = random.choice(samples_list)\n",
    "    print(f'random_sample: {random_sample}')\n",
    "    \n",
    "    # Get path of this patient\n",
    "    random_sample_path = os.path.join(data_path_GLI_train_dir, random_sample, random_sample)\n",
    "    print(f'random_sample_path: {random_sample_path}')\n",
    "    \n",
    "    # Predict patient's segmentation\n",
    "    predicted_seg = predict_segmentation(random_sample_path)\n",
    "   \n",
    "    # Load patient's original segmentation (Ground truth)\n",
    "    seg_path = random_sample_path + '-seg.nii.gz'\n",
    "    seg = nib.load(seg_path).get_fdata()\n",
    "    \n",
    "    # Resize original segmentation to the same dimensions of the predictions. (Add VOLUME_START_AT because original segmentation contains 155 slices vs only 75 for our prediction)\n",
    "    seg=cv2.resize(seg[:,:,slice_to_plot+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_NEAREST)\n",
    "    \n",
    "    # Differentiate segmentations by their labels\n",
    "    all = predicted_seg[slice_to_plot,:,:,1:4] # Deletion of class 0 (Keep only Core + Edema + Enhancing classes)\n",
    "    zero = predicted_seg[slice_to_plot,:,:,0] # Isolation of class 0, Background (kind of useless, it is the opposite of the \"all\")\n",
    "    first = predicted_seg[slice_to_plot,:,:,1] # Isolation of class 1, Core\n",
    "    second = predicted_seg[slice_to_plot,:,:,2] # Isolation of class 2, Edema\n",
    "    third = predicted_seg[slice_to_plot,:,:,3] # Isolation of class 3, Enhancing\n",
    "\n",
    "    # Plot Original segmentation & predicted segmentation\n",
    "    print(\"Patient number: \", random_sample)\n",
    "    fig, axstest = plt.subplots(1, 6, figsize=(25, 20))\n",
    "\n",
    "    # Original segmentation\n",
    "    axstest[0].imshow(seg, cmap, norm)\n",
    "    axstest[0].set_title('Original Segmentation')\n",
    "    \n",
    "    # Layers 1, 2, 3\n",
    "    axstest[1].imshow(all)\n",
    "    axstest[1].set_title('Predicted Segmentation - all layers')\n",
    "    \n",
    "    # Layer 0\n",
    "    axstest[2].imshow(zero)\n",
    "    axstest[2].set_title('Predicted Segmentation - layer 0')\n",
    "    \n",
    "    # Layer 1\n",
    "    axstest[3].imshow(first)\n",
    "    axstest[3].set_title('Predicted Segmentation - layer 1')\n",
    "    \n",
    "    # Layer 2\n",
    "    axstest[4].imshow(second)\n",
    "    axstest[4].set_title('Predicted Segmentation - layer 2')\n",
    "    \n",
    "    # Layer 3\n",
    "    axstest[5].imshow(third)\n",
    "    axstest[5].set_title('Predicted Segmentation - layer 3')\n",
    "    \n",
    "    # Add space between subplots\n",
    "    plt.subplots_adjust(wspace=0.8)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predicted_segmentations(datas_test, 60, cmap, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predicted_segmentations(datas_test, 50, cmap, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predicted_segmentations(datas_test, 70, cmap, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_post_processed_segmentations(sample, slice_to_plot, cmap, norm):\n",
    "    \n",
    "    # Get path of this patient\n",
    "    sample_path = os.path.join(data_path_GLI_train_dir, sample, sample)\n",
    "    \n",
    "    # Predict patient's segmentation\n",
    "    predicted_seg = predict_segmentation(sample_path)\n",
    "   \n",
    "    # Load patient's original segmentation (Ground truth)\n",
    "    seg_path = sample_path + '-seg.nii.gz'\n",
    "    seg = nib.load(seg_path).get_fdata()\n",
    "    \n",
    "    # Resize original segmentation to the same dimensions of the predictions. (Add VOLUME_START_AT because original segmentation contains 155 slices vs only 75 for our prediction)\n",
    "    seg=cv2.resize(seg[:,:,slice_to_plot+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_NEAREST)\n",
    "    \n",
    "    # Fix 4 to 3 to have the same values as in the predicted segmentation, and then same colors\n",
    "    seg[seg==4] = 3\n",
    "    \n",
    "    # Remove background layer (0) from original segmentation\n",
    "    seg[seg==0] = np.nan\n",
    "    \n",
    "    # Post-processing\n",
    "    # Get indexes for each class of the highest probability pixels. Array will then contain only [0 1 2 3] instead of probabilities\n",
    "    my_pred = np.argmax(predicted_seg, axis=3)\n",
    "    my_pred = my_pred[slice_to_plot, :, :]\n",
    "\n",
    "    # Remove background layer (0) from post-processed predicted segmentation\n",
    "    # To fix 0 to np.nan, we need to convert array as a float\n",
    "    my_pred = my_pred.astype(float)\n",
    "    my_pred[my_pred == 0] = np.nan\n",
    "\n",
    "    # Remove background layer (0) from classical predicted segmentation\n",
    "    all = predicted_seg[slice_to_plot,:,:,1:4] \n",
    "    \n",
    "    # Plot Original segmentation & predicted segmentation without processing & predicted segmentation\n",
    "    print(\"Patient number: \", sample)\n",
    "    fig, axstest = plt.subplots(1, 3, figsize=(15, 10))\n",
    "\n",
    "    axstest[0].imshow(seg, cmap, norm)\n",
    "    axstest[0].set_title('Original Segmentation')\n",
    "    \n",
    "    axstest[1].imshow(all)\n",
    "    axstest[1].set_title('Prediction (w/o post processing (layer 1,2,3)')\n",
    "    \n",
    "    axstest[2].imshow(my_pred, cmap, norm)\n",
    "    axstest[2].set_title('Prediction (w/ post processing (layer 1,2,3)')\n",
    "    \n",
    "    # Add space between subplots\n",
    "    plt.subplots_adjust(wspace=0.8)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_post_processed_segmentations(sample = \"BraTS-GLI-00777-000\", slice_to_plot=60, cmap=cmap, norm=norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_post_processed_segmentations(sample = \"BraTS-GLI-00675-000\", slice_to_plot=50, cmap=cmap, norm=norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 - Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_generator = DataGenerator_UnetV1(datas_test) if DATA_GENERATOR_VERSION == 1 else DataGenerator_UnetV2(datas_test)\n",
    "results = model.evaluate(test_generator, batch_size=100, callbacks= callbacks)\n",
    "\n",
    "descriptions = [\"Loss\", \"Accuracy\", \"MeanIOU\", \"Dice coefficient\", \"Precision\", \"Sensitivity\", \"Specificity\"]\n",
    "\n",
    "# Combine results list and descriptions list\n",
    "results_list = zip(results, descriptions)\n",
    "\n",
    "# Display each metric with its description\n",
    "print(\"\\nModel evaluation on the test set:\")\n",
    "print(\"==================================\")\n",
    "for i, (metric, description) in enumerate(results_list):\n",
    "    print(f\"{description} : {round(metric, 4)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
