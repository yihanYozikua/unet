{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your Unet with membrane data\n",
    "membrane data is in folder membrane/, it is a binary classification task.\n",
    "\n",
    "The input shape of image and mask are the same :(batch_size,rows,cols,channel = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)          [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_216 (Conv2D)            (None, 256, 256, 64  640         ['input_10[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_217 (Conv2D)            (None, 256, 256, 64  36928       ['conv2d_216[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_36 (MaxPooling2D  (None, 128, 128, 64  0          ['conv2d_217[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_218 (Conv2D)            (None, 128, 128, 12  73856       ['max_pooling2d_36[0][0]']       \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_219 (Conv2D)            (None, 128, 128, 12  147584      ['conv2d_218[0][0]']             \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_37 (MaxPooling2D  (None, 64, 64, 128)  0          ['conv2d_219[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_220 (Conv2D)            (None, 64, 64, 256)  295168      ['max_pooling2d_37[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_221 (Conv2D)            (None, 64, 64, 256)  590080      ['conv2d_220[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_38 (MaxPooling2D  (None, 32, 32, 256)  0          ['conv2d_221[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_222 (Conv2D)            (None, 32, 32, 512)  1180160     ['max_pooling2d_38[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_223 (Conv2D)            (None, 32, 32, 512)  2359808     ['conv2d_222[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 32, 32, 512)  0           ['conv2d_223[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_39 (MaxPooling2D  (None, 16, 16, 512)  0          ['dropout_18[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_224 (Conv2D)            (None, 16, 16, 1024  4719616     ['max_pooling2d_39[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_225 (Conv2D)            (None, 16, 16, 1024  9438208     ['conv2d_224[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 16, 16, 1024  0           ['conv2d_225[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_36 (UpSampling2D  (None, 32, 32, 1024  0          ['dropout_19[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_226 (Conv2D)            (None, 32, 32, 512)  2097664     ['up_sampling2d_36[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_36 (Concatenate)   (None, 32, 32, 1024  0           ['dropout_18[0][0]',             \n",
      "                                )                                 'conv2d_226[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_227 (Conv2D)            (None, 32, 32, 512)  4719104     ['concatenate_36[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_228 (Conv2D)            (None, 32, 32, 512)  2359808     ['conv2d_227[0][0]']             \n",
      "                                                                                                  \n",
      " up_sampling2d_37 (UpSampling2D  (None, 64, 64, 512)  0          ['conv2d_228[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_229 (Conv2D)            (None, 64, 64, 256)  524544      ['up_sampling2d_37[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_37 (Concatenate)   (None, 64, 64, 512)  0           ['conv2d_221[0][0]',             \n",
      "                                                                  'conv2d_229[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_230 (Conv2D)            (None, 64, 64, 256)  1179904     ['concatenate_37[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_231 (Conv2D)            (None, 64, 64, 256)  590080      ['conv2d_230[0][0]']             \n",
      "                                                                                                  \n",
      " up_sampling2d_38 (UpSampling2D  (None, 128, 128, 25  0          ['conv2d_231[0][0]']             \n",
      " )                              6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_232 (Conv2D)            (None, 128, 128, 12  131200      ['up_sampling2d_38[0][0]']       \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_38 (Concatenate)   (None, 128, 128, 25  0           ['conv2d_219[0][0]',             \n",
      "                                6)                                'conv2d_232[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_233 (Conv2D)            (None, 128, 128, 12  295040      ['concatenate_38[0][0]']         \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_234 (Conv2D)            (None, 128, 128, 12  147584      ['conv2d_233[0][0]']             \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_39 (UpSampling2D  (None, 256, 256, 12  0          ['conv2d_234[0][0]']             \n",
      " )                              8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_235 (Conv2D)            (None, 256, 256, 64  32832       ['up_sampling2d_39[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_39 (Concatenate)   (None, 256, 256, 12  0           ['conv2d_217[0][0]',             \n",
      "                                8)                                'conv2d_235[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_236 (Conv2D)            (None, 256, 256, 64  73792       ['concatenate_39[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_237 (Conv2D)            (None, 256, 256, 64  36928       ['conv2d_236[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_238 (Conv2D)            (None, 256, 256, 2)  1154        ['conv2d_237[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_239 (Conv2D)            (None, 256, 256, 1)  3           ['conv2d_238[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,031,685\n",
      "Trainable params: 31,031,685\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Found 0 images belonging to 1 classes.\n",
      "Found 0 images belonging to 1 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m model \u001b[39m=\u001b[39m unet()\n\u001b[1;32m     10\u001b[0m model_checkpoint \u001b[39m=\u001b[39m ModelCheckpoint(\u001b[39m'\u001b[39m\u001b[39munet_membrane.keras\u001b[39m\u001b[39m'\u001b[39m, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m,verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 12\u001b[0m \u001b[39mfor\u001b[39;00m img, mask \u001b[39min\u001b[39;00m myGene:\n\u001b[1;32m     13\u001b[0m     \u001b[39mprint\u001b[39m(img)\n\u001b[1;32m     14\u001b[0m     \u001b[39mprint\u001b[39m(mask)\n",
      "File \u001b[0;32m~/Desktop/YIHAN/unet/data.py:80\u001b[0m, in \u001b[0;36mtrainGenerator\u001b[0;34m(batch_size, train_path, image_folder, mask_folder, aug_dict, image_color_mode, mask_color_mode, image_save_prefix, mask_save_prefix, flag_multi_class, num_class, save_to_dir, target_size, seed)\u001b[0m\n\u001b[1;32m     78\u001b[0m train_generator \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(image_generator, mask_generator)\n\u001b[1;32m     79\u001b[0m \u001b[39mfor\u001b[39;00m (img,mask) \u001b[39min\u001b[39;00m train_generator:\n\u001b[0;32m---> 80\u001b[0m     img,mask \u001b[39m=\u001b[39m adjustData(img,mask,flag_multi_class,num_class)\n\u001b[1;32m     81\u001b[0m     \u001b[39myield\u001b[39;00m (img,mask)\n",
      "File \u001b[0;32m~/Desktop/YIHAN/unet/data.py:39\u001b[0m, in \u001b[0;36madjustData\u001b[0;34m(img, mask, flag_multi_class, num_class)\u001b[0m\n\u001b[1;32m     37\u001b[0m     new_mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(new_mask,(new_mask\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],new_mask\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m*\u001b[39mnew_mask\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m],new_mask\u001b[39m.\u001b[39mshape[\u001b[39m3\u001b[39m])) \u001b[39mif\u001b[39;00m flag_multi_class \u001b[39melse\u001b[39;00m np\u001b[39m.\u001b[39mreshape(new_mask,(new_mask\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m*\u001b[39mnew_mask\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],new_mask\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]))\n\u001b[1;32m     38\u001b[0m     mask \u001b[39m=\u001b[39m new_mask\n\u001b[0;32m---> 39\u001b[0m \u001b[39melif\u001b[39;00m(np\u001b[39m.\u001b[39;49mmax(img) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m     40\u001b[0m     img \u001b[39m=\u001b[39m img \u001b[39m/\u001b[39m \u001b[39m255\u001b[39m\n\u001b[1;32m     41\u001b[0m     mask \u001b[39m=\u001b[39m mask \u001b[39m/\u001b[39m\u001b[39m255\u001b[39m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/yihan/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2791\u001b[0m, in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2675\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_amax_dispatcher)\n\u001b[1;32m   2676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mamax\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, initial\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue,\n\u001b[1;32m   2677\u001b[0m          where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n\u001b[1;32m   2678\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2679\u001b[0m \u001b[39m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[1;32m   2680\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2789\u001b[0m \u001b[39m    5\u001b[39;00m\n\u001b[1;32m   2790\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2791\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49mmaximum, \u001b[39m'\u001b[39;49m\u001b[39mmax\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, \u001b[39mNone\u001b[39;49;00m, out,\n\u001b[1;32m   2792\u001b[0m                           keepdims\u001b[39m=\u001b[39;49mkeepdims, initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[0;32m~/anaconda3/envs/yihan/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "myGene = trainGenerator(2,'../brain_tumor_seg/data/unet/train/seg/','t2f','seg',data_gen_args,save_to_dir = None)\n",
    "model = unet()\n",
    "model_checkpoint = ModelCheckpoint('unet_membrane.keras', monitor='loss',verbose=1, save_best_only=True)\n",
    "\n",
    "for img, mask in myGene:\n",
    "    if img.size == 0 or mask.size == 0:\n",
    "        raise ValueError(\"There is nothing in the image from generator\")\n",
    "    print(f\"Image shape: {img.shape}, Mask shape: {mask.shape}\")\n",
    "    break\n",
    "\n",
    "model.fit(myGene,steps_per_epoch=2000,epochs=5,callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgs_train,imgs_mask_train = geneTrainNpy(\"data/membrane/train/aug/\",\"data/membrane/train/aug/\")\n",
    "#model.fit(imgs_train, imgs_mask_train, batch_size=2, nb_epoch=10, verbose=1,validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test your model and save predicted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuhaozhi\\Documents\\Study\\unet\\model.py:34: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  merge6 = merge([drop4,up6], mode = 'concat', concat_axis = 3)\n",
      "C:\\SoftWare\\Anaconda2\\envs\\python3\\lib\\site-packages\\keras\\legacy\\layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "C:\\Users\\xuhaozhi\\Documents\\Study\\unet\\model.py:39: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  merge7 = merge([conv3,up7], mode = 'concat', concat_axis = 3)\n",
      "C:\\Users\\xuhaozhi\\Documents\\Study\\unet\\model.py:44: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  merge8 = merge([conv2,up8], mode = 'concat', concat_axis = 3)\n",
      "C:\\Users\\xuhaozhi\\Documents\\Study\\unet\\model.py:49: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  merge9 = merge([conv1,up9], mode = 'concat', concat_axis = 3)\n",
      "C:\\Users\\xuhaozhi\\Documents\\Study\\unet\\model.py:55: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n",
      "  model = Model(input = inputs, output = conv10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 1/30 [>.............................] - ETA: 4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\SoftWare\\Anaconda2\\envs\\python3\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "C:\\SoftWare\\Anaconda2\\envs\\python3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 1s 47ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\SoftWare\\Anaconda2\\envs\\python3\\lib\\site-packages\\skimage\\util\\dtype.py:130: UserWarning: Possible precision loss when converting from float32 to uint16\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "testGene = testGenerator(\"data/membrane/test\")\n",
    "model = unet()\n",
    "model.load_weights(\"unet_membrane.hdf5\")\n",
    "results = model.predict_generator(testGene,30,verbose=1)\n",
    "saveResult(\"data/membrane/test\",results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
